{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PTC5srJ2bYG9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-learn in /Users/akeem/anaconda3/envs/blank_tf/lib/python3.10/site-packages (1.4.1.post1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.19.5 in /Users/akeem/anaconda3/envs/blank_tf/lib/python3.10/site-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /Users/akeem/anaconda3/envs/blank_tf/lib/python3.10/site-packages (from scikit-learn) (1.12.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /Users/akeem/anaconda3/envs/blank_tf/lib/python3.10/site-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/akeem/anaconda3/envs/blank_tf/lib/python3.10/site-packages (from scikit-learn) (3.4.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-learn\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras \n",
        "from tensorflow.keras import layers\n",
        "#from tensorflow.keras import Sequential\n",
        "#from tensorflow.keras import Dense, Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, InputLayer, Reshape, BatchNormalization\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from keras import metrics\n",
        "\n",
        "try:\n",
        "    from keras.utils import np_utils\n",
        "except:\n",
        "    pass\n",
        "try:\n",
        "    from tensorflow.keras import utils as np_utils\n",
        "except:\n",
        "    pass\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "kt2r1tfRg0cj"
      },
      "outputs": [],
      "source": [
        "# Helper to plot loss\n",
        "def plot_loss(history):\n",
        "  plt.plot(history.history['loss'], label='loss')\n",
        "  plt.plot(history.history['val_loss'], label='val_loss')\n",
        "  plt.legend()\n",
        "  plt.grid(True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SS8tDLiFbYG_"
      },
      "source": [
        "# Keras and Tensorflow Optimizations\n",
        "\n",
        "There are several things that we can do to make our networks a bit better. Unfortunately for much of this there aren't definitive answers for \"what is the best choice\", so we do have to do some trial and error, but we can use some guidelines to get us started in the right direction.\n",
        "\n",
        "## Environment Notes\n",
        "\n",
        "There were some things that changed since I originally wrote this code with respect to versions and some of the naming schemes in the Keras/Tensorflow libraries. I created a new environment from scratch, and had it install several key packages. The command I used, to make an environment called \"blank_tf\" was:\n",
        "\n",
        "```bash\n",
        " conda create -n blank_tf keras tensorflow pandas seaborn matplotlib scipy numpy scikit-learn\n",
        "```\n",
        "This will install those libraries, along with an assortment of their dependencies. If you choose to do something similar, be aware that this environment may lack other libraries that you might need for other stuff, if so, a command of '!pip install <package_name>' will install the package in the current environment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQLYUA1XbYHB"
      },
      "source": [
        "## Load MNIST Data\n",
        "\n",
        "We can use the MNIST digit dataset for testing, since it is reasonably large. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGygrQlobYHC",
        "outputId": "e48ea85c-2032-4ddc-85bf-4a02dd76b7f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(60000, 28, 28)\n",
            "Epoch 1/10\n",
            "   1/1500 [..............................] - ETA: 4:14 - loss: 2.3604 - accuracy: 0.1250"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-04-02 13:33:18.839738: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.2223 - accuracy: 0.9348 - val_loss: 0.1256 - val_accuracy: 0.9627\n",
            "Epoch 2/10\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.0881 - accuracy: 0.9730 - val_loss: 0.0916 - val_accuracy: 0.9723\n",
            "Epoch 3/10\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.0581 - accuracy: 0.9817 - val_loss: 0.0864 - val_accuracy: 0.9737\n",
            "Epoch 4/10\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.0393 - accuracy: 0.9878 - val_loss: 0.0847 - val_accuracy: 0.9758\n",
            "Epoch 5/10\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.0288 - accuracy: 0.9910 - val_loss: 0.0929 - val_accuracy: 0.9743\n",
            "Epoch 6/10\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.0216 - accuracy: 0.9933 - val_loss: 0.0847 - val_accuracy: 0.9772\n",
            "Epoch 7/10\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.0193 - accuracy: 0.9936 - val_loss: 0.0918 - val_accuracy: 0.9772\n",
            "Epoch 8/10\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.0120 - accuracy: 0.9962 - val_loss: 0.0980 - val_accuracy: 0.9763\n",
            "Epoch 9/10\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.0138 - accuracy: 0.9952 - val_loss: 0.0902 - val_accuracy: 0.9793\n",
            "Epoch 10/10\n",
            "1500/1500 [==============================] - 2s 2ms/step - loss: 0.0114 - accuracy: 0.9961 - val_loss: 0.1015 - val_accuracy: 0.9772\n",
            "313/313 [==============================] - 0s 477us/step - loss: 0.0930 - accuracy: 0.9778\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Load MNIST dataset\n",
        "mnist = keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "# Normalize the input image so that each pixel value is between 0 and 1.\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "print(train_images.shape)\n",
        "\n",
        "train_labels = np_utils.to_categorical(train_labels)\n",
        "test_labels = np_utils.to_categorical(test_labels)\n",
        "\n",
        "model = keras.Sequential()\n",
        "model.add(InputLayer(input_shape=(28, 28)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "# Train the digit classification model\n",
        "model.compile(optimizer='adam', loss=\"categorical_crossentropy\", metrics='accuracy')\n",
        "\n",
        "train_log = model.fit(\n",
        "  train_images,\n",
        "  train_labels,\n",
        "  epochs=10,\n",
        "  validation_split=0.2,\n",
        ")\n",
        "model.evaluate(test_images, test_labels)\n",
        "plot_loss(train_log)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsycEGiGbYHE"
      },
      "source": [
        "## Prequel - Saving and Loading Models\n",
        "\n",
        "As we've seen, models can take a long time to train in many cases. Like with the sklearn models, we can save and load ours as they are trained and reused. This is a pretty integral part of making neural network models usable, so it is pretty easy. \n",
        "\n",
        "In addition to this we often see models saved in the h5 format, which just saves slightly less stuff along with the model. If we are using models trained elsewhere this format is very common. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2PSIZDbbYHE",
        "outputId": "37aa2093-e7d5-4680-fac9-ba4045372d96"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_path/assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: model_path/assets\n"
          ]
        }
      ],
      "source": [
        "# Save my model\n",
        "model.save('model_path')\n",
        "model = keras.models.load_model('model_path')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "lEJgmNFYbYHE"
      },
      "outputs": [],
      "source": [
        "# Calling `save('my_model.h5')` creates a h5 file `my_model.h5`.\n",
        "model.save(\"model_path/my_h5_model.h5\")\n",
        "\n",
        "# It can be used to reconstruct the model identically.\n",
        "reconstructed_model = keras.models.load_model(\"model_path/my_h5_model.h5\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "DoRkV4nTbYHF"
      },
      "source": [
        "## Network Size\n",
        "\n",
        "Probably the first question that we will think of when building networks through Tensorflow is \"how big should it be\"? This is a very big question, and one of those ones without a real answer. We can put some guidelines in place to help us though. \n",
        "\n",
        "### What Does the Size Mean?\n",
        "\n",
        "The size of a neural network is also known as the capacity. We can relate it roughly to the size of our first model, the tree. The larger a network is the higher its capacity to learn. This is similar to a tree, the larger the tree, the more fitted it can become to the training data. \n",
        "\n",
        "### What Size to Use?\n",
        "\n",
        "We can start with a few guidelines to have a reasonably sized neural network. These steps do not ensure an optimal solution, but they'll get us started. There really is not a prescribed method for calculating the optimal network size (beleive me, I've looked), but there are several rules of thumb we can build together to get a rough estimate of a starting point for sizing:\n",
        "\n",
        "<ul>\n",
        "<li> Start with an input layer that is either\n",
        "    <ul>\n",
        "    <li> The width of the data, if the feature set is relatively small. \n",
        "    <li> A reasonably large number if the feature set is large. \n",
        "    <li> We don't have a true diving line, but 512 is a reasonable value to try for an upper end, at least at first. \n",
        "    </ul>\n",
        "<li> Add 1 or 2 hidden layers of the same size and observe the results. We want to keep the model smaller if making it larger doesn't improve things, so first we shoudl see how good of a job a small model does. If the data is very large, skipping past the 1 layer step may save some time since we can predict that we can do better with a larger model in advance. \n",
        "<li> Increase layers of the same size until we get some overfitting and the training loss flattens. We want to reach the point where the model is getting to be excellent at predicting the training data. This is something we can see in the plot by noticing that the validation loss flatlines or starts to get worse. The training loss flattening is an indication that the model is not getting any better at learning the training data; we can use early stopping with a loose patience setting on training loss and lots of epochs to find this. \n",
        "<li> Add regularization steps to cut down that overfitting. We can try regularization and dropouts to cut down on that overfitting. We probably want to try a few options, parameters, and combinations here, there's not really a way to know in advance which regularization will work best on our data. \n",
        "<li> Do a test of \"funneling\" the layer size, potentially adding more layers. The traditional configuration of layers is to gradually decrease the size from the input layer towards the output layer. There is open debate on if this is better than having layers that are all the same size. We can play with this a little to see if results improve or not. \n",
        "<li> Use pruning. Much like a tree we can prune back a model to fight overfitting. \n",
        "</ul>\n",
        "\n",
        "### Height vs Width\n",
        "\n",
        "Another begged question is should we make networks wider (more neurons) or deeper (more layers)? To that effect, we can also think about what happens as layers are added. Each layer allows the network to learn a different representation of the data, and if we flash back to the simple logistic regression and XOR examples, each layer allows the model to capture relationships that are more complex:\n",
        "<ul>\n",
        "<li> No hidden layers - linear relationships only. \n",
        "<li> 1 or more hidden layers - nonlinear relationships, of increasing complexity.\n",
        "</ul>\n",
        "\n",
        "So the number of layers in our model directly relates to the complexity of relationships that we can capture. This doesn't directly mean that more layers are better, but it generally means that we want the number of layers to mirror the \"complexity\" of the data, though complexity is a term with no exact definition or metric here. Once again, there's no universal answer on the balance between width of layers and number of layers, but the general evidence leans towards more layers. There are several reasons for this, none of them definitive, but taken as a whole they add up to a strong case:\n",
        "\n",
        "<ul>\n",
        "<li> Ability to learn different representation of the data - this will be more clear next time when we start to look at some image specific neural networks, but one of the cool features of neural networks is that at each layer the network \"sees\" a different representation of the data, as it goes through each round of transformations. This has the effect of allowing it to identify different features at each layer, and use those features to make more and more accurate predictions. We'll examine this more soon. \n",
        "<li> Avoiding overfitting - extremely wide neural networks tend towards overfitting the training data and not generalizing as well to new data. \n",
        "<li> Ability to add interim steps - with a multi layer network we can add multiple steps such as regularization or dropouts, again to fight overfitting. \n",
        "<li> Automatic feature selection - deep neural networks will automatically perform a type of feature selection as the least important features are minimized in their importance. This is an emerging area of research - some people have argued that well designed neural networks can remove the need for feature selection, and neural networks are being created to be feature selection tools. We can see this illustrated most clearly with images again, we feed a network an entire image, and get a prediction. Note that this isn't a total rejection of feature selection for neural networks, improving the feature set will impact neural network models just as it will for ordinary models; with neural networks we just have the potential for the network to \"cover for mistakes\" in the features. This is more dramatic as data size and network size increase. \n",
        "<li> Results - deep learning has become a common term recently for a reason, due to the success of deep neural networks with many layers. Most of the cool stuff that we see coming from AI such as image recognition, translation, and self navigating robots are the result of deep learning networks. In practice these networks have tended to outperform shallower ones, especially in more complex tasks. \n",
        "</ul>\n",
        "\n",
        "### Overfitting and Underfitting\n",
        "\n",
        "Why not make a model that is both very wide and very deep? This will tend to overfit as it can \"memorize\" the training data. With large datasets we do see very large models in some cases, since the more data we have, the more fitting we can handle. With large datasets and huge models, the training time can potentially explode, so we have to be careful. This is similar to what we saw with unlimited size in trees, we can eventually create a model large enough to memorize the training data. On the whole, the model capacity can be thought of similarly to the size of a tree. If we have large amounts of complex data, we want a model that has a very high capacity, as the relationships are complicated and we have enough data to mitigate overfitting. If we have smaller or more simple data, we want a smaller model, as a large one will overfit our data. \n",
        "\n",
        "Finding the \"optimal\" size is still somewhat of an art, combined with patience for trial and error. <b>The easiest starting point is probably to create a model that can potentially overfit, though not comically large, then use some regularization techniques and early stopping to find the optimal fit.</b> We should also note that it is possible and reasonable that models of different sizes and configurations tend to converge on similar levels of performace. These neural networks are extremely flexible in how they learn during the training process, so they can \"learn around\" some degree of design decisions in a way that is more dramatic than our previous models. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-CRvieaiZI2",
        "outputId": "8c109988-428d-481d-d54e-b8eb1954cb2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1500/1500 [==============================] - 8s 5ms/step - loss: 0.2250 - accuracy: 0.9309 - val_loss: 0.1217 - val_accuracy: 0.9620\n",
            "Epoch 2/100\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.1070 - accuracy: 0.9666 - val_loss: 0.1066 - val_accuracy: 0.9692\n",
            "Epoch 3/100\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0853 - accuracy: 0.9737 - val_loss: 0.0946 - val_accuracy: 0.9721\n",
            "Epoch 4/100\n",
            "1500/1500 [==============================] - 11s 8ms/step - loss: 0.0695 - accuracy: 0.9787 - val_loss: 0.0933 - val_accuracy: 0.9742\n",
            "Epoch 5/100\n",
            "1500/1500 [==============================] - 13s 9ms/step - loss: 0.0581 - accuracy: 0.9820 - val_loss: 0.0951 - val_accuracy: 0.9743\n",
            "Epoch 6/100\n",
            "1500/1500 [==============================] - 11s 8ms/step - loss: 0.0519 - accuracy: 0.9836 - val_loss: 0.0921 - val_accuracy: 0.9769\n",
            "Epoch 7/100\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0496 - accuracy: 0.9846 - val_loss: 0.1158 - val_accuracy: 0.9734\n",
            "Epoch 8/100\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0424 - accuracy: 0.9868 - val_loss: 0.1216 - val_accuracy: 0.9733\n",
            "Epoch 9/100\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0389 - accuracy: 0.9883 - val_loss: 0.1008 - val_accuracy: 0.9783\n",
            "Epoch 10/100\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.0414 - accuracy: 0.9884 - val_loss: 0.0957 - val_accuracy: 0.9765\n",
            "Epoch 11/100\n",
            "1500/1500 [==============================] - 10s 7ms/step - loss: 0.0357 - accuracy: 0.9896 - val_loss: 0.1291 - val_accuracy: 0.9762\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.0849 - accuracy: 0.9790\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Model\n",
        "model = keras.Sequential()\n",
        "model.add(InputLayer(input_shape=(28, 28)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(784, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(784, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True) \n",
        "\n",
        "# Train the digit classification model\n",
        "model.compile(optimizer='adam', loss=\"categorical_crossentropy\", metrics='accuracy')\n",
        "\n",
        "train_log = model.fit(\n",
        "  train_images,\n",
        "  train_labels,\n",
        "  epochs=100,\n",
        "  validation_split=0.2,\n",
        "  callbacks=[callback]\n",
        ")\n",
        "model.evaluate(test_images, test_labels)\n",
        "plot_loss(train_log)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJkWGpsmbYHG",
        "outputId": "cda23fac-98c0-4d7d-d016-56d69a369bda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1500/1500 [==============================] - 12s 8ms/step - loss: 0.2871 - accuracy: 0.9134 - val_loss: 0.1562 - val_accuracy: 0.9554\n",
            "Epoch 2/100\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.1530 - accuracy: 0.9570 - val_loss: 0.1137 - val_accuracy: 0.9667\n",
            "Epoch 3/100\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.1197 - accuracy: 0.9669 - val_loss: 0.1153 - val_accuracy: 0.9689\n",
            "Epoch 4/100\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.1025 - accuracy: 0.9712 - val_loss: 0.1107 - val_accuracy: 0.9707\n",
            "Epoch 5/100\n",
            "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0907 - accuracy: 0.9753 - val_loss: 0.0977 - val_accuracy: 0.9747\n",
            "Epoch 6/100\n",
            " 708/1500 [=============>................] - ETA: 4s - loss: 0.0783 - accuracy: 0.9781"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[7], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Train the digit classification model\u001b[39;00m\n\u001b[1;32m     18\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 20\u001b[0m train_log \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m  \u001b[49m\u001b[43mtrain_images\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m  \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m  \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m  \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m  \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m model\u001b[38;5;241m.\u001b[39mevaluate(test_images, test_labels)\n\u001b[1;32m     28\u001b[0m plot_loss(train_log)\n",
            "File \u001b[0;32m~/anaconda3/envs/blank_tf/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m~/anaconda3/envs/blank_tf/lib/python3.10/site-packages/keras/engine/training.py:1650\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1642\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1643\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1644\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1648\u001b[0m ):\n\u001b[1;32m   1649\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1650\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1651\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1652\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
            "File \u001b[0;32m~/anaconda3/envs/blank_tf/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m~/anaconda3/envs/blank_tf/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    877\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 880\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    882\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    883\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
            "File \u001b[0;32m~/anaconda3/envs/blank_tf/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:912\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    909\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    910\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    911\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 912\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    914\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    915\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    916\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
            "File \u001b[0;32m~/anaconda3/envs/blank_tf/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    132\u001b[0m   (concrete_function,\n\u001b[1;32m    133\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/anaconda3/envs/blank_tf/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1741\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1744\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1745\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1746\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1747\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m     args,\n\u001b[1;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1750\u001b[0m     executing_eagerly)\n\u001b[1;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
            "File \u001b[0;32m~/anaconda3/envs/blank_tf/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    377\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 378\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    384\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    385\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    386\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    387\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    390\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    391\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
            "File \u001b[0;32m~/anaconda3/envs/blank_tf/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Bigger Model\n",
        "model = keras.Sequential()\n",
        "model.add(InputLayer(input_shape=(28, 28)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True) \n",
        "\n",
        "# Train the digit classification model\n",
        "model.compile(optimizer='adam', loss=\"categorical_crossentropy\", metrics='accuracy')\n",
        "\n",
        "train_log = model.fit(\n",
        "  train_images,\n",
        "  train_labels,\n",
        "  epochs=100,\n",
        "  validation_split=0.2,\n",
        "  callbacks=[callback]\n",
        ")\n",
        "model.evaluate(test_images, test_labels)\n",
        "plot_loss(train_log)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cmRw70jwga-g",
        "outputId": "c6dacb57-0449-40b7-e461-457f48745d70"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3815 - accuracy: 0.8892 - val_loss: 0.1902 - val_accuracy: 0.9459\n",
            "Epoch 2/100\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1722 - accuracy: 0.9550 - val_loss: 0.1276 - val_accuracy: 0.9660\n",
            "Epoch 3/100\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1339 - accuracy: 0.9655 - val_loss: 0.1143 - val_accuracy: 0.9712\n",
            "Epoch 4/100\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.1110 - accuracy: 0.9717 - val_loss: 0.1075 - val_accuracy: 0.9728\n",
            "Epoch 5/100\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0984 - accuracy: 0.9750 - val_loss: 0.1050 - val_accuracy: 0.9740\n",
            "Epoch 6/100\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0873 - accuracy: 0.9771 - val_loss: 0.1058 - val_accuracy: 0.9747\n",
            "Epoch 7/100\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0776 - accuracy: 0.9798 - val_loss: 0.0881 - val_accuracy: 0.9787\n",
            "Epoch 8/100\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0760 - accuracy: 0.9812 - val_loss: 0.1055 - val_accuracy: 0.9768\n",
            "Epoch 9/100\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0683 - accuracy: 0.9822 - val_loss: 0.1086 - val_accuracy: 0.9746\n",
            "Epoch 10/100\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0600 - accuracy: 0.9843 - val_loss: 0.1111 - val_accuracy: 0.9793\n",
            "Epoch 11/100\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0564 - accuracy: 0.9855 - val_loss: 0.1091 - val_accuracy: 0.9776\n",
            "Epoch 12/100\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.0578 - accuracy: 0.9853 - val_loss: 0.1005 - val_accuracy: 0.9789\n",
            "313/313 [==============================] - 0s 635us/step - loss: 0.0929 - accuracy: 0.9781\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Tapered Model\n",
        "model = keras.Sequential()\n",
        "model.add(InputLayer(input_shape=(28, 28)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(500, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(350, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(200, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True) \n",
        "\n",
        "# Train the digit classification model\n",
        "model.compile(optimizer='adam', loss=\"categorical_crossentropy\", metrics='accuracy')\n",
        "\n",
        "train_log = model.fit(\n",
        "  train_images,\n",
        "  train_labels,\n",
        "  epochs=100,\n",
        "  validation_split=0.2,\n",
        "  callbacks=[callback]\n",
        ")\n",
        "model.evaluate(test_images, test_labels)\n",
        "plot_loss(train_log)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "LwRjUyBMbYHG"
      },
      "source": [
        "## Epochs and Batch Sizes\n",
        "\n",
        "![Batch Sizes](images/iterations_epoch.webp \"Batch Sizes\")\n",
        "\n",
        "### Epochs\n",
        "\n",
        "Each epoch is a run through all of the training data. Epochs are simple, we can set a large number and use early stopping to cut things off when we've reached the best result. \n",
        "\n",
        "### Batch Sizes\n",
        "\n",
        "Batch size determines how many records are processed before the gradients are updated - i.e. the number of records between one forward and backwards pass. The batch sizes are a matter of very open debate for the optimal solution. At the high end, batch sizes are limited by what can fit in memory. When dealing with very large data this may matter as a batch that is a small fraction of the data may be a massive absolute size. At the lower end using smaller batches gives the same effect as it does when we looked at regular gradient descent - the gradients become less stable as we are relying on a smaller number of records. In reading more about batch sizes I want to update my recommendation to be even smaller than the 50 to 150 I suggested before, down to less than 100, even as small as into the single digits. There is research that smaller batch sizes tend to produce models that generalize better than ones with larger batches. \n",
        "\n",
        "Larger batch sizes do tend to be processed more quickly, sometimes substantially so, as the hardware is better able to be \"saturated\" with data to process. In big data scenarios, this can matter. One thing that you see in practice is that the GPUs (or similar) that are used to train neural networks have a certain amount of memory, and the batch size is limited by that memory. When doing something that involves large images or video, or similar, this can be a real area for concern. For us, these constraints won't really come up, but it's good to be aware of them. \n",
        "\n",
        "Dont' stress too much on batch size, this is really something that needs to be grid searched to find a great answer and in scenarios where it actually matters, is largely influenced by the hardware that is available."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMFYDxPdbYHG",
        "outputId": "bff27c4c-5d53-4d25-96f5-ef5c69444d3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 1.3769 - accuracy: 0.6282 - val_loss: 0.4761 - val_accuracy: 0.8654\n",
            "Epoch 2/100\n",
            "10/10 [==============================] - 0s 49ms/step - loss: 0.4748 - accuracy: 0.8557 - val_loss: 0.3058 - val_accuracy: 0.9145\n",
            "Epoch 3/100\n",
            "10/10 [==============================] - 0s 50ms/step - loss: 0.3443 - accuracy: 0.8989 - val_loss: 0.2441 - val_accuracy: 0.9285\n",
            "Epoch 4/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.2684 - accuracy: 0.9211 - val_loss: 0.2009 - val_accuracy: 0.9409\n",
            "Epoch 5/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.2248 - accuracy: 0.9344 - val_loss: 0.1758 - val_accuracy: 0.9507\n",
            "Epoch 6/100\n",
            "10/10 [==============================] - 1s 56ms/step - loss: 0.1941 - accuracy: 0.9439 - val_loss: 0.1585 - val_accuracy: 0.9547\n",
            "Epoch 7/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.1702 - accuracy: 0.9494 - val_loss: 0.1440 - val_accuracy: 0.9593\n",
            "Epoch 8/100\n",
            "10/10 [==============================] - 1s 61ms/step - loss: 0.1520 - accuracy: 0.9551 - val_loss: 0.1307 - val_accuracy: 0.9621\n",
            "Epoch 9/100\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 0.1349 - accuracy: 0.9593 - val_loss: 0.1221 - val_accuracy: 0.9641\n",
            "Epoch 10/100\n",
            "10/10 [==============================] - 1s 90ms/step - loss: 0.1235 - accuracy: 0.9633 - val_loss: 0.1153 - val_accuracy: 0.9655\n",
            "Epoch 11/100\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.1117 - accuracy: 0.9674 - val_loss: 0.1087 - val_accuracy: 0.9678\n",
            "Epoch 12/100\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.1009 - accuracy: 0.9704 - val_loss: 0.1021 - val_accuracy: 0.9705\n",
            "Epoch 13/100\n",
            "10/10 [==============================] - 1s 65ms/step - loss: 0.0929 - accuracy: 0.9727 - val_loss: 0.0994 - val_accuracy: 0.9687\n",
            "Epoch 14/100\n",
            "10/10 [==============================] - 1s 62ms/step - loss: 0.0864 - accuracy: 0.9745 - val_loss: 0.0940 - val_accuracy: 0.9716\n",
            "Epoch 15/100\n",
            "10/10 [==============================] - 1s 60ms/step - loss: 0.0792 - accuracy: 0.9760 - val_loss: 0.0915 - val_accuracy: 0.9725\n",
            "Epoch 16/100\n",
            "10/10 [==============================] - 1s 56ms/step - loss: 0.0738 - accuracy: 0.9777 - val_loss: 0.0885 - val_accuracy: 0.9733\n",
            "Epoch 17/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0682 - accuracy: 0.9804 - val_loss: 0.0874 - val_accuracy: 0.9737\n",
            "Epoch 18/100\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.0632 - accuracy: 0.9816 - val_loss: 0.0854 - val_accuracy: 0.9738\n",
            "Epoch 19/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.0599 - accuracy: 0.9821 - val_loss: 0.0831 - val_accuracy: 0.9743\n",
            "Epoch 20/100\n",
            "10/10 [==============================] - 1s 55ms/step - loss: 0.0557 - accuracy: 0.9831 - val_loss: 0.0792 - val_accuracy: 0.9755\n",
            "Epoch 21/100\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.0501 - accuracy: 0.9854 - val_loss: 0.0786 - val_accuracy: 0.9753\n",
            "Epoch 22/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.0477 - accuracy: 0.9859 - val_loss: 0.0770 - val_accuracy: 0.9769\n",
            "Epoch 23/100\n",
            "10/10 [==============================] - 1s 63ms/step - loss: 0.0444 - accuracy: 0.9869 - val_loss: 0.0764 - val_accuracy: 0.9768\n",
            "Epoch 24/100\n",
            "10/10 [==============================] - 1s 61ms/step - loss: 0.0419 - accuracy: 0.9885 - val_loss: 0.0762 - val_accuracy: 0.9768\n",
            "Epoch 25/100\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.0394 - accuracy: 0.9883 - val_loss: 0.0761 - val_accuracy: 0.9772\n",
            "Epoch 26/100\n",
            "10/10 [==============================] - 1s 69ms/step - loss: 0.0363 - accuracy: 0.9897 - val_loss: 0.0745 - val_accuracy: 0.9784\n",
            "Epoch 27/100\n",
            "10/10 [==============================] - 1s 59ms/step - loss: 0.0347 - accuracy: 0.9903 - val_loss: 0.0724 - val_accuracy: 0.9783\n",
            "Epoch 28/100\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.0328 - accuracy: 0.9903 - val_loss: 0.0721 - val_accuracy: 0.9779\n",
            "Epoch 29/100\n",
            "10/10 [==============================] - 1s 58ms/step - loss: 0.0302 - accuracy: 0.9918 - val_loss: 0.0715 - val_accuracy: 0.9789\n",
            "Epoch 30/100\n",
            "10/10 [==============================] - 1s 64ms/step - loss: 0.0283 - accuracy: 0.9917 - val_loss: 0.0716 - val_accuracy: 0.9793\n",
            "Epoch 31/100\n",
            "10/10 [==============================] - 1s 57ms/step - loss: 0.0272 - accuracy: 0.9922 - val_loss: 0.0719 - val_accuracy: 0.9787\n",
            "Epoch 32/100\n",
            "10/10 [==============================] - 1s 53ms/step - loss: 0.0246 - accuracy: 0.9931 - val_loss: 0.0701 - val_accuracy: 0.9791\n",
            "Epoch 33/100\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.0239 - accuracy: 0.9928 - val_loss: 0.0702 - val_accuracy: 0.9789\n",
            "Epoch 34/100\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.0227 - accuracy: 0.9933 - val_loss: 0.0703 - val_accuracy: 0.9797\n",
            "Epoch 35/100\n",
            "10/10 [==============================] - 1s 52ms/step - loss: 0.0224 - accuracy: 0.9936 - val_loss: 0.0709 - val_accuracy: 0.9790\n",
            "313/313 [==============================] - 0s 654us/step - loss: 0.0626 - accuracy: 0.9809\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Big Batch\n",
        "model = keras.Sequential()\n",
        "model.add(InputLayer(input_shape=(28, 28)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(500, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(350, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True) \n",
        "\n",
        "# Train the digit classification model\n",
        "model.compile(optimizer='adam', loss=\"categorical_crossentropy\", metrics='accuracy')\n",
        "\n",
        "train_log = model.fit(\n",
        "  train_images,\n",
        "  train_labels,\n",
        "  epochs=100,\n",
        "  batch_size=5000,\n",
        "  validation_split=0.2,\n",
        "  callbacks=[callback]\n",
        ")\n",
        "model.evaluate(test_images, test_labels)\n",
        "plot_loss(train_log)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbJeAtnDipXo",
        "outputId": "e5abf716-b380-4174-f0df-9611e7689a9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "24000/24000 [==============================] - 53s 2ms/step - loss: 0.3020 - accuracy: 0.9150 - val_loss: 0.2201 - val_accuracy: 0.9416\n",
            "Epoch 2/300\n",
            "24000/24000 [==============================] - 47s 2ms/step - loss: 0.2189 - accuracy: 0.9455 - val_loss: 0.1836 - val_accuracy: 0.9528\n",
            "Epoch 3/300\n",
            "24000/24000 [==============================] - 47s 2ms/step - loss: 0.2135 - accuracy: 0.9518 - val_loss: 0.1743 - val_accuracy: 0.9672\n",
            "Epoch 4/300\n",
            "24000/24000 [==============================] - 46s 2ms/step - loss: 0.2083 - accuracy: 0.9542 - val_loss: 0.1937 - val_accuracy: 0.9653\n",
            "Epoch 5/300\n",
            "24000/24000 [==============================] - 46s 2ms/step - loss: 0.2057 - accuracy: 0.9569 - val_loss: 0.1727 - val_accuracy: 0.9685\n",
            "Epoch 6/300\n",
            "24000/24000 [==============================] - 48s 2ms/step - loss: 0.2048 - accuracy: 0.9585 - val_loss: 0.2042 - val_accuracy: 0.9689\n",
            "Epoch 7/300\n",
            "24000/24000 [==============================] - 47s 2ms/step - loss: 0.2028 - accuracy: 0.9583 - val_loss: 0.2001 - val_accuracy: 0.9668\n",
            "Epoch 8/300\n",
            "24000/24000 [==============================] - 47s 2ms/step - loss: 0.1926 - accuracy: 0.9630 - val_loss: 0.2436 - val_accuracy: 0.9652\n",
            "313/313 [==============================] - 0s 561us/step - loss: 0.1512 - accuracy: 0.9677\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Small Batch\n",
        "model = keras.Sequential()\n",
        "model.add(InputLayer(input_shape=(28, 28)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(500, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(350, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True) \n",
        "\n",
        "# Train the digit classification model\n",
        "model.compile(optimizer='adam', loss=\"categorical_crossentropy\", metrics='accuracy')\n",
        "\n",
        "# Note: Batch size of 2 is good to test\n",
        "# But it can take a VERY long time, be aggressive with the early stopping\n",
        "train_log = model.fit(\n",
        "  train_images,\n",
        "  train_labels,\n",
        "  epochs=300,\n",
        "  batch_size=2,\n",
        "  validation_split=0.2,\n",
        "  callbacks=[callback]\n",
        ")\n",
        "model.evaluate(test_images, test_labels)\n",
        "plot_loss(train_log)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "bUFvtavwbYHH"
      },
      "source": [
        "## Optimizer\n",
        "\n",
        "Of all options the optimizer is the one we will care about the least. Each different optimizer is a different algorithm for doing the gradient descent. The optimizers have different results with respect to speed, memory usage, computational expense, and likelyhood to get stuck in a local minima. The optimizer is similar to some of the options we saw with logistic regression - there were several solver options for that model, each of which performed the gradient descent process with a slightly different set of calculations. Optimizers tend to manipulate the learning rate, attempting to narrow in on the optimum weights in fewer epochs and thus fewer calculations.\n",
        "\n",
        "![Optimizers](images/optimizers.gif \"Optimizers\")\n",
        "\n",
        "<b>Note:</b> this animation doesn't have Adam, which is unfortumate, but it was the most clear one I could find. The different optimizers are all trying to find the same minimum, and in most cases they all do, but they take differnt paths to get there, over a different number of steps.\n",
        "\n",
        "Adam is a good compromise between all factors and is very commonly used. We'll just use this for our work. One other common one is RMSprop, if you're feeling spicy, give that a try and see if there are any imporvements. These optimizers don't change the model we are making (outside of edge cases, like getting stuck in a minima), they change the process of finding that model. The biggest impact of the optimizer is on the speed of the training process, and in turn the ability to experiment with different models. This is more of a concern as the data gets larger, as small improvements on each individual gradient descent step can add up to large improvements in the overall training time. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5qIRrRF2bYHH"
      },
      "outputs": [],
      "source": [
        "optimizer_1 = tf.keras.optimizers.Adam()\n",
        "optimizer_2 = tf.keras.optimizers.RMSprop()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "RXb18AySbYHH"
      },
      "source": [
        "## Activation \n",
        "\n",
        "Activation functions are the key to adding non-linearity to the network allowing it to learn complex and non-linear relationships in the data. We've used ReLU as the default and that is a solid choice in most cases. ReLU has one issue, the dying ReLU problem. This can happen when we get inputs to the activation function fall in the negative area. In short there can be neurons that \"die\" and never get updated again because the value becomes 0 and stays 0. These dead neurons are a problem as they now aren't contributing to the learning.\n",
        "\n",
        "![ReLU](images/relu.jpeg \"ReLU\")\n",
        "\n",
        "To combat the dying ReLU problem there are a couple of other activation functions that avoid that issue - Leaky ReLU and ELU. Each one changes the negative values to something other than 0 - Leaky ReLU uses a slight linear gradient, ELU uses an exponential function for a similar, but curved, slight gradient. These ReLU variants are a good choice, and probably the 'best' overall activation functions for most scenarios. One some datasets will be impacted by the dying ReLU problem. \n",
        "\n",
        "These activation function also have an impact on the speed of training. The ReLU function is very fast to calculate, and the Leaky ReLU and ELU functions are a bit slower. Other activation functions may be even more expensive. Will this matter? As with many things, it depends. For the small examples we are using, it probably won't matter much. On very large applications, we may need to consider the ability to train models more quickly, and try more models vs. the improved fit of another activation function.\n",
        "\n",
        "#### Activation Function Guidelines\n",
        "\n",
        "We can write a few rules of thumb to guide us in deciding on activation functions. On the whole, the choice is like a hyperparameter choice, and we want to choose whichever is the best for our data. Some of the guidelines are:\n",
        "<ul>\n",
        "<li> The output layer should have an activation function that matches the type of problem we are solving. \n",
        "    <ul>\n",
        "    <li> <b>Regression:</b> Linear activation function.\n",
        "    <li> <b>Binary Classification:</b> Sigmoid activation function.\n",
        "    <li> <b>Multiclass Classification:</b> Softmax activation function.\n",
        "    </ul>\n",
        "<li> Depending on the type of network/problem, our hidden layers default to different activation functions:\n",
        "    <ul>\n",
        "    <li> <b>Deep Neural Networks:</b> ReLU activation functions.\n",
        "    <li> <b>Convolutional Neural Networks: (Images)</b> ReLU activation functions.\n",
        "    <li> <b>Recurrent Neural Networks:(Seqential, Time Series)</b> Tanh activation function.\n",
        "    </ul>\n",
        "</ul>\n",
        "\n",
        "There are more activation functions, and others are being developed somewhat regularly. If in doubt, just use a ReLU variant. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQ81hFfxbYHH",
        "outputId": "d9a522ce-4252-4709-cb3a-c5cebfb1f355"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "750/750 [==============================] - 3s 3ms/step - loss: 0.2742 - accuracy: 0.9152 - val_loss: 0.1390 - val_accuracy: 0.9590\n",
            "Epoch 2/10\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.1414 - accuracy: 0.9574 - val_loss: 0.1277 - val_accuracy: 0.9630\n",
            "Epoch 3/10\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.1098 - accuracy: 0.9672 - val_loss: 0.1226 - val_accuracy: 0.9646\n",
            "Epoch 4/10\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.0962 - accuracy: 0.9718 - val_loss: 0.1139 - val_accuracy: 0.9672\n",
            "Epoch 5/10\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.0858 - accuracy: 0.9743 - val_loss: 0.0950 - val_accuracy: 0.9743\n",
            "Epoch 6/10\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.0802 - accuracy: 0.9757 - val_loss: 0.1005 - val_accuracy: 0.9730\n",
            "Epoch 7/10\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.0715 - accuracy: 0.9791 - val_loss: 0.1006 - val_accuracy: 0.9742\n",
            "Epoch 8/10\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.0669 - accuracy: 0.9795 - val_loss: 0.0986 - val_accuracy: 0.9768\n",
            "Epoch 9/10\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.0622 - accuracy: 0.9803 - val_loss: 0.1215 - val_accuracy: 0.9707\n",
            "Epoch 10/10\n",
            "750/750 [==============================] - 2s 3ms/step - loss: 0.0601 - accuracy: 0.9821 - val_loss: 0.0976 - val_accuracy: 0.9756\n",
            "313/313 [==============================] - 0s 589us/step - loss: 0.0930 - accuracy: 0.9785\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Take a leak \n",
        "model = keras.Sequential()\n",
        "model.add(InputLayer(input_shape=(28, 28)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(500, activation='leaky_relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(350, activation='leaky_relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True) \n",
        "\n",
        "# Train the digit classification model\n",
        "model.compile(optimizer=optimizer_2, loss=\"categorical_crossentropy\", metrics='accuracy')\n",
        "\n",
        "train_log = model.fit(\n",
        "  train_images,\n",
        "  train_labels,\n",
        "  epochs=10,\n",
        "  batch_size=64,\n",
        "  validation_split=0.2,\n",
        "  callbacks=[callback]\n",
        ")\n",
        "model.evaluate(test_images, test_labels)\n",
        "plot_loss(train_log)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Batch Normalization\n",
        "\n",
        "Batch normalization is a technique that is used to normalize the inputs of each layer, so that the network can learn more quickly and with more stability. This is a technique that is used to help with the vanishing gradient problem, which is a problem that can occur when the gradients become very small and the network stops learning. This is a common problem with deep networks, and batch normalization is a common solution.\n",
        "\n",
        "Using batch normalization can have a few effects on the network:\n",
        "<ul>\n",
        "<li> Faster training - the network can learn more quickly with batch normalization.\n",
        "<li> More stable training - the network is less likely to get stuck in a local minima.\n",
        "<li> Regularization - batch normalization can act as a form of regularization, helping to prevent overfitting.\n",
        "</ul>\n",
        "\n",
        "Batch normalization is a good choice for many networks, and we see it used very commonly in practice. It is unlikely to make things worse. Implementing batch normalization is as simple as adding a layer to the network. In most cases we can add it after the activation function, meaning after a dense layer here. It can be done at other points, such as before the activation layer, if it is separated from the dense layer - this is more of a fine-tuning concern. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.3746 - accuracy: 0.8929 - val_loss: 1.8112 - val_accuracy: 0.3566\n",
            "Epoch 2/100\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.2017 - accuracy: 0.9427 - val_loss: 1.1541 - val_accuracy: 0.7108\n",
            "Epoch 3/100\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.1472 - accuracy: 0.9586 - val_loss: 0.6243 - val_accuracy: 0.8037\n",
            "Epoch 4/100\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.1114 - accuracy: 0.9693 - val_loss: 0.2897 - val_accuracy: 0.9233\n",
            "Epoch 5/100\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0886 - accuracy: 0.9760 - val_loss: 0.1585 - val_accuracy: 0.9567\n",
            "Epoch 6/100\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0696 - accuracy: 0.9815 - val_loss: 0.1161 - val_accuracy: 0.9671\n",
            "Epoch 7/100\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0561 - accuracy: 0.9858 - val_loss: 0.1052 - val_accuracy: 0.9682\n",
            "Epoch 8/100\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0435 - accuracy: 0.9898 - val_loss: 0.0931 - val_accuracy: 0.9735\n",
            "Epoch 9/100\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0353 - accuracy: 0.9915 - val_loss: 0.0939 - val_accuracy: 0.9723\n",
            "Epoch 10/100\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0271 - accuracy: 0.9945 - val_loss: 0.0877 - val_accuracy: 0.9731\n",
            "Epoch 11/100\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0214 - accuracy: 0.9962 - val_loss: 0.0845 - val_accuracy: 0.9752\n",
            "Epoch 12/100\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.0170 - accuracy: 0.9977 - val_loss: 0.0840 - val_accuracy: 0.9744\n",
            "Epoch 13/100\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0132 - accuracy: 0.9981 - val_loss: 0.0827 - val_accuracy: 0.9753\n",
            "Epoch 14/100\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.0110 - accuracy: 0.9985 - val_loss: 0.0802 - val_accuracy: 0.9758\n",
            "Epoch 15/100\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0081 - accuracy: 0.9994 - val_loss: 0.0799 - val_accuracy: 0.9769\n",
            "Epoch 16/100\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0062 - accuracy: 0.9998 - val_loss: 0.0806 - val_accuracy: 0.9764\n",
            "Epoch 17/100\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.0051 - accuracy: 0.9998 - val_loss: 0.0796 - val_accuracy: 0.9770\n",
            "Epoch 18/100\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.0047 - accuracy: 0.9998 - val_loss: 0.0829 - val_accuracy: 0.9778\n",
            "Epoch 19/100\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0813 - val_accuracy: 0.9769\n",
            "Epoch 20/100\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.0809 - val_accuracy: 0.9772\n",
            "313/313 [==============================] - 0s 679us/step - loss: 0.0715 - accuracy: 0.9786\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# with sigmoid\n",
        "model = keras.Sequential()\n",
        "model.add(InputLayer(input_shape=(28, 28)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(500, activation='sigmoid'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(350, activation='sigmoid'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True) \n",
        "\n",
        "# Train the digit classification model\n",
        "model.compile(optimizer='adam', loss=\"categorical_crossentropy\", metrics='accuracy')\n",
        "\n",
        "train_log = model.fit(\n",
        "  train_images,\n",
        "  train_labels,\n",
        "  epochs=100,\n",
        "  batch_size=500,\n",
        "  validation_split=0.2,\n",
        "  callbacks=[callback]\n",
        ")\n",
        "model.evaluate(test_images, test_labels)\n",
        "plot_loss(train_log)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "96/96 [==============================] - 1s 10ms/step - loss: 0.2454 - accuracy: 0.9267 - val_loss: 0.6515 - val_accuracy: 0.9370\n",
            "Epoch 2/100\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0679 - accuracy: 0.9812 - val_loss: 0.2852 - val_accuracy: 0.9571\n",
            "Epoch 3/100\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0333 - accuracy: 0.9914 - val_loss: 0.1309 - val_accuracy: 0.9675\n",
            "Epoch 4/100\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0179 - accuracy: 0.9962 - val_loss: 0.0888 - val_accuracy: 0.9745\n",
            "Epoch 5/100\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0103 - accuracy: 0.9981 - val_loss: 0.0830 - val_accuracy: 0.9756\n",
            "Epoch 6/100\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0056 - accuracy: 0.9993 - val_loss: 0.0820 - val_accuracy: 0.9773\n",
            "Epoch 7/100\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0037 - accuracy: 0.9995 - val_loss: 0.0833 - val_accuracy: 0.9766\n",
            "Epoch 8/100\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0021 - accuracy: 0.9998 - val_loss: 0.0855 - val_accuracy: 0.9780\n",
            "Epoch 9/100\n",
            "96/96 [==============================] - 1s 9ms/step - loss: 0.0018 - accuracy: 0.9998 - val_loss: 0.0872 - val_accuracy: 0.9783\n",
            "313/313 [==============================] - 0s 567us/step - loss: 0.0693 - accuracy: 0.9797\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# With ReLU\n",
        "model = keras.Sequential()\n",
        "model.add(InputLayer(input_shape=(28, 28)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(500, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(350, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True) \n",
        "\n",
        "# Train the digit classification model\n",
        "model.compile(optimizer='adam', loss=\"categorical_crossentropy\", metrics='accuracy')\n",
        "\n",
        "train_log = model.fit(\n",
        "  train_images,\n",
        "  train_labels,\n",
        "  epochs=100,\n",
        "  batch_size=500,\n",
        "  validation_split=0.2,\n",
        "  callbacks=[callback]\n",
        ")\n",
        "model.evaluate(test_images, test_labels)\n",
        "plot_loss(train_log)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Gi7DxgCsbYHH"
      },
      "source": [
        "## Initialization\n",
        "\n",
        "The initialization provides the starting point for all the weights and bias values that we start out with. We initially started with random values in the scratch network - this is generally fine, but we can sometimes do better. One specific case where we can do better is when we have data that is highly imbalanced. This is a common problem in things such as fraud detection, where we have a very small number of fraud cases, and a very large number of non-fraud cases. Seeding the model with an \"expectation\" of the bias values can help the model learn faster and converge on an answer more quickly. In cases where we have a lot of data, this can be a big deal. In cases where we may have local minima in the loss curve, this can be significant - the more \"ground\" the gradient descent covers, the greater the odds it encounters a local minima that might be a trap. With imbalanced data, we expect that the model will need to cover a lot of that ground, so starting off with a better bias value can help. \n",
        "\n",
        "### Imbalanced Weighting\n",
        "\n",
        "One application where initialization can help significantly is when dealing with imbalanced data. In this example of credit card fraud (real data that has been put through PCA), very, very few transactions are fraudulent. So we have a very imbalanced target value - the class variable. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "jf84UJGPbYHI",
        "outputId": "8293e2c9-d3ae-45d7-a10d-30eeeeb95c1a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>...</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>149.62</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>...</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>378.66</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>123.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>69.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 31 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
              "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
              "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
              "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
              "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
              "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
              "\n",
              "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
              "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
              "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
              "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
              "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
              "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
              "\n",
              "        V26       V27       V28  Amount  Class  \n",
              "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
              "1  0.125895 -0.008983  0.014724    2.69      0  \n",
              "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
              "3 -0.221929  0.062723  0.061458  123.50      0  \n",
              "4  0.502292  0.219422  0.215153   69.99      0  \n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "file = tf.keras.utils\n",
        "raw_df = pd.read_csv('https://storage.googleapis.com/download.tensorflow.org/data/creditcard.csv')\n",
        "raw_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Count the Target Outcomes\n",
        "\n",
        "Credit card fraud is relatively rare, at least in view of the total number of transactions. We can count up the target values to see exactly what the expected skew is. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ec08WeQEi_Fz",
        "outputId": "c35fb180-9017-4304-ce29-fd36ca25bfc2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Examples:\n",
            "    Total: 284807\n",
            "    Positive: 492 (0.17% of total)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Bincount will count the number in each category\n",
        "neg, pos = np.bincount(raw_df['Class'])\n",
        "total = neg + pos\n",
        "print('Examples:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(\n",
        "    total, pos, 100 * pos / total))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gr-lqY0tHwp"
      },
      "source": [
        "### We Have an Imbalance\n",
        "\n",
        "A big one. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w5S02N45tGfu",
        "outputId": "27b8e170-e838-4c7d-adf1-b9013e4f9a6b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0              0.0\n",
              "1              0.0\n",
              "2              1.0\n",
              "3              1.0\n",
              "4              2.0\n",
              "            ...   \n",
              "284802    172786.0\n",
              "284803    172787.0\n",
              "284804    172788.0\n",
              "284805    172788.0\n",
              "284806    172792.0\n",
              "Name: Time, Length: 284807, dtype: float64"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# pop just removes a column. The equivalent of how we normally drop. \n",
        "# the TF docs commonly use this, so I've left it as is. \n",
        "cleaned_df = raw_df.copy()\n",
        "# You don't want the `Time` column.\n",
        "cleaned_df.pop('Time')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-3538h2djFHF"
      },
      "outputs": [],
      "source": [
        "# Use a utility from sklearn to split and shuffle your dataset.\n",
        "train_df, test_df = train_test_split(cleaned_df, test_size=0.2)\n",
        "\n",
        "# Form np arrays of labels and features.\n",
        "train_labels = np.array(train_df.pop('Class'))\n",
        "test_labels = np.array(test_df.pop('Class'))\n",
        "\n",
        "train_features = np.array(train_df)\n",
        "test_features = np.array(test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GC5P3kaBjMwN",
        "outputId": "ed06c86d-234b-4045-b4fc-1c117eddf35a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training features shape: (227845, 29)\n",
            "Training labels shape: (227845,)\n",
            "Test features shape: (56962, 29)\n",
            "Test labels shape: (56962,)\n"
          ]
        }
      ],
      "source": [
        "scaler = StandardScaler()\n",
        "train_features = scaler.fit_transform(train_features)\n",
        "test_features = scaler.transform(test_features)\n",
        "\n",
        "#train_features = np.clip(train_features, -5, 5)\n",
        "#test_features = np.clip(test_features, -5, 5)\n",
        "\n",
        "print('Training features shape:', train_features.shape)\n",
        "print('Training labels shape:', train_labels.shape)\n",
        "print('Test features shape:', test_features.shape)\n",
        "print('Test labels shape:', test_labels.shape)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "jtt_zz0HA6Jp"
      },
      "source": [
        "### Create a Biased Model\n",
        "\n",
        "The bias of the data is inserted in the model compilation step on the output layer. What does this do? It preconfigures the output layer to \"expect\" results to be this skewed. Recall that, along with the weight, the bias values are one of the things that is learned in training. By default the initial values are randomized, so the model needs to learn the skew towards the imbalance - if the balance between classes is moderate, that's not a big deal; if the balance is so drastically skewed in one direction, that's less practical. With the preset bias we can speed convergance and likely reduce loss. \n",
        "\n",
        "#### Other Imbalenced Work\n",
        "\n",
        "Other things that we looked at to improve balance such as under/over sampling still works with neural networks as it would with anything else. This is just one nn-specific thing that we can implement with minimal extra work. \n",
        "\n",
        "#### Metrics\n",
        "\n",
        "We can also add a bunch of metrics to what we get returned by creating a list of the metrics that we want. Keras.metrics has a list, they are all the metrics we might expect. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nO7R0L7XjTZv",
        "outputId": "1344b694-02cc-4855-8d0a-30cd56f4e6d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_31 (Dense)            (None, 16)                480       \n",
            "                                                                 \n",
            " dropout_17 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_32 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 497\n",
            "Trainable params: 497\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "2849/2849 [==============================] - 2s 521us/step - loss: 0.0078 - precision: 0.7441 - recall: 0.4787 - auc: 0.8584 - prc: 0.5039 - val_loss: 0.0043 - val_precision: 0.8864 - val_recall: 0.5493 - val_auc: 0.9292 - val_prc: 0.7288\n",
            "Epoch 2/30\n",
            "2849/2849 [==============================] - 1s 431us/step - loss: 0.0051 - precision: 0.8773 - recall: 0.5884 - auc: 0.9229 - prc: 0.7001 - val_loss: 0.0040 - val_precision: 0.8913 - val_recall: 0.5775 - val_auc: 0.9363 - val_prc: 0.7347\n",
            "Epoch 3/30\n",
            "2849/2849 [==============================] - 1s 433us/step - loss: 0.0051 - precision: 0.8784 - recall: 0.5945 - auc: 0.9184 - prc: 0.6942 - val_loss: 0.0039 - val_precision: 0.8718 - val_recall: 0.4789 - val_auc: 0.9364 - val_prc: 0.7398\n",
            "Epoch 4/30\n",
            "2849/2849 [==============================] - 1s 431us/step - loss: 0.0047 - precision: 0.8468 - recall: 0.5732 - auc: 0.9290 - prc: 0.7112 - val_loss: 0.0036 - val_precision: 0.8889 - val_recall: 0.5634 - val_auc: 0.9364 - val_prc: 0.7384\n",
            "Epoch 5/30\n",
            "2849/2849 [==============================] - 1s 434us/step - loss: 0.0047 - precision: 0.8482 - recall: 0.5793 - auc: 0.9274 - prc: 0.7014 - val_loss: 0.0035 - val_precision: 0.8864 - val_recall: 0.5493 - val_auc: 0.9363 - val_prc: 0.7352\n",
            "Epoch 6/30\n",
            "2849/2849 [==============================] - 1s 432us/step - loss: 0.0043 - precision: 0.8584 - recall: 0.6098 - auc: 0.9337 - prc: 0.7408 - val_loss: 0.0035 - val_precision: 0.8913 - val_recall: 0.5775 - val_auc: 0.9363 - val_prc: 0.7382\n",
            "Epoch 7/30\n",
            "2849/2849 [==============================] - 1s 432us/step - loss: 0.0046 - precision: 0.8940 - recall: 0.5915 - auc: 0.9304 - prc: 0.7219 - val_loss: 0.0035 - val_precision: 0.8889 - val_recall: 0.7887 - val_auc: 0.9433 - val_prc: 0.7529\n",
            "Epoch 8/30\n",
            "2849/2849 [==============================] - 1s 451us/step - loss: 0.0040 - precision: 0.8875 - recall: 0.6494 - auc: 0.9396 - prc: 0.7507 - val_loss: 0.0034 - val_precision: 0.9038 - val_recall: 0.6620 - val_auc: 0.9433 - val_prc: 0.7494\n",
            "Epoch 9/30\n",
            "2849/2849 [==============================] - 1s 431us/step - loss: 0.0043 - precision: 0.8686 - recall: 0.6250 - auc: 0.9350 - prc: 0.7329 - val_loss: 0.0035 - val_precision: 0.9074 - val_recall: 0.6901 - val_auc: 0.9363 - val_prc: 0.7433\n",
            "Epoch 10/30\n",
            "2849/2849 [==============================] - 1s 432us/step - loss: 0.0041 - precision: 0.8783 - recall: 0.6159 - auc: 0.9411 - prc: 0.7391 - val_loss: 0.0034 - val_precision: 0.8889 - val_recall: 0.5634 - val_auc: 0.9434 - val_prc: 0.7532\n",
            "Epoch 11/30\n",
            "2849/2849 [==============================] - 1s 429us/step - loss: 0.0039 - precision: 0.8703 - recall: 0.6341 - auc: 0.9396 - prc: 0.7486 - val_loss: 0.0034 - val_precision: 0.8929 - val_recall: 0.7042 - val_auc: 0.9432 - val_prc: 0.7453\n",
            "Epoch 12/30\n",
            "2849/2849 [==============================] - 1s 430us/step - loss: 0.0043 - precision: 0.8625 - recall: 0.6311 - auc: 0.9364 - prc: 0.7260 - val_loss: 0.0036 - val_precision: 0.8378 - val_recall: 0.4366 - val_auc: 0.9433 - val_prc: 0.7658\n",
            "Epoch 13/30\n",
            "2849/2849 [==============================] - 1s 430us/step - loss: 0.0042 - precision: 0.8785 - recall: 0.5732 - auc: 0.9423 - prc: 0.7192 - val_loss: 0.0034 - val_precision: 0.8889 - val_recall: 0.6761 - val_auc: 0.9432 - val_prc: 0.7447\n",
            "Epoch 14/30\n",
            "2849/2849 [==============================] - 1s 430us/step - loss: 0.0043 - precision: 0.8657 - recall: 0.5701 - auc: 0.9484 - prc: 0.7161 - val_loss: 0.0032 - val_precision: 0.9074 - val_recall: 0.6901 - val_auc: 0.9432 - val_prc: 0.7599\n",
            "Epoch 15/30\n",
            "2849/2849 [==============================] - 1s 439us/step - loss: 0.0041 - precision: 0.8739 - recall: 0.5915 - auc: 0.9529 - prc: 0.7462 - val_loss: 0.0033 - val_precision: 0.9038 - val_recall: 0.6620 - val_auc: 0.9434 - val_prc: 0.7552\n",
            "Epoch 16/30\n",
            "2849/2849 [==============================] - 1s 429us/step - loss: 0.0038 - precision: 0.8548 - recall: 0.6463 - auc: 0.9559 - prc: 0.7613 - val_loss: 0.0033 - val_precision: 0.8824 - val_recall: 0.6338 - val_auc: 0.9432 - val_prc: 0.7370\n",
            "Epoch 17/30\n",
            "2849/2849 [==============================] - 1s 429us/step - loss: 0.0039 - precision: 0.8627 - recall: 0.6128 - auc: 0.9422 - prc: 0.7475 - val_loss: 0.0034 - val_precision: 0.9107 - val_recall: 0.7183 - val_auc: 0.9432 - val_prc: 0.7498\n",
            "Epoch 18/30\n",
            "2849/2849 [==============================] - 1s 435us/step - loss: 0.0041 - precision: 0.8816 - recall: 0.6128 - auc: 0.9498 - prc: 0.7414 - val_loss: 0.0033 - val_precision: 0.8980 - val_recall: 0.6197 - val_auc: 0.9434 - val_prc: 0.7590\n",
            "1781/1781 [==============================] - 1s 297us/step - loss: 0.0049 - precision: 0.8219 - recall: 0.6452 - auc: 0.9188 - prc: 0.6993\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "METRICS = [\n",
        "      #keras.metrics.TruePositives(name='tp'),\n",
        "      #keras.metrics.FalsePositives(name='fp'),\n",
        "      #keras.metrics.TrueNegatives(name='tn'),\n",
        "      #keras.metrics.FalseNegatives(name='fn'), \n",
        "      #keras.metrics.BinaryAccuracy(name='accuracy'),\n",
        "      keras.metrics.Precision(name='precision'),\n",
        "      keras.metrics.Recall(name='recall'),\n",
        "      keras.metrics.AUC(name='auc'),\n",
        "      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
        "]\n",
        "\n",
        "initial_bias = np.log([pos/neg])\n",
        "\n",
        "output_bias = tf.keras.initializers.Constant(initial_bias)\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Dense(16, activation='relu',input_shape=(train_features.shape[-1],)))\n",
        "model.add(keras.layers.Dropout(0.5))\n",
        "model.add(keras.layers.Dense(1, activation='sigmoid', bias_initializer=output_bias))\n",
        "model.summary()\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=4, restore_best_weights=True) \n",
        "\n",
        "#model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-3),loss=keras.losses.BinaryCrossentropy(),metrics=metrics)\n",
        "model.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=METRICS)\n",
        "#Fit\n",
        "train_log = model.fit(\n",
        "  train_features,\n",
        "  train_labels,\n",
        "  epochs=30,\n",
        "  batch_size=64,\n",
        "  validation_split=0.2,\n",
        "  callbacks=[callback]\n",
        ")\n",
        "model.evaluate(test_features, test_labels)\n",
        "plot_loss(train_log)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model Structure and Tuning\n",
        "\n",
        "We'll look at tuning neural network models in more depth soon. For now, we can use the results of our model's training and validation scores, along with a few guidelines, to aim us in the correct direction for making a good model. \n",
        "\n",
        "Some guidelines for tuning neural networks are:\n",
        "<ul>\n",
        "<li> Start with something small-ish, and increase as needed. For our exercises, this likely means 2 or 3 hidden layers to start. </li>\n",
        "<li> Use early stopping to find the optimal number of epochs. </li>\n",
        "<li> If the training score is similar to the validation score, the model is probably underfitting. Try things to allow it to learn more:</li>\n",
        "    <ul>\n",
        "    <li> Increasing the number of layers. </li>\n",
        "    <li> Increasing the number of neurons in each layer. </li>\n",
        "    <li> Training for more epochs. </li>\n",
        "    </ul>\n",
        "<li> If the training score is much higher than the validation score, the model is probably overfitting. Try things to prevent it from learning too much:</li>\n",
        "    <ul>\n",
        "    <li> Adding regularization. </li>\n",
        "    <li> Adding dropout. </li>\n",
        "    <li> Reducing the number of layers or the size of the layers. </li>\n",
        "    </ul>\n",
        "<li> If the model's scores seem to flatline, try adding some batch normalization or changing some other optimization-ish option. </li>\n",
        "</ul>\n",
        "\n",
        "These are just guidelines, but they are a good starting point. "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exercise\n",
        "\n",
        "Predict the price of diamonds! (The example solutions are fairly extreme in terms of the approach they take, you'll probably be ok with less dramatic approaches.)\n",
        "\n",
        "![Diamonds](images/diamonds.jpeg \"Diamonds\" )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>carat</th>\n",
              "      <th>depth</th>\n",
              "      <th>table</th>\n",
              "      <th>price</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>z</th>\n",
              "      <th>cut_Ideal</th>\n",
              "      <th>cut_Premium</th>\n",
              "      <th>cut_Very Good</th>\n",
              "      <th>...</th>\n",
              "      <th>color_I</th>\n",
              "      <th>color_J</th>\n",
              "      <th>clarity_IF</th>\n",
              "      <th>clarity_VVS1</th>\n",
              "      <th>clarity_VVS2</th>\n",
              "      <th>clarity_VS1</th>\n",
              "      <th>clarity_VS2</th>\n",
              "      <th>clarity_SI1</th>\n",
              "      <th>clarity_SI2</th>\n",
              "      <th>clarity_I1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.23</td>\n",
              "      <td>61.5</td>\n",
              "      <td>55.0</td>\n",
              "      <td>326</td>\n",
              "      <td>3.95</td>\n",
              "      <td>3.98</td>\n",
              "      <td>2.43</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.21</td>\n",
              "      <td>59.8</td>\n",
              "      <td>61.0</td>\n",
              "      <td>326</td>\n",
              "      <td>3.89</td>\n",
              "      <td>3.84</td>\n",
              "      <td>2.31</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.23</td>\n",
              "      <td>56.9</td>\n",
              "      <td>65.0</td>\n",
              "      <td>327</td>\n",
              "      <td>4.05</td>\n",
              "      <td>4.07</td>\n",
              "      <td>2.31</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.29</td>\n",
              "      <td>62.4</td>\n",
              "      <td>58.0</td>\n",
              "      <td>334</td>\n",
              "      <td>4.20</td>\n",
              "      <td>4.23</td>\n",
              "      <td>2.63</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.31</td>\n",
              "      <td>63.3</td>\n",
              "      <td>58.0</td>\n",
              "      <td>335</td>\n",
              "      <td>4.34</td>\n",
              "      <td>4.35</td>\n",
              "      <td>2.75</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 27 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   carat  depth  table  price     x     y     z  cut_Ideal  cut_Premium  \\\n",
              "0   0.23   61.5   55.0    326  3.95  3.98  2.43       True        False   \n",
              "1   0.21   59.8   61.0    326  3.89  3.84  2.31      False         True   \n",
              "2   0.23   56.9   65.0    327  4.05  4.07  2.31      False        False   \n",
              "3   0.29   62.4   58.0    334  4.20  4.23  2.63      False         True   \n",
              "4   0.31   63.3   58.0    335  4.34  4.35  2.75      False        False   \n",
              "\n",
              "   cut_Very Good  ...  color_I  color_J  clarity_IF  clarity_VVS1  \\\n",
              "0          False  ...    False    False       False         False   \n",
              "1          False  ...    False    False       False         False   \n",
              "2          False  ...    False    False       False         False   \n",
              "3          False  ...     True    False       False         False   \n",
              "4          False  ...    False     True       False         False   \n",
              "\n",
              "   clarity_VVS2  clarity_VS1  clarity_VS2  clarity_SI1  clarity_SI2  \\\n",
              "0         False        False        False        False         True   \n",
              "1         False        False        False         True        False   \n",
              "2         False         True        False        False        False   \n",
              "3         False        False         True        False        False   \n",
              "4         False        False        False        False         True   \n",
              "\n",
              "   clarity_I1  \n",
              "0       False  \n",
              "1       False  \n",
              "2       False  \n",
              "3       False  \n",
              "4       False  \n",
              "\n",
              "[5 rows x 27 columns]"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ex_df = sns.load_dataset(\"diamonds\")\n",
        "ex_df = pd.get_dummies(ex_df)\n",
        "\n",
        "ex_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "26"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y = np.array(ex_df[\"price\"]).astype(np.float32)\n",
        "X = np.array(ex_df.drop(columns={\"price\"})).astype(np.float32)\n",
        "X_tr_ex, X_te_ex, y_tr_ex, y_te_ex = train_test_split(X, y)\n",
        "start_width = X.shape[1]\n",
        "start_width"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>unique</th>\n",
              "      <th>top</th>\n",
              "      <th>freq</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>carat</th>\n",
              "      <td>53940.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.79794</td>\n",
              "      <td>0.474011</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.7</td>\n",
              "      <td>1.04</td>\n",
              "      <td>5.01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>depth</th>\n",
              "      <td>53940.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>61.749405</td>\n",
              "      <td>1.432621</td>\n",
              "      <td>43.0</td>\n",
              "      <td>61.0</td>\n",
              "      <td>61.8</td>\n",
              "      <td>62.5</td>\n",
              "      <td>79.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>table</th>\n",
              "      <td>53940.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>57.457184</td>\n",
              "      <td>2.234491</td>\n",
              "      <td>43.0</td>\n",
              "      <td>56.0</td>\n",
              "      <td>57.0</td>\n",
              "      <td>59.0</td>\n",
              "      <td>95.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>price</th>\n",
              "      <td>53940.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3932.799722</td>\n",
              "      <td>3989.439738</td>\n",
              "      <td>326.0</td>\n",
              "      <td>950.0</td>\n",
              "      <td>2401.0</td>\n",
              "      <td>5324.25</td>\n",
              "      <td>18823.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>x</th>\n",
              "      <td>53940.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.731157</td>\n",
              "      <td>1.121761</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.71</td>\n",
              "      <td>5.7</td>\n",
              "      <td>6.54</td>\n",
              "      <td>10.74</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>y</th>\n",
              "      <td>53940.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.734526</td>\n",
              "      <td>1.142135</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.72</td>\n",
              "      <td>5.71</td>\n",
              "      <td>6.54</td>\n",
              "      <td>58.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>z</th>\n",
              "      <td>53940.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.538734</td>\n",
              "      <td>0.705699</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.91</td>\n",
              "      <td>3.53</td>\n",
              "      <td>4.04</td>\n",
              "      <td>31.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cut_Ideal</th>\n",
              "      <td>53940</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "      <td>32389</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cut_Premium</th>\n",
              "      <td>53940</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "      <td>40149</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cut_Very Good</th>\n",
              "      <td>53940</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "      <td>41858</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cut_Good</th>\n",
              "      <td>53940</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "      <td>49034</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cut_Fair</th>\n",
              "      <td>53940</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "      <td>52330</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>color_D</th>\n",
              "      <td>53940</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "      <td>47165</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>color_E</th>\n",
              "      <td>53940</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "      <td>44143</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>color_F</th>\n",
              "      <td>53940</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "      <td>44398</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>color_G</th>\n",
              "      <td>53940</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "      <td>42648</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>color_H</th>\n",
              "      <td>53940</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "      <td>45636</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>color_I</th>\n",
              "      <td>53940</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "      <td>48518</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>color_J</th>\n",
              "      <td>53940</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "      <td>51132</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>clarity_IF</th>\n",
              "      <td>53940</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "      <td>52150</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>clarity_VVS1</th>\n",
              "      <td>53940</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "      <td>50285</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>clarity_VVS2</th>\n",
              "      <td>53940</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "      <td>48874</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>clarity_VS1</th>\n",
              "      <td>53940</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "      <td>45769</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>clarity_VS2</th>\n",
              "      <td>53940</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "      <td>41682</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>clarity_SI1</th>\n",
              "      <td>53940</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "      <td>40875</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>clarity_SI2</th>\n",
              "      <td>53940</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "      <td>44746</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>clarity_I1</th>\n",
              "      <td>53940</td>\n",
              "      <td>2</td>\n",
              "      <td>False</td>\n",
              "      <td>53199</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 count unique    top   freq         mean          std    min  \\\n",
              "carat          53940.0    NaN    NaN    NaN      0.79794     0.474011    0.2   \n",
              "depth          53940.0    NaN    NaN    NaN    61.749405     1.432621   43.0   \n",
              "table          53940.0    NaN    NaN    NaN    57.457184     2.234491   43.0   \n",
              "price          53940.0    NaN    NaN    NaN  3932.799722  3989.439738  326.0   \n",
              "x              53940.0    NaN    NaN    NaN     5.731157     1.121761    0.0   \n",
              "y              53940.0    NaN    NaN    NaN     5.734526     1.142135    0.0   \n",
              "z              53940.0    NaN    NaN    NaN     3.538734     0.705699    0.0   \n",
              "cut_Ideal        53940      2  False  32389          NaN          NaN    NaN   \n",
              "cut_Premium      53940      2  False  40149          NaN          NaN    NaN   \n",
              "cut_Very Good    53940      2  False  41858          NaN          NaN    NaN   \n",
              "cut_Good         53940      2  False  49034          NaN          NaN    NaN   \n",
              "cut_Fair         53940      2  False  52330          NaN          NaN    NaN   \n",
              "color_D          53940      2  False  47165          NaN          NaN    NaN   \n",
              "color_E          53940      2  False  44143          NaN          NaN    NaN   \n",
              "color_F          53940      2  False  44398          NaN          NaN    NaN   \n",
              "color_G          53940      2  False  42648          NaN          NaN    NaN   \n",
              "color_H          53940      2  False  45636          NaN          NaN    NaN   \n",
              "color_I          53940      2  False  48518          NaN          NaN    NaN   \n",
              "color_J          53940      2  False  51132          NaN          NaN    NaN   \n",
              "clarity_IF       53940      2  False  52150          NaN          NaN    NaN   \n",
              "clarity_VVS1     53940      2  False  50285          NaN          NaN    NaN   \n",
              "clarity_VVS2     53940      2  False  48874          NaN          NaN    NaN   \n",
              "clarity_VS1      53940      2  False  45769          NaN          NaN    NaN   \n",
              "clarity_VS2      53940      2  False  41682          NaN          NaN    NaN   \n",
              "clarity_SI1      53940      2  False  40875          NaN          NaN    NaN   \n",
              "clarity_SI2      53940      2  False  44746          NaN          NaN    NaN   \n",
              "clarity_I1       53940      2  False  53199          NaN          NaN    NaN   \n",
              "\n",
              "                 25%     50%      75%      max  \n",
              "carat            0.4     0.7     1.04     5.01  \n",
              "depth           61.0    61.8     62.5     79.0  \n",
              "table           56.0    57.0     59.0     95.0  \n",
              "price          950.0  2401.0  5324.25  18823.0  \n",
              "x               4.71     5.7     6.54    10.74  \n",
              "y               4.72    5.71     6.54     58.9  \n",
              "z               2.91    3.53     4.04     31.8  \n",
              "cut_Ideal        NaN     NaN      NaN      NaN  \n",
              "cut_Premium      NaN     NaN      NaN      NaN  \n",
              "cut_Very Good    NaN     NaN      NaN      NaN  \n",
              "cut_Good         NaN     NaN      NaN      NaN  \n",
              "cut_Fair         NaN     NaN      NaN      NaN  \n",
              "color_D          NaN     NaN      NaN      NaN  \n",
              "color_E          NaN     NaN      NaN      NaN  \n",
              "color_F          NaN     NaN      NaN      NaN  \n",
              "color_G          NaN     NaN      NaN      NaN  \n",
              "color_H          NaN     NaN      NaN      NaN  \n",
              "color_I          NaN     NaN      NaN      NaN  \n",
              "color_J          NaN     NaN      NaN      NaN  \n",
              "clarity_IF       NaN     NaN      NaN      NaN  \n",
              "clarity_VVS1     NaN     NaN      NaN      NaN  \n",
              "clarity_VVS2     NaN     NaN      NaN      NaN  \n",
              "clarity_VS1      NaN     NaN      NaN      NaN  \n",
              "clarity_VS2      NaN     NaN      NaN      NaN  \n",
              "clarity_SI1      NaN     NaN      NaN      NaN  \n",
              "clarity_SI2      NaN     NaN      NaN      NaN  \n",
              "clarity_I1       NaN     NaN      NaN      NaN  "
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ex_df.describe(include=\"all\").T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Generate a Baseline\n",
        "\n",
        "I'll use a different loss - mean absolute percentage. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "422/422 [==============================] - 0s 233us/step - loss: 9.4137\n",
            "9.413739204406738\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#baseline\n",
        "normalizer = tf.keras.layers.Normalization(axis=-1)\n",
        "normalizer.adapt(np.array(X_tr_ex))\n",
        "\n",
        "mod_ex = keras.Sequential()\n",
        "mod_ex.add(normalizer)\n",
        "mod_ex.add(InputLayer(input_shape=(start_width,)))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dense(1))\n",
        "\n",
        "mod_ex.compile(optimizer='adam', loss=\"mean_absolute_percentage_error\")\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=12, restore_best_weights=True) \n",
        "\n",
        "hist_ex = mod_ex.fit(\n",
        "  X_tr_ex,\n",
        "  y_tr_ex,\n",
        "  epochs=100,\n",
        "  batch_size=64,\n",
        "  validation_split=0.2,\n",
        "  callbacks=[callback],\n",
        "  verbose=0\n",
        ")\n",
        "print(mod_ex.evaluate(X_te_ex, y_te_ex))\n",
        "plot_loss(hist_ex)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Attempt Optimization\n",
        "\n",
        "Looks like lots of loss! What to do?\n",
        "\n",
        "Things to try:\n",
        "<ol>\n",
        "<li> Depth.\n",
        "<li> Width. \n",
        "<li> Activations. \n",
        "<li> Batches. \n",
        "</ol>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "422/422 [==============================] - 0s 309us/step - loss: 6.4728\n",
            "6.47279167175293\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Comically Deep Model\n",
        "normalizer = tf.keras.layers.Normalization(axis=-1)\n",
        "normalizer.adapt(np.array(X_tr_ex))\n",
        "\n",
        "mod_ex = keras.Sequential()\n",
        "mod_ex.add(normalizer)\n",
        "mod_ex.add(InputLayer(input_shape=(start_width,)))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dense(1))\n",
        "\n",
        "mod_ex.compile(optimizer='adam', loss=\"mean_absolute_percentage_error\")\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True) \n",
        "\n",
        "hist_ex = mod_ex.fit(\n",
        "  X_tr_ex,\n",
        "  y_tr_ex,\n",
        "  epochs=1000,\n",
        "  batch_size=64,\n",
        "  validation_split=0.2,\n",
        "  callbacks=[callback],\n",
        "  verbose=0\n",
        ")\n",
        "print(mod_ex.evaluate(X_te_ex, y_te_ex))\n",
        "plot_loss(hist_ex)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Try Adding Dropouts\n",
        "\n",
        "We don't have a bunch of overfitting, so we may not expect miracles here... "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "422/422 [==============================] - 0s 280us/step - loss: 43.5719\n",
            "43.57194519042969\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Comically Deep Model with Dropouts\n",
        "normalizer = tf.keras.layers.Normalization(axis=-1)\n",
        "normalizer.adapt(np.array(X_tr_ex))\n",
        "\n",
        "mod_ex = keras.Sequential()\n",
        "mod_ex.add(normalizer)\n",
        "mod_ex.add(InputLayer(input_shape=(start_width,)))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dropout(.2))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dropout(.2))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dropout(.2))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dropout(.2))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dropout(.2))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dropout(.2))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dropout(.2))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dropout(.2))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dropout(.2))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dropout(.2))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dense(1))\n",
        "\n",
        "mod_ex.compile(optimizer='adam', loss=\"mean_absolute_percentage_error\")\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True) \n",
        "\n",
        "hist_ex = mod_ex.fit(\n",
        "  X_tr_ex,\n",
        "  y_tr_ex,\n",
        "  epochs=200,\n",
        "  batch_size=4048,\n",
        "  validation_split=0.2,\n",
        "  callbacks=[callback],\n",
        "  verbose=0\n",
        ")\n",
        "print(mod_ex.evaluate(X_te_ex, y_te_ex))\n",
        "plot_loss(hist_ex)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Taper Model Somewhat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "506/506 [==============================] - 1s 735us/step - loss: 54.4815 - mean_squared_error: 18469084.0000 - mean_absolute_error: 2539.8125 - mean_absolute_percentage_error: 54.4815 - val_loss: 16.0361 - val_mean_squared_error: 2205936.7500 - val_mean_absolute_error: 687.8245 - val_mean_absolute_percentage_error: 16.0361\n",
            "Epoch 2/1000\n",
            "506/506 [==============================] - 0s 567us/step - loss: 13.2684 - mean_squared_error: 1592866.1250 - mean_absolute_error: 574.2430 - mean_absolute_percentage_error: 13.2684 - val_loss: 12.1257 - val_mean_squared_error: 1523874.1250 - val_mean_absolute_error: 514.1353 - val_mean_absolute_percentage_error: 12.1257\n",
            "Epoch 3/1000\n",
            "506/506 [==============================] - 0s 565us/step - loss: 11.3960 - mean_squared_error: 1303480.6250 - mean_absolute_error: 501.6617 - mean_absolute_percentage_error: 11.3960 - val_loss: 11.3132 - val_mean_squared_error: 1300195.7500 - val_mean_absolute_error: 463.3058 - val_mean_absolute_percentage_error: 11.3132\n",
            "Epoch 4/1000\n",
            "506/506 [==============================] - 0s 566us/step - loss: 10.7097 - mean_squared_error: 1157387.2500 - mean_absolute_error: 470.1126 - mean_absolute_percentage_error: 10.7097 - val_loss: 10.7892 - val_mean_squared_error: 1291829.5000 - val_mean_absolute_error: 458.8971 - val_mean_absolute_percentage_error: 10.7892\n",
            "Epoch 5/1000\n",
            "506/506 [==============================] - 0s 568us/step - loss: 10.2845 - mean_squared_error: 1059659.0000 - mean_absolute_error: 447.9543 - mean_absolute_percentage_error: 10.2845 - val_loss: 10.4747 - val_mean_squared_error: 1138137.5000 - val_mean_absolute_error: 423.3940 - val_mean_absolute_percentage_error: 10.4747\n",
            "Epoch 6/1000\n",
            "506/506 [==============================] - 0s 568us/step - loss: 9.9955 - mean_squared_error: 972102.6250 - mean_absolute_error: 428.1541 - mean_absolute_percentage_error: 9.9955 - val_loss: 10.2941 - val_mean_squared_error: 1071776.8750 - val_mean_absolute_error: 409.2859 - val_mean_absolute_percentage_error: 10.2941\n",
            "Epoch 7/1000\n",
            "506/506 [==============================] - 0s 566us/step - loss: 9.7520 - mean_squared_error: 908035.9375 - mean_absolute_error: 413.8818 - mean_absolute_percentage_error: 9.7520 - val_loss: 10.0690 - val_mean_squared_error: 1067738.5000 - val_mean_absolute_error: 411.6892 - val_mean_absolute_percentage_error: 10.0690\n",
            "Epoch 8/1000\n",
            "506/506 [==============================] - 0s 567us/step - loss: 9.5399 - mean_squared_error: 858493.9375 - mean_absolute_error: 400.2794 - mean_absolute_percentage_error: 9.5399 - val_loss: 9.8803 - val_mean_squared_error: 977444.4375 - val_mean_absolute_error: 386.8122 - val_mean_absolute_percentage_error: 9.8803\n",
            "Epoch 9/1000\n",
            "506/506 [==============================] - 0s 567us/step - loss: 9.3906 - mean_squared_error: 811468.7500 - mean_absolute_error: 389.0594 - mean_absolute_percentage_error: 9.3906 - val_loss: 9.6995 - val_mean_squared_error: 941598.5000 - val_mean_absolute_error: 381.9110 - val_mean_absolute_percentage_error: 9.6995\n",
            "Epoch 10/1000\n",
            "506/506 [==============================] - 0s 564us/step - loss: 9.2546 - mean_squared_error: 760412.0000 - mean_absolute_error: 378.8214 - mean_absolute_percentage_error: 9.2546 - val_loss: 9.7202 - val_mean_squared_error: 909921.6875 - val_mean_absolute_error: 378.4753 - val_mean_absolute_percentage_error: 9.7202\n",
            "Epoch 11/1000\n",
            "506/506 [==============================] - 0s 575us/step - loss: 9.1438 - mean_squared_error: 733192.6250 - mean_absolute_error: 371.3824 - mean_absolute_percentage_error: 9.1438 - val_loss: 9.5591 - val_mean_squared_error: 864906.5000 - val_mean_absolute_error: 363.2254 - val_mean_absolute_percentage_error: 9.5591\n",
            "Epoch 12/1000\n",
            "506/506 [==============================] - 0s 565us/step - loss: 9.0569 - mean_squared_error: 701940.2500 - mean_absolute_error: 365.0106 - mean_absolute_percentage_error: 9.0569 - val_loss: 9.4189 - val_mean_squared_error: 841192.0000 - val_mean_absolute_error: 358.4980 - val_mean_absolute_percentage_error: 9.4189\n",
            "Epoch 13/1000\n",
            "506/506 [==============================] - 0s 567us/step - loss: 8.9607 - mean_squared_error: 677415.9375 - mean_absolute_error: 359.4433 - mean_absolute_percentage_error: 8.9607 - val_loss: 9.4308 - val_mean_squared_error: 840289.8750 - val_mean_absolute_error: 365.4024 - val_mean_absolute_percentage_error: 9.4308\n",
            "Epoch 14/1000\n",
            "506/506 [==============================] - 0s 573us/step - loss: 8.9431 - mean_squared_error: 665889.7500 - mean_absolute_error: 356.6853 - mean_absolute_percentage_error: 8.9431 - val_loss: 9.2774 - val_mean_squared_error: 824545.4375 - val_mean_absolute_error: 359.9996 - val_mean_absolute_percentage_error: 9.2774\n",
            "Epoch 15/1000\n",
            "506/506 [==============================] - 0s 575us/step - loss: 8.8889 - mean_squared_error: 641405.4375 - mean_absolute_error: 354.8013 - mean_absolute_percentage_error: 8.8889 - val_loss: 9.1420 - val_mean_squared_error: 799947.4375 - val_mean_absolute_error: 351.6982 - val_mean_absolute_percentage_error: 9.1420\n",
            "Epoch 16/1000\n",
            "506/506 [==============================] - 0s 569us/step - loss: 8.8206 - mean_squared_error: 620410.6250 - mean_absolute_error: 351.3549 - mean_absolute_percentage_error: 8.8206 - val_loss: 9.1470 - val_mean_squared_error: 784260.7500 - val_mean_absolute_error: 344.1608 - val_mean_absolute_percentage_error: 9.1470\n",
            "Epoch 17/1000\n",
            "506/506 [==============================] - 0s 568us/step - loss: 8.7845 - mean_squared_error: 604050.4375 - mean_absolute_error: 349.1706 - mean_absolute_percentage_error: 8.7845 - val_loss: 9.2885 - val_mean_squared_error: 780372.6875 - val_mean_absolute_error: 345.6145 - val_mean_absolute_percentage_error: 9.2885\n",
            "Epoch 18/1000\n",
            "506/506 [==============================] - 0s 570us/step - loss: 8.7944 - mean_squared_error: 599898.1250 - mean_absolute_error: 348.5774 - mean_absolute_percentage_error: 8.7944 - val_loss: 9.1438 - val_mean_squared_error: 771184.1250 - val_mean_absolute_error: 348.6828 - val_mean_absolute_percentage_error: 9.1438\n",
            "Epoch 19/1000\n",
            "506/506 [==============================] - 0s 574us/step - loss: 8.7496 - mean_squared_error: 583699.7500 - mean_absolute_error: 346.6250 - mean_absolute_percentage_error: 8.7496 - val_loss: 9.2754 - val_mean_squared_error: 766986.2500 - val_mean_absolute_error: 340.9431 - val_mean_absolute_percentage_error: 9.2754\n",
            "Epoch 20/1000\n",
            "506/506 [==============================] - 0s 572us/step - loss: 8.7217 - mean_squared_error: 582612.4375 - mean_absolute_error: 345.3839 - mean_absolute_percentage_error: 8.7217 - val_loss: 9.0738 - val_mean_squared_error: 755197.3125 - val_mean_absolute_error: 338.6769 - val_mean_absolute_percentage_error: 9.0738\n",
            "Epoch 21/1000\n",
            "506/506 [==============================] - 0s 572us/step - loss: 8.7107 - mean_squared_error: 556970.6875 - mean_absolute_error: 343.7994 - mean_absolute_percentage_error: 8.7107 - val_loss: 9.0322 - val_mean_squared_error: 751138.8750 - val_mean_absolute_error: 344.1812 - val_mean_absolute_percentage_error: 9.0322\n",
            "Epoch 22/1000\n",
            "506/506 [==============================] - 0s 570us/step - loss: 8.6641 - mean_squared_error: 552667.0000 - mean_absolute_error: 342.1653 - mean_absolute_percentage_error: 8.6641 - val_loss: 8.9862 - val_mean_squared_error: 744498.9375 - val_mean_absolute_error: 338.0939 - val_mean_absolute_percentage_error: 8.9862\n",
            "Epoch 23/1000\n",
            "506/506 [==============================] - 0s 569us/step - loss: 8.6465 - mean_squared_error: 545872.8125 - mean_absolute_error: 341.2813 - mean_absolute_percentage_error: 8.6465 - val_loss: 8.9859 - val_mean_squared_error: 744108.1250 - val_mean_absolute_error: 336.6740 - val_mean_absolute_percentage_error: 8.9859\n",
            "Epoch 24/1000\n",
            "506/506 [==============================] - 0s 575us/step - loss: 8.6074 - mean_squared_error: 534492.9375 - mean_absolute_error: 339.4680 - mean_absolute_percentage_error: 8.6074 - val_loss: 8.9771 - val_mean_squared_error: 735400.8125 - val_mean_absolute_error: 340.3418 - val_mean_absolute_percentage_error: 8.9771\n",
            "Epoch 25/1000\n",
            "506/506 [==============================] - 0s 619us/step - loss: 8.5966 - mean_squared_error: 522608.3125 - mean_absolute_error: 338.6613 - mean_absolute_percentage_error: 8.5966 - val_loss: 9.0004 - val_mean_squared_error: 731279.6250 - val_mean_absolute_error: 338.0287 - val_mean_absolute_percentage_error: 9.0004\n",
            "Epoch 26/1000\n",
            "506/506 [==============================] - 0s 602us/step - loss: 8.5897 - mean_squared_error: 515288.5000 - mean_absolute_error: 338.7601 - mean_absolute_percentage_error: 8.5897 - val_loss: 8.9484 - val_mean_squared_error: 725805.1875 - val_mean_absolute_error: 334.1526 - val_mean_absolute_percentage_error: 8.9484\n",
            "Epoch 27/1000\n",
            "506/506 [==============================] - 0s 686us/step - loss: 8.5266 - mean_squared_error: 511992.1562 - mean_absolute_error: 336.2967 - mean_absolute_percentage_error: 8.5266 - val_loss: 9.0098 - val_mean_squared_error: 738132.0625 - val_mean_absolute_error: 332.7704 - val_mean_absolute_percentage_error: 9.0098\n",
            "Epoch 28/1000\n",
            "506/506 [==============================] - 0s 650us/step - loss: 8.5359 - mean_squared_error: 507444.8750 - mean_absolute_error: 335.8871 - mean_absolute_percentage_error: 8.5359 - val_loss: 8.9102 - val_mean_squared_error: 722427.6250 - val_mean_absolute_error: 329.6354 - val_mean_absolute_percentage_error: 8.9102\n",
            "Epoch 29/1000\n",
            "506/506 [==============================] - 0s 621us/step - loss: 8.5028 - mean_squared_error: 503392.2500 - mean_absolute_error: 334.4800 - mean_absolute_percentage_error: 8.5028 - val_loss: 8.9445 - val_mean_squared_error: 710456.1875 - val_mean_absolute_error: 334.9478 - val_mean_absolute_percentage_error: 8.9445\n",
            "Epoch 30/1000\n",
            "506/506 [==============================] - 0s 638us/step - loss: 8.4779 - mean_squared_error: 498963.0938 - mean_absolute_error: 333.8994 - mean_absolute_percentage_error: 8.4779 - val_loss: 8.8979 - val_mean_squared_error: 703145.5000 - val_mean_absolute_error: 329.8627 - val_mean_absolute_percentage_error: 8.8979\n",
            "Epoch 31/1000\n",
            "506/506 [==============================] - 0s 592us/step - loss: 8.4682 - mean_squared_error: 495151.0000 - mean_absolute_error: 333.2012 - mean_absolute_percentage_error: 8.4682 - val_loss: 8.9342 - val_mean_squared_error: 707911.6250 - val_mean_absolute_error: 342.6160 - val_mean_absolute_percentage_error: 8.9342\n",
            "Epoch 32/1000\n",
            "506/506 [==============================] - 0s 574us/step - loss: 8.4682 - mean_squared_error: 491482.5625 - mean_absolute_error: 333.3511 - mean_absolute_percentage_error: 8.4682 - val_loss: 8.8253 - val_mean_squared_error: 695120.0625 - val_mean_absolute_error: 332.9855 - val_mean_absolute_percentage_error: 8.8253\n",
            "Epoch 33/1000\n",
            "506/506 [==============================] - 0s 590us/step - loss: 8.4037 - mean_squared_error: 484434.8125 - mean_absolute_error: 330.7472 - mean_absolute_percentage_error: 8.4037 - val_loss: 8.9988 - val_mean_squared_error: 698818.0625 - val_mean_absolute_error: 346.8756 - val_mean_absolute_percentage_error: 8.9988\n",
            "Epoch 34/1000\n",
            "506/506 [==============================] - 0s 571us/step - loss: 8.4405 - mean_squared_error: 483188.2188 - mean_absolute_error: 331.6202 - mean_absolute_percentage_error: 8.4405 - val_loss: 8.9072 - val_mean_squared_error: 692234.2500 - val_mean_absolute_error: 329.5137 - val_mean_absolute_percentage_error: 8.9072\n",
            "Epoch 35/1000\n",
            "506/506 [==============================] - 0s 571us/step - loss: 8.3747 - mean_squared_error: 475170.0000 - mean_absolute_error: 328.7707 - mean_absolute_percentage_error: 8.3747 - val_loss: 8.8063 - val_mean_squared_error: 686777.7500 - val_mean_absolute_error: 326.8344 - val_mean_absolute_percentage_error: 8.8063\n",
            "Epoch 36/1000\n",
            "506/506 [==============================] - 0s 571us/step - loss: 8.3748 - mean_squared_error: 470633.2500 - mean_absolute_error: 329.1226 - mean_absolute_percentage_error: 8.3748 - val_loss: 9.0625 - val_mean_squared_error: 685369.0000 - val_mean_absolute_error: 345.6670 - val_mean_absolute_percentage_error: 9.0625\n",
            "Epoch 37/1000\n",
            "506/506 [==============================] - 0s 567us/step - loss: 8.3620 - mean_squared_error: 467731.5000 - mean_absolute_error: 328.8863 - mean_absolute_percentage_error: 8.3620 - val_loss: 8.8583 - val_mean_squared_error: 678223.3125 - val_mean_absolute_error: 326.5231 - val_mean_absolute_percentage_error: 8.8583\n",
            "Epoch 38/1000\n",
            "506/506 [==============================] - 0s 570us/step - loss: 8.3645 - mean_squared_error: 466220.9375 - mean_absolute_error: 328.6565 - mean_absolute_percentage_error: 8.3645 - val_loss: 8.7064 - val_mean_squared_error: 669687.1875 - val_mean_absolute_error: 326.9115 - val_mean_absolute_percentage_error: 8.7064\n",
            "Epoch 39/1000\n",
            "506/506 [==============================] - 0s 567us/step - loss: 8.3416 - mean_squared_error: 462399.6875 - mean_absolute_error: 328.3898 - mean_absolute_percentage_error: 8.3416 - val_loss: 8.7204 - val_mean_squared_error: 659679.8750 - val_mean_absolute_error: 329.2634 - val_mean_absolute_percentage_error: 8.7204\n",
            "Epoch 40/1000\n",
            "506/506 [==============================] - 0s 570us/step - loss: 8.3165 - mean_squared_error: 458826.7188 - mean_absolute_error: 326.7855 - mean_absolute_percentage_error: 8.3165 - val_loss: 8.6848 - val_mean_squared_error: 664495.6875 - val_mean_absolute_error: 324.7596 - val_mean_absolute_percentage_error: 8.6848\n",
            "Epoch 41/1000\n",
            "506/506 [==============================] - 0s 570us/step - loss: 8.3117 - mean_squared_error: 460027.0312 - mean_absolute_error: 327.0074 - mean_absolute_percentage_error: 8.3117 - val_loss: 8.6915 - val_mean_squared_error: 660795.5625 - val_mean_absolute_error: 324.6264 - val_mean_absolute_percentage_error: 8.6915\n",
            "Epoch 42/1000\n",
            "506/506 [==============================] - 0s 657us/step - loss: 8.3280 - mean_squared_error: 454111.2812 - mean_absolute_error: 326.6809 - mean_absolute_percentage_error: 8.3280 - val_loss: 8.7036 - val_mean_squared_error: 654535.2500 - val_mean_absolute_error: 328.4243 - val_mean_absolute_percentage_error: 8.7036\n",
            "Epoch 43/1000\n",
            "506/506 [==============================] - 0s 640us/step - loss: 8.2790 - mean_squared_error: 452650.1562 - mean_absolute_error: 325.9442 - mean_absolute_percentage_error: 8.2790 - val_loss: 8.7100 - val_mean_squared_error: 655751.5625 - val_mean_absolute_error: 325.0793 - val_mean_absolute_percentage_error: 8.7100\n",
            "Epoch 44/1000\n",
            "506/506 [==============================] - 0s 597us/step - loss: 8.2845 - mean_squared_error: 450537.5625 - mean_absolute_error: 325.9264 - mean_absolute_percentage_error: 8.2845 - val_loss: 8.6508 - val_mean_squared_error: 673794.5000 - val_mean_absolute_error: 322.6042 - val_mean_absolute_percentage_error: 8.6508\n",
            "Epoch 45/1000\n",
            "506/506 [==============================] - 0s 568us/step - loss: 8.2702 - mean_squared_error: 450594.2500 - mean_absolute_error: 325.7664 - mean_absolute_percentage_error: 8.2702 - val_loss: 8.6882 - val_mean_squared_error: 652134.0625 - val_mean_absolute_error: 326.2504 - val_mean_absolute_percentage_error: 8.6882\n",
            "Epoch 46/1000\n",
            "506/506 [==============================] - 0s 568us/step - loss: 8.2587 - mean_squared_error: 448381.9375 - mean_absolute_error: 325.2352 - mean_absolute_percentage_error: 8.2587 - val_loss: 8.7186 - val_mean_squared_error: 656619.1875 - val_mean_absolute_error: 323.5815 - val_mean_absolute_percentage_error: 8.7186\n",
            "Epoch 47/1000\n",
            "506/506 [==============================] - 0s 577us/step - loss: 8.2395 - mean_squared_error: 447171.8125 - mean_absolute_error: 325.2769 - mean_absolute_percentage_error: 8.2395 - val_loss: 8.9479 - val_mean_squared_error: 658312.6875 - val_mean_absolute_error: 340.3179 - val_mean_absolute_percentage_error: 8.9479\n",
            "Epoch 48/1000\n",
            "506/506 [==============================] - 0s 570us/step - loss: 8.2666 - mean_squared_error: 446173.1875 - mean_absolute_error: 325.9579 - mean_absolute_percentage_error: 8.2666 - val_loss: 8.6229 - val_mean_squared_error: 649104.5000 - val_mean_absolute_error: 326.3205 - val_mean_absolute_percentage_error: 8.6229\n",
            "Epoch 49/1000\n",
            "506/506 [==============================] - 0s 568us/step - loss: 8.2288 - mean_squared_error: 447541.0938 - mean_absolute_error: 324.9478 - mean_absolute_percentage_error: 8.2288 - val_loss: 8.6586 - val_mean_squared_error: 646460.6875 - val_mean_absolute_error: 324.7182 - val_mean_absolute_percentage_error: 8.6586\n",
            "Epoch 50/1000\n",
            "506/506 [==============================] - 0s 567us/step - loss: 8.2412 - mean_squared_error: 445422.3750 - mean_absolute_error: 324.5599 - mean_absolute_percentage_error: 8.2412 - val_loss: 8.9820 - val_mean_squared_error: 651091.1250 - val_mean_absolute_error: 323.9381 - val_mean_absolute_percentage_error: 8.9820\n",
            "Epoch 51/1000\n",
            "506/506 [==============================] - 0s 630us/step - loss: 8.2304 - mean_squared_error: 441919.1875 - mean_absolute_error: 325.3688 - mean_absolute_percentage_error: 8.2304 - val_loss: 8.6338 - val_mean_squared_error: 646302.6250 - val_mean_absolute_error: 322.3130 - val_mean_absolute_percentage_error: 8.6338\n",
            "Epoch 52/1000\n",
            "506/506 [==============================] - 0s 568us/step - loss: 8.2029 - mean_squared_error: 444073.6250 - mean_absolute_error: 324.4441 - mean_absolute_percentage_error: 8.2029 - val_loss: 8.8150 - val_mean_squared_error: 644972.3125 - val_mean_absolute_error: 333.1676 - val_mean_absolute_percentage_error: 8.8150\n",
            "Epoch 53/1000\n",
            "506/506 [==============================] - 0s 567us/step - loss: 8.2065 - mean_squared_error: 441377.6875 - mean_absolute_error: 323.5868 - mean_absolute_percentage_error: 8.2065 - val_loss: 8.5925 - val_mean_squared_error: 645589.3750 - val_mean_absolute_error: 326.2293 - val_mean_absolute_percentage_error: 8.5925\n",
            "Epoch 54/1000\n",
            "506/506 [==============================] - 0s 567us/step - loss: 8.2057 - mean_squared_error: 439744.0625 - mean_absolute_error: 324.5112 - mean_absolute_percentage_error: 8.2057 - val_loss: 8.5914 - val_mean_squared_error: 642961.1250 - val_mean_absolute_error: 323.7164 - val_mean_absolute_percentage_error: 8.5914\n",
            "Epoch 55/1000\n",
            "506/506 [==============================] - 0s 568us/step - loss: 8.1834 - mean_squared_error: 437360.0625 - mean_absolute_error: 323.4091 - mean_absolute_percentage_error: 8.1834 - val_loss: 8.5913 - val_mean_squared_error: 647789.5000 - val_mean_absolute_error: 322.5010 - val_mean_absolute_percentage_error: 8.5913\n",
            "Epoch 56/1000\n",
            "506/506 [==============================] - 0s 565us/step - loss: 8.1790 - mean_squared_error: 439328.9688 - mean_absolute_error: 323.9560 - mean_absolute_percentage_error: 8.1790 - val_loss: 8.6571 - val_mean_squared_error: 653257.0625 - val_mean_absolute_error: 323.5768 - val_mean_absolute_percentage_error: 8.6571\n",
            "Epoch 57/1000\n",
            "506/506 [==============================] - 0s 568us/step - loss: 8.1813 - mean_squared_error: 439198.6562 - mean_absolute_error: 324.2594 - mean_absolute_percentage_error: 8.1813 - val_loss: 8.5850 - val_mean_squared_error: 636189.8750 - val_mean_absolute_error: 327.8565 - val_mean_absolute_percentage_error: 8.5850\n",
            "Epoch 58/1000\n",
            "506/506 [==============================] - 0s 566us/step - loss: 8.1662 - mean_squared_error: 437382.1250 - mean_absolute_error: 323.4903 - mean_absolute_percentage_error: 8.1662 - val_loss: 8.6358 - val_mean_squared_error: 636685.0625 - val_mean_absolute_error: 325.0025 - val_mean_absolute_percentage_error: 8.6358\n",
            "Epoch 59/1000\n",
            "506/506 [==============================] - 0s 567us/step - loss: 8.1513 - mean_squared_error: 434554.1250 - mean_absolute_error: 322.6978 - mean_absolute_percentage_error: 8.1513 - val_loss: 8.9427 - val_mean_squared_error: 665075.2500 - val_mean_absolute_error: 327.7618 - val_mean_absolute_percentage_error: 8.9427\n",
            "Epoch 60/1000\n",
            "506/506 [==============================] - 0s 569us/step - loss: 8.1590 - mean_squared_error: 436496.4062 - mean_absolute_error: 322.8047 - mean_absolute_percentage_error: 8.1590 - val_loss: 8.4744 - val_mean_squared_error: 626284.5000 - val_mean_absolute_error: 322.5055 - val_mean_absolute_percentage_error: 8.4744\n",
            "Epoch 61/1000\n",
            "506/506 [==============================] - 0s 567us/step - loss: 8.1322 - mean_squared_error: 434169.6250 - mean_absolute_error: 322.3282 - mean_absolute_percentage_error: 8.1322 - val_loss: 8.5232 - val_mean_squared_error: 624194.5000 - val_mean_absolute_error: 325.2736 - val_mean_absolute_percentage_error: 8.5232\n",
            "Epoch 62/1000\n",
            "506/506 [==============================] - 0s 567us/step - loss: 8.1833 - mean_squared_error: 433762.4375 - mean_absolute_error: 324.5276 - mean_absolute_percentage_error: 8.1833 - val_loss: 8.6364 - val_mean_squared_error: 627520.9375 - val_mean_absolute_error: 327.5645 - val_mean_absolute_percentage_error: 8.6364\n",
            "Epoch 63/1000\n",
            "506/506 [==============================] - 0s 569us/step - loss: 8.1196 - mean_squared_error: 431693.8750 - mean_absolute_error: 322.6628 - mean_absolute_percentage_error: 8.1196 - val_loss: 8.9176 - val_mean_squared_error: 637104.5625 - val_mean_absolute_error: 346.1197 - val_mean_absolute_percentage_error: 8.9176\n",
            "Epoch 64/1000\n",
            "506/506 [==============================] - 0s 565us/step - loss: 8.1229 - mean_squared_error: 431350.6562 - mean_absolute_error: 322.2885 - mean_absolute_percentage_error: 8.1229 - val_loss: 8.5096 - val_mean_squared_error: 627648.3125 - val_mean_absolute_error: 321.8983 - val_mean_absolute_percentage_error: 8.5096\n",
            "Epoch 65/1000\n",
            "506/506 [==============================] - 0s 582us/step - loss: 8.0986 - mean_squared_error: 431739.1562 - mean_absolute_error: 322.1916 - mean_absolute_percentage_error: 8.0986 - val_loss: 8.5269 - val_mean_squared_error: 620131.6875 - val_mean_absolute_error: 324.8522 - val_mean_absolute_percentage_error: 8.5269\n",
            "Epoch 66/1000\n",
            "506/506 [==============================] - 0s 570us/step - loss: 8.1195 - mean_squared_error: 429102.1562 - mean_absolute_error: 322.2493 - mean_absolute_percentage_error: 8.1195 - val_loss: 8.6240 - val_mean_squared_error: 627166.0000 - val_mean_absolute_error: 337.0197 - val_mean_absolute_percentage_error: 8.6240\n",
            "Epoch 67/1000\n",
            "506/506 [==============================] - 0s 568us/step - loss: 8.1329 - mean_squared_error: 433800.4062 - mean_absolute_error: 323.5919 - mean_absolute_percentage_error: 8.1329 - val_loss: 8.5934 - val_mean_squared_error: 617385.1250 - val_mean_absolute_error: 329.5161 - val_mean_absolute_percentage_error: 8.5934\n",
            "Epoch 68/1000\n",
            "506/506 [==============================] - 0s 702us/step - loss: 8.0747 - mean_squared_error: 427786.2188 - mean_absolute_error: 321.5668 - mean_absolute_percentage_error: 8.0747 - val_loss: 8.4632 - val_mean_squared_error: 626941.2500 - val_mean_absolute_error: 319.8487 - val_mean_absolute_percentage_error: 8.4632\n",
            "Epoch 69/1000\n",
            "506/506 [==============================] - 0s 611us/step - loss: 8.1148 - mean_squared_error: 429113.8750 - mean_absolute_error: 322.7926 - mean_absolute_percentage_error: 8.1148 - val_loss: 8.5047 - val_mean_squared_error: 620809.5000 - val_mean_absolute_error: 321.8613 - val_mean_absolute_percentage_error: 8.5047\n",
            "Epoch 70/1000\n",
            "506/506 [==============================] - 0s 583us/step - loss: 8.0990 - mean_squared_error: 427672.0312 - mean_absolute_error: 321.9008 - mean_absolute_percentage_error: 8.0990 - val_loss: 8.5811 - val_mean_squared_error: 614033.7500 - val_mean_absolute_error: 330.4907 - val_mean_absolute_percentage_error: 8.5811\n",
            "Epoch 71/1000\n",
            "506/506 [==============================] - 0s 569us/step - loss: 8.0556 - mean_squared_error: 427482.9375 - mean_absolute_error: 321.2232 - mean_absolute_percentage_error: 8.0556 - val_loss: 8.4250 - val_mean_squared_error: 618770.1875 - val_mean_absolute_error: 320.3893 - val_mean_absolute_percentage_error: 8.4250\n",
            "Epoch 72/1000\n",
            "506/506 [==============================] - 0s 567us/step - loss: 8.0848 - mean_squared_error: 429456.4375 - mean_absolute_error: 322.3770 - mean_absolute_percentage_error: 8.0848 - val_loss: 8.4548 - val_mean_squared_error: 631489.5625 - val_mean_absolute_error: 320.7821 - val_mean_absolute_percentage_error: 8.4548\n",
            "Epoch 73/1000\n",
            "506/506 [==============================] - 0s 569us/step - loss: 8.0748 - mean_squared_error: 428762.1250 - mean_absolute_error: 322.0883 - mean_absolute_percentage_error: 8.0748 - val_loss: 8.4026 - val_mean_squared_error: 613677.9375 - val_mean_absolute_error: 320.8519 - val_mean_absolute_percentage_error: 8.4026\n",
            "Epoch 74/1000\n",
            "506/506 [==============================] - 0s 567us/step - loss: 8.0590 - mean_squared_error: 425587.1250 - mean_absolute_error: 321.3367 - mean_absolute_percentage_error: 8.0590 - val_loss: 8.3960 - val_mean_squared_error: 608271.6250 - val_mean_absolute_error: 321.0370 - val_mean_absolute_percentage_error: 8.3960\n",
            "Epoch 75/1000\n",
            "506/506 [==============================] - 0s 576us/step - loss: 8.0465 - mean_squared_error: 426998.8438 - mean_absolute_error: 321.4413 - mean_absolute_percentage_error: 8.0465 - val_loss: 8.4675 - val_mean_squared_error: 610620.3125 - val_mean_absolute_error: 323.6412 - val_mean_absolute_percentage_error: 8.4675\n",
            "Epoch 76/1000\n",
            "506/506 [==============================] - 0s 571us/step - loss: 8.0316 - mean_squared_error: 425724.5000 - mean_absolute_error: 320.9932 - mean_absolute_percentage_error: 8.0316 - val_loss: 8.3740 - val_mean_squared_error: 614115.3750 - val_mean_absolute_error: 320.1773 - val_mean_absolute_percentage_error: 8.3740\n",
            "Epoch 77/1000\n",
            "506/506 [==============================] - 0s 564us/step - loss: 8.0203 - mean_squared_error: 428338.6875 - mean_absolute_error: 320.8184 - mean_absolute_percentage_error: 8.0203 - val_loss: 8.7240 - val_mean_squared_error: 623825.2500 - val_mean_absolute_error: 322.7932 - val_mean_absolute_percentage_error: 8.7240\n",
            "Epoch 78/1000\n",
            "506/506 [==============================] - 0s 568us/step - loss: 8.0396 - mean_squared_error: 424145.2188 - mean_absolute_error: 320.3647 - mean_absolute_percentage_error: 8.0396 - val_loss: 8.4430 - val_mean_squared_error: 608399.9375 - val_mean_absolute_error: 320.6264 - val_mean_absolute_percentage_error: 8.4430\n",
            "Epoch 79/1000\n",
            "506/506 [==============================] - 0s 568us/step - loss: 8.0123 - mean_squared_error: 424106.9062 - mean_absolute_error: 320.2234 - mean_absolute_percentage_error: 8.0123 - val_loss: 8.4552 - val_mean_squared_error: 607341.1250 - val_mean_absolute_error: 322.7850 - val_mean_absolute_percentage_error: 8.4552\n",
            "Epoch 80/1000\n",
            "506/506 [==============================] - 0s 570us/step - loss: 7.9929 - mean_squared_error: 422431.5625 - mean_absolute_error: 320.0821 - mean_absolute_percentage_error: 7.9929 - val_loss: 8.3669 - val_mean_squared_error: 605102.9375 - val_mean_absolute_error: 326.0998 - val_mean_absolute_percentage_error: 8.3669\n",
            "Epoch 81/1000\n",
            "506/506 [==============================] - 0s 567us/step - loss: 7.9776 - mean_squared_error: 422104.5000 - mean_absolute_error: 319.5879 - mean_absolute_percentage_error: 7.9776 - val_loss: 8.4583 - val_mean_squared_error: 609061.6875 - val_mean_absolute_error: 320.3284 - val_mean_absolute_percentage_error: 8.4583\n",
            "Epoch 82/1000\n",
            "506/506 [==============================] - 0s 568us/step - loss: 7.9769 - mean_squared_error: 423230.6250 - mean_absolute_error: 320.0360 - mean_absolute_percentage_error: 7.9769 - val_loss: 8.3638 - val_mean_squared_error: 598670.3750 - val_mean_absolute_error: 320.2422 - val_mean_absolute_percentage_error: 8.3638\n",
            "Epoch 83/1000\n",
            "506/506 [==============================] - 0s 631us/step - loss: 7.9606 - mean_squared_error: 422449.6562 - mean_absolute_error: 319.6298 - mean_absolute_percentage_error: 7.9606 - val_loss: 8.6175 - val_mean_squared_error: 640567.0000 - val_mean_absolute_error: 324.3969 - val_mean_absolute_percentage_error: 8.6175\n",
            "Epoch 84/1000\n",
            "506/506 [==============================] - 0s 566us/step - loss: 7.9542 - mean_squared_error: 422390.8438 - mean_absolute_error: 319.0029 - mean_absolute_percentage_error: 7.9542 - val_loss: 8.3074 - val_mean_squared_error: 595142.8125 - val_mean_absolute_error: 320.5754 - val_mean_absolute_percentage_error: 8.3074\n",
            "Epoch 85/1000\n",
            "506/506 [==============================] - 0s 600us/step - loss: 7.9485 - mean_squared_error: 419896.4688 - mean_absolute_error: 319.0122 - mean_absolute_percentage_error: 7.9485 - val_loss: 8.2887 - val_mean_squared_error: 597885.5000 - val_mean_absolute_error: 319.5780 - val_mean_absolute_percentage_error: 8.2887\n",
            "Epoch 86/1000\n",
            "506/506 [==============================] - 0s 572us/step - loss: 7.9599 - mean_squared_error: 420231.7812 - mean_absolute_error: 319.4008 - mean_absolute_percentage_error: 7.9599 - val_loss: 8.4203 - val_mean_squared_error: 607195.8125 - val_mean_absolute_error: 318.9162 - val_mean_absolute_percentage_error: 8.4203\n",
            "Epoch 87/1000\n",
            "506/506 [==============================] - 0s 566us/step - loss: 7.9293 - mean_squared_error: 418874.5938 - mean_absolute_error: 318.4623 - mean_absolute_percentage_error: 7.9293 - val_loss: 8.3742 - val_mean_squared_error: 598308.7500 - val_mean_absolute_error: 323.5894 - val_mean_absolute_percentage_error: 8.3742\n",
            "Epoch 88/1000\n",
            "506/506 [==============================] - 0s 565us/step - loss: 7.9410 - mean_squared_error: 420676.8125 - mean_absolute_error: 319.2379 - mean_absolute_percentage_error: 7.9410 - val_loss: 8.3930 - val_mean_squared_error: 599407.1250 - val_mean_absolute_error: 327.8798 - val_mean_absolute_percentage_error: 8.3930\n",
            "Epoch 89/1000\n",
            "506/506 [==============================] - 0s 568us/step - loss: 7.9200 - mean_squared_error: 417896.9375 - mean_absolute_error: 318.6701 - mean_absolute_percentage_error: 7.9200 - val_loss: 8.2941 - val_mean_squared_error: 595642.2500 - val_mean_absolute_error: 319.5890 - val_mean_absolute_percentage_error: 8.2941\n",
            "Epoch 90/1000\n",
            "506/506 [==============================] - 0s 566us/step - loss: 7.9226 - mean_squared_error: 422463.0938 - mean_absolute_error: 319.4410 - mean_absolute_percentage_error: 7.9226 - val_loss: 8.7227 - val_mean_squared_error: 605979.2500 - val_mean_absolute_error: 320.1896 - val_mean_absolute_percentage_error: 8.7227\n",
            "Epoch 91/1000\n",
            "506/506 [==============================] - 0s 589us/step - loss: 7.9146 - mean_squared_error: 419484.2188 - mean_absolute_error: 318.4310 - mean_absolute_percentage_error: 7.9146 - val_loss: 8.4379 - val_mean_squared_error: 594482.4375 - val_mean_absolute_error: 327.6744 - val_mean_absolute_percentage_error: 8.4379\n",
            "Epoch 92/1000\n",
            "506/506 [==============================] - 0s 633us/step - loss: 7.8957 - mean_squared_error: 418647.1875 - mean_absolute_error: 318.4456 - mean_absolute_percentage_error: 7.8957 - val_loss: 8.3576 - val_mean_squared_error: 592686.0000 - val_mean_absolute_error: 321.5900 - val_mean_absolute_percentage_error: 8.3576\n",
            "Epoch 93/1000\n",
            "506/506 [==============================] - 0s 663us/step - loss: 7.8841 - mean_squared_error: 418661.0938 - mean_absolute_error: 318.7776 - mean_absolute_percentage_error: 7.8841 - val_loss: 8.3066 - val_mean_squared_error: 611605.9375 - val_mean_absolute_error: 318.2226 - val_mean_absolute_percentage_error: 8.3066\n",
            "Epoch 94/1000\n",
            "506/506 [==============================] - 0s 643us/step - loss: 7.8856 - mean_squared_error: 417238.0938 - mean_absolute_error: 317.7242 - mean_absolute_percentage_error: 7.8856 - val_loss: 8.2618 - val_mean_squared_error: 596622.1875 - val_mean_absolute_error: 318.4127 - val_mean_absolute_percentage_error: 8.2618\n",
            "Epoch 95/1000\n",
            "506/506 [==============================] - 0s 682us/step - loss: 7.8467 - mean_squared_error: 415494.7812 - mean_absolute_error: 317.7002 - mean_absolute_percentage_error: 7.8467 - val_loss: 8.2367 - val_mean_squared_error: 598752.9375 - val_mean_absolute_error: 316.5902 - val_mean_absolute_percentage_error: 8.2367\n",
            "Epoch 96/1000\n",
            "506/506 [==============================] - 0s 643us/step - loss: 7.8663 - mean_squared_error: 416323.7500 - mean_absolute_error: 318.1310 - mean_absolute_percentage_error: 7.8663 - val_loss: 8.2812 - val_mean_squared_error: 589784.1250 - val_mean_absolute_error: 321.5677 - val_mean_absolute_percentage_error: 8.2812\n",
            "Epoch 97/1000\n",
            "506/506 [==============================] - 0s 601us/step - loss: 7.8336 - mean_squared_error: 415172.8750 - mean_absolute_error: 317.2610 - mean_absolute_percentage_error: 7.8336 - val_loss: 8.2667 - val_mean_squared_error: 602173.5625 - val_mean_absolute_error: 316.9857 - val_mean_absolute_percentage_error: 8.2667\n",
            "Epoch 98/1000\n",
            "506/506 [==============================] - 0s 587us/step - loss: 7.8260 - mean_squared_error: 414997.3438 - mean_absolute_error: 317.2635 - mean_absolute_percentage_error: 7.8260 - val_loss: 8.1975 - val_mean_squared_error: 592889.1875 - val_mean_absolute_error: 318.0512 - val_mean_absolute_percentage_error: 8.1975\n",
            "Epoch 99/1000\n",
            "506/506 [==============================] - 0s 660us/step - loss: 7.8188 - mean_squared_error: 413309.5312 - mean_absolute_error: 316.7541 - mean_absolute_percentage_error: 7.8188 - val_loss: 8.3334 - val_mean_squared_error: 595454.4375 - val_mean_absolute_error: 329.6688 - val_mean_absolute_percentage_error: 8.3334\n",
            "Epoch 100/1000\n",
            "506/506 [==============================] - 0s 585us/step - loss: 7.8180 - mean_squared_error: 414955.1875 - mean_absolute_error: 317.5361 - mean_absolute_percentage_error: 7.8180 - val_loss: 8.1644 - val_mean_squared_error: 598729.3750 - val_mean_absolute_error: 316.1804 - val_mean_absolute_percentage_error: 8.1644\n",
            "Epoch 101/1000\n",
            "506/506 [==============================] - 0s 727us/step - loss: 7.8020 - mean_squared_error: 413011.5312 - mean_absolute_error: 316.7352 - mean_absolute_percentage_error: 7.8020 - val_loss: 8.1679 - val_mean_squared_error: 596907.1875 - val_mean_absolute_error: 317.6223 - val_mean_absolute_percentage_error: 8.1679\n",
            "Epoch 102/1000\n",
            "506/506 [==============================] - 0s 578us/step - loss: 7.7926 - mean_squared_error: 410792.9062 - mean_absolute_error: 316.2468 - mean_absolute_percentage_error: 7.7926 - val_loss: 8.1520 - val_mean_squared_error: 596513.6250 - val_mean_absolute_error: 316.8895 - val_mean_absolute_percentage_error: 8.1520\n",
            "Epoch 103/1000\n",
            "506/506 [==============================] - 0s 580us/step - loss: 7.7986 - mean_squared_error: 413695.7500 - mean_absolute_error: 316.6837 - mean_absolute_percentage_error: 7.7986 - val_loss: 8.2093 - val_mean_squared_error: 590863.2500 - val_mean_absolute_error: 318.9490 - val_mean_absolute_percentage_error: 8.2093\n",
            "Epoch 104/1000\n",
            "506/506 [==============================] - 0s 585us/step - loss: 7.7886 - mean_squared_error: 413599.7812 - mean_absolute_error: 316.6877 - mean_absolute_percentage_error: 7.7886 - val_loss: 8.1915 - val_mean_squared_error: 608397.7500 - val_mean_absolute_error: 317.4285 - val_mean_absolute_percentage_error: 8.1915\n",
            "Epoch 105/1000\n",
            "506/506 [==============================] - 0s 580us/step - loss: 7.7623 - mean_squared_error: 414442.9062 - mean_absolute_error: 316.4189 - mean_absolute_percentage_error: 7.7623 - val_loss: 8.1672 - val_mean_squared_error: 596472.6250 - val_mean_absolute_error: 318.5363 - val_mean_absolute_percentage_error: 8.1672\n",
            "Epoch 106/1000\n",
            "506/506 [==============================] - 0s 582us/step - loss: 7.7956 - mean_squared_error: 412624.9375 - mean_absolute_error: 316.6294 - mean_absolute_percentage_error: 7.7956 - val_loss: 8.1252 - val_mean_squared_error: 590433.9375 - val_mean_absolute_error: 316.3480 - val_mean_absolute_percentage_error: 8.1252\n",
            "Epoch 107/1000\n",
            "506/506 [==============================] - 0s 578us/step - loss: 7.7757 - mean_squared_error: 411420.9688 - mean_absolute_error: 316.4557 - mean_absolute_percentage_error: 7.7757 - val_loss: 8.1814 - val_mean_squared_error: 588998.6875 - val_mean_absolute_error: 321.6138 - val_mean_absolute_percentage_error: 8.1814\n",
            "Epoch 108/1000\n",
            "506/506 [==============================] - 0s 583us/step - loss: 7.7395 - mean_squared_error: 410704.1562 - mean_absolute_error: 315.1411 - mean_absolute_percentage_error: 7.7395 - val_loss: 8.1429 - val_mean_squared_error: 593068.0625 - val_mean_absolute_error: 326.9059 - val_mean_absolute_percentage_error: 8.1429\n",
            "Epoch 109/1000\n",
            "506/506 [==============================] - 0s 581us/step - loss: 7.7319 - mean_squared_error: 411619.7812 - mean_absolute_error: 315.8324 - mean_absolute_percentage_error: 7.7319 - val_loss: 8.1023 - val_mean_squared_error: 587260.5000 - val_mean_absolute_error: 317.6101 - val_mean_absolute_percentage_error: 8.1023\n",
            "Epoch 110/1000\n",
            "506/506 [==============================] - 0s 658us/step - loss: 7.7301 - mean_squared_error: 411341.2500 - mean_absolute_error: 315.4218 - mean_absolute_percentage_error: 7.7301 - val_loss: 8.0911 - val_mean_squared_error: 601369.0625 - val_mean_absolute_error: 314.3256 - val_mean_absolute_percentage_error: 8.0911\n",
            "Epoch 111/1000\n",
            "506/506 [==============================] - 0s 621us/step - loss: 7.7191 - mean_squared_error: 408158.9375 - mean_absolute_error: 314.7226 - mean_absolute_percentage_error: 7.7191 - val_loss: 8.1398 - val_mean_squared_error: 601806.2500 - val_mean_absolute_error: 314.7215 - val_mean_absolute_percentage_error: 8.1398\n",
            "Epoch 112/1000\n",
            "506/506 [==============================] - 0s 643us/step - loss: 7.7105 - mean_squared_error: 410778.8750 - mean_absolute_error: 314.6832 - mean_absolute_percentage_error: 7.7105 - val_loss: 8.0776 - val_mean_squared_error: 592746.5000 - val_mean_absolute_error: 319.2712 - val_mean_absolute_percentage_error: 8.0776\n",
            "Epoch 113/1000\n",
            "506/506 [==============================] - 0s 592us/step - loss: 7.7048 - mean_squared_error: 410774.2500 - mean_absolute_error: 314.9130 - mean_absolute_percentage_error: 7.7048 - val_loss: 8.0795 - val_mean_squared_error: 592826.8125 - val_mean_absolute_error: 315.2107 - val_mean_absolute_percentage_error: 8.0795\n",
            "Epoch 114/1000\n",
            "506/506 [==============================] - 0s 576us/step - loss: 7.6997 - mean_squared_error: 411986.2500 - mean_absolute_error: 314.9745 - mean_absolute_percentage_error: 7.6997 - val_loss: 8.0844 - val_mean_squared_error: 588284.0000 - val_mean_absolute_error: 319.0909 - val_mean_absolute_percentage_error: 8.0844\n",
            "Epoch 115/1000\n",
            "506/506 [==============================] - 0s 597us/step - loss: 7.6987 - mean_squared_error: 409482.9062 - mean_absolute_error: 314.5948 - mean_absolute_percentage_error: 7.6987 - val_loss: 8.0981 - val_mean_squared_error: 594364.8750 - val_mean_absolute_error: 314.5091 - val_mean_absolute_percentage_error: 8.0981\n",
            "Epoch 116/1000\n",
            "506/506 [==============================] - 0s 674us/step - loss: 7.6927 - mean_squared_error: 408428.2812 - mean_absolute_error: 313.9124 - mean_absolute_percentage_error: 7.6927 - val_loss: 8.0688 - val_mean_squared_error: 591790.3125 - val_mean_absolute_error: 315.8689 - val_mean_absolute_percentage_error: 8.0688\n",
            "Epoch 117/1000\n",
            "506/506 [==============================] - 0s 581us/step - loss: 7.6739 - mean_squared_error: 409271.9688 - mean_absolute_error: 314.2207 - mean_absolute_percentage_error: 7.6739 - val_loss: 8.0532 - val_mean_squared_error: 588741.9375 - val_mean_absolute_error: 317.4030 - val_mean_absolute_percentage_error: 8.0532\n",
            "Epoch 118/1000\n",
            "506/506 [==============================] - 0s 587us/step - loss: 7.6589 - mean_squared_error: 406433.5312 - mean_absolute_error: 313.5340 - mean_absolute_percentage_error: 7.6589 - val_loss: 8.0934 - val_mean_squared_error: 598541.1250 - val_mean_absolute_error: 316.6219 - val_mean_absolute_percentage_error: 8.0934\n",
            "Epoch 119/1000\n",
            "506/506 [==============================] - 0s 643us/step - loss: 7.6394 - mean_squared_error: 406384.8750 - mean_absolute_error: 313.1049 - mean_absolute_percentage_error: 7.6394 - val_loss: 7.9831 - val_mean_squared_error: 594002.6875 - val_mean_absolute_error: 314.0888 - val_mean_absolute_percentage_error: 7.9831\n",
            "Epoch 120/1000\n",
            "506/506 [==============================] - 0s 576us/step - loss: 7.6569 - mean_squared_error: 409007.5312 - mean_absolute_error: 313.7699 - mean_absolute_percentage_error: 7.6569 - val_loss: 8.0537 - val_mean_squared_error: 598787.7500 - val_mean_absolute_error: 313.0070 - val_mean_absolute_percentage_error: 8.0537\n",
            "Epoch 121/1000\n",
            "506/506 [==============================] - 0s 579us/step - loss: 7.6321 - mean_squared_error: 406304.3438 - mean_absolute_error: 313.3624 - mean_absolute_percentage_error: 7.6321 - val_loss: 8.0594 - val_mean_squared_error: 598304.4375 - val_mean_absolute_error: 313.9311 - val_mean_absolute_percentage_error: 8.0594\n",
            "Epoch 122/1000\n",
            "506/506 [==============================] - 0s 576us/step - loss: 7.6242 - mean_squared_error: 407584.1562 - mean_absolute_error: 313.5977 - mean_absolute_percentage_error: 7.6242 - val_loss: 8.0657 - val_mean_squared_error: 594343.1250 - val_mean_absolute_error: 318.5304 - val_mean_absolute_percentage_error: 8.0657\n",
            "Epoch 123/1000\n",
            "506/506 [==============================] - 0s 579us/step - loss: 7.6475 - mean_squared_error: 406563.3750 - mean_absolute_error: 313.2021 - mean_absolute_percentage_error: 7.6475 - val_loss: 7.9981 - val_mean_squared_error: 592611.3750 - val_mean_absolute_error: 316.8904 - val_mean_absolute_percentage_error: 7.9981\n",
            "Epoch 124/1000\n",
            "506/506 [==============================] - 0s 576us/step - loss: 7.6374 - mean_squared_error: 403272.9375 - mean_absolute_error: 313.3436 - mean_absolute_percentage_error: 7.6374 - val_loss: 8.0482 - val_mean_squared_error: 587961.1250 - val_mean_absolute_error: 319.6427 - val_mean_absolute_percentage_error: 8.0482\n",
            "Epoch 125/1000\n",
            "506/506 [==============================] - 0s 575us/step - loss: 7.6007 - mean_squared_error: 404776.0312 - mean_absolute_error: 312.7368 - mean_absolute_percentage_error: 7.6007 - val_loss: 8.0026 - val_mean_squared_error: 603579.1875 - val_mean_absolute_error: 311.8622 - val_mean_absolute_percentage_error: 8.0026\n",
            "Epoch 126/1000\n",
            "506/506 [==============================] - 0s 579us/step - loss: 7.6147 - mean_squared_error: 405935.0000 - mean_absolute_error: 313.4062 - mean_absolute_percentage_error: 7.6147 - val_loss: 8.0839 - val_mean_squared_error: 615690.0625 - val_mean_absolute_error: 313.6994 - val_mean_absolute_percentage_error: 8.0839\n",
            "Epoch 127/1000\n",
            "506/506 [==============================] - 0s 631us/step - loss: 7.6364 - mean_squared_error: 406123.0312 - mean_absolute_error: 313.0870 - mean_absolute_percentage_error: 7.6364 - val_loss: 8.0176 - val_mean_squared_error: 615173.8125 - val_mean_absolute_error: 312.9750 - val_mean_absolute_percentage_error: 8.0176\n",
            "Epoch 128/1000\n",
            "506/506 [==============================] - 0s 766us/step - loss: 7.5978 - mean_squared_error: 404000.4375 - mean_absolute_error: 311.9703 - mean_absolute_percentage_error: 7.5978 - val_loss: 7.9380 - val_mean_squared_error: 590114.6250 - val_mean_absolute_error: 315.3380 - val_mean_absolute_percentage_error: 7.9380\n",
            "Epoch 129/1000\n",
            "506/506 [==============================] - 0s 593us/step - loss: 7.5783 - mean_squared_error: 403919.7188 - mean_absolute_error: 311.8464 - mean_absolute_percentage_error: 7.5783 - val_loss: 7.9520 - val_mean_squared_error: 597669.4375 - val_mean_absolute_error: 311.2734 - val_mean_absolute_percentage_error: 7.9520\n",
            "Epoch 130/1000\n",
            "506/506 [==============================] - 0s 572us/step - loss: 7.5897 - mean_squared_error: 404109.5312 - mean_absolute_error: 312.0649 - mean_absolute_percentage_error: 7.5897 - val_loss: 7.9142 - val_mean_squared_error: 592556.7500 - val_mean_absolute_error: 311.1952 - val_mean_absolute_percentage_error: 7.9142\n",
            "Epoch 131/1000\n",
            "506/506 [==============================] - 0s 603us/step - loss: 7.5847 - mean_squared_error: 405319.5938 - mean_absolute_error: 312.5670 - mean_absolute_percentage_error: 7.5847 - val_loss: 8.0680 - val_mean_squared_error: 633895.8125 - val_mean_absolute_error: 315.1664 - val_mean_absolute_percentage_error: 8.0680\n",
            "Epoch 132/1000\n",
            "506/506 [==============================] - 0s 596us/step - loss: 7.5529 - mean_squared_error: 403351.8438 - mean_absolute_error: 311.2340 - mean_absolute_percentage_error: 7.5529 - val_loss: 8.0028 - val_mean_squared_error: 596853.8125 - val_mean_absolute_error: 321.0058 - val_mean_absolute_percentage_error: 8.0028\n",
            "Epoch 133/1000\n",
            "506/506 [==============================] - 0s 572us/step - loss: 7.5738 - mean_squared_error: 402229.1250 - mean_absolute_error: 312.0866 - mean_absolute_percentage_error: 7.5738 - val_loss: 7.9356 - val_mean_squared_error: 592100.6875 - val_mean_absolute_error: 312.1888 - val_mean_absolute_percentage_error: 7.9356\n",
            "Epoch 134/1000\n",
            "506/506 [==============================] - 0s 568us/step - loss: 7.5663 - mean_squared_error: 403955.7500 - mean_absolute_error: 311.2909 - mean_absolute_percentage_error: 7.5663 - val_loss: 7.9433 - val_mean_squared_error: 594863.0625 - val_mean_absolute_error: 313.7190 - val_mean_absolute_percentage_error: 7.9433\n",
            "Epoch 135/1000\n",
            "506/506 [==============================] - 0s 613us/step - loss: 7.5520 - mean_squared_error: 401492.8438 - mean_absolute_error: 310.9535 - mean_absolute_percentage_error: 7.5520 - val_loss: 8.0533 - val_mean_squared_error: 601215.3750 - val_mean_absolute_error: 310.9850 - val_mean_absolute_percentage_error: 8.0533\n",
            "Epoch 136/1000\n",
            "506/506 [==============================] - 0s 850us/step - loss: 7.5748 - mean_squared_error: 401124.3750 - mean_absolute_error: 311.9779 - mean_absolute_percentage_error: 7.5748 - val_loss: 7.8878 - val_mean_squared_error: 595567.1250 - val_mean_absolute_error: 310.1097 - val_mean_absolute_percentage_error: 7.8878\n",
            "Epoch 137/1000\n",
            "506/506 [==============================] - 0s 669us/step - loss: 7.5579 - mean_squared_error: 399151.9688 - mean_absolute_error: 311.4517 - mean_absolute_percentage_error: 7.5579 - val_loss: 8.1372 - val_mean_squared_error: 595138.8750 - val_mean_absolute_error: 322.3679 - val_mean_absolute_percentage_error: 8.1372\n",
            "Epoch 138/1000\n",
            "506/506 [==============================] - 0s 647us/step - loss: 7.5314 - mean_squared_error: 397731.8438 - mean_absolute_error: 310.5459 - mean_absolute_percentage_error: 7.5314 - val_loss: 7.9385 - val_mean_squared_error: 596765.6250 - val_mean_absolute_error: 309.8531 - val_mean_absolute_percentage_error: 7.9385\n",
            "Epoch 139/1000\n",
            "506/506 [==============================] - 0s 648us/step - loss: 7.5220 - mean_squared_error: 398702.0625 - mean_absolute_error: 310.0434 - mean_absolute_percentage_error: 7.5220 - val_loss: 7.9295 - val_mean_squared_error: 592186.3125 - val_mean_absolute_error: 314.8901 - val_mean_absolute_percentage_error: 7.9295\n",
            "Epoch 140/1000\n",
            "506/506 [==============================] - 0s 639us/step - loss: 7.5192 - mean_squared_error: 397947.0625 - mean_absolute_error: 310.0733 - mean_absolute_percentage_error: 7.5192 - val_loss: 7.8545 - val_mean_squared_error: 602051.9375 - val_mean_absolute_error: 309.2041 - val_mean_absolute_percentage_error: 7.8545\n",
            "Epoch 141/1000\n",
            "506/506 [==============================] - 0s 588us/step - loss: 7.5546 - mean_squared_error: 399934.5938 - mean_absolute_error: 310.7993 - mean_absolute_percentage_error: 7.5546 - val_loss: 8.0268 - val_mean_squared_error: 620313.6875 - val_mean_absolute_error: 312.6980 - val_mean_absolute_percentage_error: 8.0268\n",
            "Epoch 142/1000\n",
            "506/506 [==============================] - 0s 568us/step - loss: 7.5305 - mean_squared_error: 395012.5938 - mean_absolute_error: 309.9638 - mean_absolute_percentage_error: 7.5305 - val_loss: 7.8842 - val_mean_squared_error: 601596.5625 - val_mean_absolute_error: 310.3653 - val_mean_absolute_percentage_error: 7.8842\n",
            "Epoch 143/1000\n",
            "506/506 [==============================] - 0s 628us/step - loss: 7.5148 - mean_squared_error: 399331.7812 - mean_absolute_error: 310.0039 - mean_absolute_percentage_error: 7.5148 - val_loss: 7.8565 - val_mean_squared_error: 594426.1250 - val_mean_absolute_error: 311.4413 - val_mean_absolute_percentage_error: 7.8565\n",
            "Epoch 144/1000\n",
            "506/506 [==============================] - 0s 567us/step - loss: 7.5086 - mean_squared_error: 397059.7500 - mean_absolute_error: 309.2075 - mean_absolute_percentage_error: 7.5086 - val_loss: 7.9482 - val_mean_squared_error: 594224.3125 - val_mean_absolute_error: 313.6815 - val_mean_absolute_percentage_error: 7.9482\n",
            "Epoch 145/1000\n",
            "506/506 [==============================] - 0s 570us/step - loss: 7.5008 - mean_squared_error: 395929.5312 - mean_absolute_error: 308.7334 - mean_absolute_percentage_error: 7.5008 - val_loss: 8.0304 - val_mean_squared_error: 604401.1875 - val_mean_absolute_error: 309.8528 - val_mean_absolute_percentage_error: 8.0304\n",
            "Epoch 146/1000\n",
            "506/506 [==============================] - 0s 569us/step - loss: 7.5208 - mean_squared_error: 394998.2500 - mean_absolute_error: 309.4709 - mean_absolute_percentage_error: 7.5208 - val_loss: 7.8419 - val_mean_squared_error: 595513.0625 - val_mean_absolute_error: 308.5731 - val_mean_absolute_percentage_error: 7.8419\n",
            "Epoch 147/1000\n",
            "506/506 [==============================] - 0s 566us/step - loss: 7.4859 - mean_squared_error: 396567.5000 - mean_absolute_error: 308.9197 - mean_absolute_percentage_error: 7.4859 - val_loss: 7.9164 - val_mean_squared_error: 590404.0625 - val_mean_absolute_error: 308.6208 - val_mean_absolute_percentage_error: 7.9164\n",
            "Epoch 148/1000\n",
            "506/506 [==============================] - 0s 565us/step - loss: 7.5101 - mean_squared_error: 395094.5625 - mean_absolute_error: 309.4304 - mean_absolute_percentage_error: 7.5101 - val_loss: 7.8427 - val_mean_squared_error: 595163.0000 - val_mean_absolute_error: 312.4448 - val_mean_absolute_percentage_error: 7.8427\n",
            "Epoch 149/1000\n",
            "506/506 [==============================] - 0s 569us/step - loss: 7.4723 - mean_squared_error: 394790.6250 - mean_absolute_error: 308.2170 - mean_absolute_percentage_error: 7.4723 - val_loss: 7.8847 - val_mean_squared_error: 600682.8750 - val_mean_absolute_error: 306.7596 - val_mean_absolute_percentage_error: 7.8847\n",
            "Epoch 150/1000\n",
            "506/506 [==============================] - 0s 571us/step - loss: 7.4657 - mean_squared_error: 396984.6562 - mean_absolute_error: 308.4608 - mean_absolute_percentage_error: 7.4657 - val_loss: 7.8297 - val_mean_squared_error: 590520.6875 - val_mean_absolute_error: 312.0082 - val_mean_absolute_percentage_error: 7.8297\n",
            "Epoch 151/1000\n",
            "506/506 [==============================] - 0s 569us/step - loss: 7.4750 - mean_squared_error: 396503.4062 - mean_absolute_error: 308.6238 - mean_absolute_percentage_error: 7.4750 - val_loss: 8.0379 - val_mean_squared_error: 599357.5000 - val_mean_absolute_error: 308.4559 - val_mean_absolute_percentage_error: 8.0379\n",
            "Epoch 152/1000\n",
            "506/506 [==============================] - 0s 568us/step - loss: 7.4786 - mean_squared_error: 397539.5000 - mean_absolute_error: 308.8120 - mean_absolute_percentage_error: 7.4786 - val_loss: 7.8965 - val_mean_squared_error: 602539.0625 - val_mean_absolute_error: 306.6699 - val_mean_absolute_percentage_error: 7.8965\n",
            "Epoch 153/1000\n",
            "506/506 [==============================] - 0s 643us/step - loss: 7.4536 - mean_squared_error: 393412.9375 - mean_absolute_error: 307.9142 - mean_absolute_percentage_error: 7.4536 - val_loss: 7.8384 - val_mean_squared_error: 595703.4375 - val_mean_absolute_error: 309.0257 - val_mean_absolute_percentage_error: 7.8384\n",
            "Epoch 154/1000\n",
            "506/506 [==============================] - 0s 565us/step - loss: 7.4550 - mean_squared_error: 392086.5938 - mean_absolute_error: 307.3517 - mean_absolute_percentage_error: 7.4550 - val_loss: 7.9225 - val_mean_squared_error: 614049.3750 - val_mean_absolute_error: 307.9294 - val_mean_absolute_percentage_error: 7.9225\n",
            "Epoch 155/1000\n",
            "506/506 [==============================] - 0s 567us/step - loss: 7.4575 - mean_squared_error: 394057.6562 - mean_absolute_error: 306.9675 - mean_absolute_percentage_error: 7.4575 - val_loss: 7.9947 - val_mean_squared_error: 594124.1250 - val_mean_absolute_error: 316.2611 - val_mean_absolute_percentage_error: 7.9947\n",
            "Epoch 156/1000\n",
            "506/506 [==============================] - 0s 567us/step - loss: 7.4467 - mean_squared_error: 394683.3125 - mean_absolute_error: 307.6671 - mean_absolute_percentage_error: 7.4467 - val_loss: 7.7922 - val_mean_squared_error: 593727.1250 - val_mean_absolute_error: 306.9688 - val_mean_absolute_percentage_error: 7.7922\n",
            "Epoch 157/1000\n",
            "506/506 [==============================] - 0s 570us/step - loss: 7.4414 - mean_squared_error: 394433.1562 - mean_absolute_error: 307.0536 - mean_absolute_percentage_error: 7.4414 - val_loss: 7.8181 - val_mean_squared_error: 593858.8125 - val_mean_absolute_error: 307.1984 - val_mean_absolute_percentage_error: 7.8181\n",
            "Epoch 158/1000\n",
            "506/506 [==============================] - 0s 569us/step - loss: 7.4424 - mean_squared_error: 394015.5312 - mean_absolute_error: 307.2317 - mean_absolute_percentage_error: 7.4424 - val_loss: 7.8558 - val_mean_squared_error: 596335.7500 - val_mean_absolute_error: 306.0948 - val_mean_absolute_percentage_error: 7.8558\n",
            "Epoch 159/1000\n",
            "506/506 [==============================] - 0s 576us/step - loss: 7.4259 - mean_squared_error: 392129.2812 - mean_absolute_error: 306.6567 - mean_absolute_percentage_error: 7.4259 - val_loss: 7.8318 - val_mean_squared_error: 595906.6875 - val_mean_absolute_error: 307.6372 - val_mean_absolute_percentage_error: 7.8318\n",
            "Epoch 160/1000\n",
            "506/506 [==============================] - 0s 568us/step - loss: 7.4277 - mean_squared_error: 391751.2812 - mean_absolute_error: 306.2751 - mean_absolute_percentage_error: 7.4277 - val_loss: 7.8468 - val_mean_squared_error: 597403.2500 - val_mean_absolute_error: 306.6928 - val_mean_absolute_percentage_error: 7.8468\n",
            "Epoch 161/1000\n",
            "506/506 [==============================] - 0s 576us/step - loss: 7.4070 - mean_squared_error: 392445.2812 - mean_absolute_error: 306.3160 - mean_absolute_percentage_error: 7.4070 - val_loss: 7.7402 - val_mean_squared_error: 595742.3125 - val_mean_absolute_error: 306.1825 - val_mean_absolute_percentage_error: 7.7402\n",
            "Epoch 162/1000\n",
            "506/506 [==============================] - 0s 565us/step - loss: 7.4300 - mean_squared_error: 390821.4375 - mean_absolute_error: 306.1133 - mean_absolute_percentage_error: 7.4300 - val_loss: 7.8839 - val_mean_squared_error: 595359.4375 - val_mean_absolute_error: 318.9621 - val_mean_absolute_percentage_error: 7.8839\n",
            "Epoch 163/1000\n",
            "506/506 [==============================] - 0s 631us/step - loss: 7.3941 - mean_squared_error: 392157.6250 - mean_absolute_error: 306.4552 - mean_absolute_percentage_error: 7.3941 - val_loss: 7.8113 - val_mean_squared_error: 591226.0000 - val_mean_absolute_error: 312.4106 - val_mean_absolute_percentage_error: 7.8113\n",
            "Epoch 164/1000\n",
            "506/506 [==============================] - 0s 574us/step - loss: 7.4087 - mean_squared_error: 389627.2188 - mean_absolute_error: 306.3460 - mean_absolute_percentage_error: 7.4087 - val_loss: 7.8725 - val_mean_squared_error: 606224.9375 - val_mean_absolute_error: 307.1239 - val_mean_absolute_percentage_error: 7.8725\n",
            "Epoch 165/1000\n",
            "506/506 [==============================] - 0s 567us/step - loss: 7.3894 - mean_squared_error: 388849.7500 - mean_absolute_error: 304.8323 - mean_absolute_percentage_error: 7.3894 - val_loss: 7.7676 - val_mean_squared_error: 602414.1875 - val_mean_absolute_error: 304.8795 - val_mean_absolute_percentage_error: 7.7676\n",
            "Epoch 166/1000\n",
            "506/506 [==============================] - 0s 566us/step - loss: 7.3890 - mean_squared_error: 391611.8125 - mean_absolute_error: 305.6456 - mean_absolute_percentage_error: 7.3890 - val_loss: 7.8118 - val_mean_squared_error: 599907.1250 - val_mean_absolute_error: 306.6440 - val_mean_absolute_percentage_error: 7.8118\n",
            "Epoch 167/1000\n",
            "506/506 [==============================] - 0s 569us/step - loss: 7.3682 - mean_squared_error: 388270.9375 - mean_absolute_error: 305.0906 - mean_absolute_percentage_error: 7.3682 - val_loss: 7.7707 - val_mean_squared_error: 596421.8125 - val_mean_absolute_error: 306.4268 - val_mean_absolute_percentage_error: 7.7707\n",
            "Epoch 168/1000\n",
            "506/506 [==============================] - 0s 569us/step - loss: 7.3603 - mean_squared_error: 386925.6562 - mean_absolute_error: 304.7603 - mean_absolute_percentage_error: 7.3603 - val_loss: 7.8714 - val_mean_squared_error: 600707.5625 - val_mean_absolute_error: 316.3656 - val_mean_absolute_percentage_error: 7.8714\n",
            "Epoch 169/1000\n",
            "506/506 [==============================] - 0s 576us/step - loss: 7.3889 - mean_squared_error: 390446.8438 - mean_absolute_error: 305.1805 - mean_absolute_percentage_error: 7.3889 - val_loss: 7.7257 - val_mean_squared_error: 592683.4375 - val_mean_absolute_error: 306.9833 - val_mean_absolute_percentage_error: 7.7257\n",
            "Epoch 170/1000\n",
            "506/506 [==============================] - 0s 586us/step - loss: 7.3710 - mean_squared_error: 389121.7812 - mean_absolute_error: 305.7185 - mean_absolute_percentage_error: 7.3710 - val_loss: 7.7113 - val_mean_squared_error: 600606.1875 - val_mean_absolute_error: 303.7552 - val_mean_absolute_percentage_error: 7.7113\n",
            "Epoch 171/1000\n",
            "506/506 [==============================] - 0s 586us/step - loss: 7.3774 - mean_squared_error: 389394.2812 - mean_absolute_error: 305.6677 - mean_absolute_percentage_error: 7.3774 - val_loss: 7.6978 - val_mean_squared_error: 600389.7500 - val_mean_absolute_error: 304.2131 - val_mean_absolute_percentage_error: 7.6978\n",
            "Epoch 172/1000\n",
            "506/506 [==============================] - 0s 632us/step - loss: 7.3535 - mean_squared_error: 386562.5938 - mean_absolute_error: 304.5300 - mean_absolute_percentage_error: 7.3535 - val_loss: 7.8538 - val_mean_squared_error: 605153.7500 - val_mean_absolute_error: 304.5570 - val_mean_absolute_percentage_error: 7.8538\n",
            "Epoch 173/1000\n",
            "506/506 [==============================] - 0s 569us/step - loss: 7.3550 - mean_squared_error: 387787.1562 - mean_absolute_error: 304.7617 - mean_absolute_percentage_error: 7.3550 - val_loss: 7.6874 - val_mean_squared_error: 595854.0000 - val_mean_absolute_error: 305.2299 - val_mean_absolute_percentage_error: 7.6874\n",
            "Epoch 174/1000\n",
            "506/506 [==============================] - 0s 566us/step - loss: 7.3158 - mean_squared_error: 385981.7500 - mean_absolute_error: 303.4824 - mean_absolute_percentage_error: 7.3158 - val_loss: 7.7261 - val_mean_squared_error: 603984.6250 - val_mean_absolute_error: 303.5654 - val_mean_absolute_percentage_error: 7.7261\n",
            "Epoch 175/1000\n",
            "506/506 [==============================] - 0s 569us/step - loss: 7.3587 - mean_squared_error: 387446.8125 - mean_absolute_error: 304.5987 - mean_absolute_percentage_error: 7.3587 - val_loss: 7.6857 - val_mean_squared_error: 592932.6250 - val_mean_absolute_error: 303.8098 - val_mean_absolute_percentage_error: 7.6857\n",
            "Epoch 176/1000\n",
            "506/506 [==============================] - 0s 568us/step - loss: 7.3143 - mean_squared_error: 383478.6250 - mean_absolute_error: 303.1326 - mean_absolute_percentage_error: 7.3143 - val_loss: 7.8506 - val_mean_squared_error: 594102.9375 - val_mean_absolute_error: 314.0668 - val_mean_absolute_percentage_error: 7.8506\n",
            "Epoch 177/1000\n",
            "506/506 [==============================] - 0s 571us/step - loss: 7.3164 - mean_squared_error: 385731.0312 - mean_absolute_error: 303.7565 - mean_absolute_percentage_error: 7.3164 - val_loss: 7.7722 - val_mean_squared_error: 600521.9375 - val_mean_absolute_error: 316.3664 - val_mean_absolute_percentage_error: 7.7722\n",
            "Epoch 178/1000\n",
            "506/506 [==============================] - 0s 568us/step - loss: 7.3011 - mean_squared_error: 385522.2500 - mean_absolute_error: 303.6348 - mean_absolute_percentage_error: 7.3011 - val_loss: 7.7300 - val_mean_squared_error: 595147.0625 - val_mean_absolute_error: 306.6818 - val_mean_absolute_percentage_error: 7.7300\n",
            "Epoch 179/1000\n",
            "506/506 [==============================] - 0s 595us/step - loss: 7.3056 - mean_squared_error: 385540.6250 - mean_absolute_error: 304.0985 - mean_absolute_percentage_error: 7.3056 - val_loss: 7.6809 - val_mean_squared_error: 592414.8750 - val_mean_absolute_error: 304.7226 - val_mean_absolute_percentage_error: 7.6809\n",
            "Epoch 180/1000\n",
            "506/506 [==============================] - 0s 658us/step - loss: 7.2897 - mean_squared_error: 384225.5312 - mean_absolute_error: 303.3975 - mean_absolute_percentage_error: 7.2897 - val_loss: 7.7030 - val_mean_squared_error: 593324.3125 - val_mean_absolute_error: 305.3423 - val_mean_absolute_percentage_error: 7.7030\n",
            "Epoch 181/1000\n",
            "506/506 [==============================] - 0s 582us/step - loss: 7.2812 - mean_squared_error: 385556.5000 - mean_absolute_error: 303.3301 - mean_absolute_percentage_error: 7.2812 - val_loss: 7.6112 - val_mean_squared_error: 597718.4375 - val_mean_absolute_error: 304.8976 - val_mean_absolute_percentage_error: 7.6112\n",
            "Epoch 182/1000\n",
            "506/506 [==============================] - 0s 572us/step - loss: 7.2827 - mean_squared_error: 387935.4688 - mean_absolute_error: 303.4400 - mean_absolute_percentage_error: 7.2827 - val_loss: 7.8550 - val_mean_squared_error: 604274.3750 - val_mean_absolute_error: 320.0974 - val_mean_absolute_percentage_error: 7.8550\n",
            "Epoch 183/1000\n",
            "506/506 [==============================] - 0s 589us/step - loss: 7.2753 - mean_squared_error: 384471.2812 - mean_absolute_error: 303.1981 - mean_absolute_percentage_error: 7.2753 - val_loss: 7.6328 - val_mean_squared_error: 594465.6250 - val_mean_absolute_error: 302.3272 - val_mean_absolute_percentage_error: 7.6328\n",
            "Epoch 184/1000\n",
            "506/506 [==============================] - 0s 629us/step - loss: 7.2518 - mean_squared_error: 383414.1875 - mean_absolute_error: 302.2917 - mean_absolute_percentage_error: 7.2518 - val_loss: 7.6818 - val_mean_squared_error: 604285.5000 - val_mean_absolute_error: 303.9006 - val_mean_absolute_percentage_error: 7.6818\n",
            "Epoch 185/1000\n",
            "506/506 [==============================] - 0s 575us/step - loss: 7.2624 - mean_squared_error: 385951.1562 - mean_absolute_error: 303.0413 - mean_absolute_percentage_error: 7.2624 - val_loss: 7.6827 - val_mean_squared_error: 600022.8750 - val_mean_absolute_error: 307.9440 - val_mean_absolute_percentage_error: 7.6827\n",
            "Epoch 186/1000\n",
            "506/506 [==============================] - 0s 605us/step - loss: 7.2577 - mean_squared_error: 383795.8125 - mean_absolute_error: 302.4336 - mean_absolute_percentage_error: 7.2577 - val_loss: 7.6903 - val_mean_squared_error: 602781.0000 - val_mean_absolute_error: 306.5660 - val_mean_absolute_percentage_error: 7.6903\n",
            "Epoch 187/1000\n",
            "506/506 [==============================] - 1s 1ms/step - loss: 7.2835 - mean_squared_error: 388797.4062 - mean_absolute_error: 303.9048 - mean_absolute_percentage_error: 7.2835 - val_loss: 7.8261 - val_mean_squared_error: 602059.8750 - val_mean_absolute_error: 314.8383 - val_mean_absolute_percentage_error: 7.8261\n",
            "Epoch 188/1000\n",
            "506/506 [==============================] - 0s 780us/step - loss: 7.2475 - mean_squared_error: 383437.3438 - mean_absolute_error: 302.7665 - mean_absolute_percentage_error: 7.2475 - val_loss: 7.6478 - val_mean_squared_error: 603844.2500 - val_mean_absolute_error: 305.7559 - val_mean_absolute_percentage_error: 7.6478\n",
            "Epoch 189/1000\n",
            "506/506 [==============================] - 0s 598us/step - loss: 7.2740 - mean_squared_error: 384862.3750 - mean_absolute_error: 303.1581 - mean_absolute_percentage_error: 7.2740 - val_loss: 7.7223 - val_mean_squared_error: 598173.9375 - val_mean_absolute_error: 310.2771 - val_mean_absolute_percentage_error: 7.7223\n",
            "Epoch 190/1000\n",
            "506/506 [==============================] - 0s 570us/step - loss: 7.2672 - mean_squared_error: 383792.0312 - mean_absolute_error: 302.9834 - mean_absolute_percentage_error: 7.2672 - val_loss: 7.5772 - val_mean_squared_error: 602843.5000 - val_mean_absolute_error: 301.5876 - val_mean_absolute_percentage_error: 7.5772\n",
            "Epoch 191/1000\n",
            "506/506 [==============================] - 0s 677us/step - loss: 7.2258 - mean_squared_error: 382883.9062 - mean_absolute_error: 302.3397 - mean_absolute_percentage_error: 7.2258 - val_loss: 7.6376 - val_mean_squared_error: 613213.8750 - val_mean_absolute_error: 302.8384 - val_mean_absolute_percentage_error: 7.6376\n",
            "Epoch 192/1000\n",
            "506/506 [==============================] - 0s 627us/step - loss: 7.2390 - mean_squared_error: 383511.1250 - mean_absolute_error: 302.7780 - mean_absolute_percentage_error: 7.2390 - val_loss: 7.6396 - val_mean_squared_error: 603384.4375 - val_mean_absolute_error: 303.9057 - val_mean_absolute_percentage_error: 7.6396\n",
            "Epoch 193/1000\n",
            "506/506 [==============================] - 0s 594us/step - loss: 7.2074 - mean_squared_error: 384272.1562 - mean_absolute_error: 302.4781 - mean_absolute_percentage_error: 7.2074 - val_loss: 7.6102 - val_mean_squared_error: 601427.5000 - val_mean_absolute_error: 308.0334 - val_mean_absolute_percentage_error: 7.6102\n",
            "Epoch 194/1000\n",
            "506/506 [==============================] - 0s 592us/step - loss: 7.2172 - mean_squared_error: 384860.2812 - mean_absolute_error: 302.6387 - mean_absolute_percentage_error: 7.2172 - val_loss: 7.5962 - val_mean_squared_error: 619899.9375 - val_mean_absolute_error: 301.9794 - val_mean_absolute_percentage_error: 7.5962\n",
            "Epoch 195/1000\n",
            "506/506 [==============================] - 0s 667us/step - loss: 7.2209 - mean_squared_error: 381373.6875 - mean_absolute_error: 301.6006 - mean_absolute_percentage_error: 7.2209 - val_loss: 7.6510 - val_mean_squared_error: 598360.1875 - val_mean_absolute_error: 305.0970 - val_mean_absolute_percentage_error: 7.6510\n",
            "Epoch 196/1000\n",
            "506/506 [==============================] - 0s 571us/step - loss: 7.2282 - mean_squared_error: 384215.7500 - mean_absolute_error: 303.1992 - mean_absolute_percentage_error: 7.2282 - val_loss: 7.7337 - val_mean_squared_error: 619024.0625 - val_mean_absolute_error: 302.4071 - val_mean_absolute_percentage_error: 7.7337\n",
            "Epoch 197/1000\n",
            "506/506 [==============================] - 0s 569us/step - loss: 7.1897 - mean_squared_error: 379598.0625 - mean_absolute_error: 301.1393 - mean_absolute_percentage_error: 7.1897 - val_loss: 7.5971 - val_mean_squared_error: 602055.1875 - val_mean_absolute_error: 308.1379 - val_mean_absolute_percentage_error: 7.5971\n",
            "Epoch 198/1000\n",
            "506/506 [==============================] - 0s 577us/step - loss: 7.1849 - mean_squared_error: 380691.9062 - mean_absolute_error: 301.4694 - mean_absolute_percentage_error: 7.1849 - val_loss: 7.5962 - val_mean_squared_error: 598854.3750 - val_mean_absolute_error: 305.4175 - val_mean_absolute_percentage_error: 7.5962\n",
            "Epoch 199/1000\n",
            "506/506 [==============================] - 0s 587us/step - loss: 7.1886 - mean_squared_error: 379147.9688 - mean_absolute_error: 301.4305 - mean_absolute_percentage_error: 7.1886 - val_loss: 7.7760 - val_mean_squared_error: 601428.0625 - val_mean_absolute_error: 315.6148 - val_mean_absolute_percentage_error: 7.7760\n",
            "Epoch 200/1000\n",
            "506/506 [==============================] - 0s 596us/step - loss: 7.1763 - mean_squared_error: 380606.1250 - mean_absolute_error: 301.6198 - mean_absolute_percentage_error: 7.1763 - val_loss: 7.6259 - val_mean_squared_error: 604865.0000 - val_mean_absolute_error: 302.5727 - val_mean_absolute_percentage_error: 7.6259\n",
            "Epoch 201/1000\n",
            "506/506 [==============================] - 0s 636us/step - loss: 7.1786 - mean_squared_error: 383175.2812 - mean_absolute_error: 302.1234 - mean_absolute_percentage_error: 7.1786 - val_loss: 7.6387 - val_mean_squared_error: 603797.7500 - val_mean_absolute_error: 302.2684 - val_mean_absolute_percentage_error: 7.6387\n",
            "Epoch 202/1000\n",
            "506/506 [==============================] - 0s 573us/step - loss: 7.1540 - mean_squared_error: 379625.4375 - mean_absolute_error: 301.0052 - mean_absolute_percentage_error: 7.1540 - val_loss: 7.4957 - val_mean_squared_error: 597188.8125 - val_mean_absolute_error: 303.5569 - val_mean_absolute_percentage_error: 7.4957\n",
            "Epoch 203/1000\n",
            "506/506 [==============================] - 0s 572us/step - loss: 7.1892 - mean_squared_error: 380867.3125 - mean_absolute_error: 301.7702 - mean_absolute_percentage_error: 7.1892 - val_loss: 7.5942 - val_mean_squared_error: 623884.2500 - val_mean_absolute_error: 302.2430 - val_mean_absolute_percentage_error: 7.5942\n",
            "Epoch 204/1000\n",
            "506/506 [==============================] - 0s 573us/step - loss: 7.1502 - mean_squared_error: 380174.5000 - mean_absolute_error: 300.8918 - mean_absolute_percentage_error: 7.1502 - val_loss: 7.5625 - val_mean_squared_error: 614483.3125 - val_mean_absolute_error: 300.6743 - val_mean_absolute_percentage_error: 7.5625\n",
            "Epoch 205/1000\n",
            "506/506 [==============================] - 0s 577us/step - loss: 7.1707 - mean_squared_error: 380328.6562 - mean_absolute_error: 301.1969 - mean_absolute_percentage_error: 7.1707 - val_loss: 7.6122 - val_mean_squared_error: 601939.3125 - val_mean_absolute_error: 302.6726 - val_mean_absolute_percentage_error: 7.6122\n",
            "Epoch 206/1000\n",
            "506/506 [==============================] - 0s 572us/step - loss: 7.1605 - mean_squared_error: 381018.1875 - mean_absolute_error: 301.1051 - mean_absolute_percentage_error: 7.1605 - val_loss: 7.6965 - val_mean_squared_error: 602675.5000 - val_mean_absolute_error: 315.4829 - val_mean_absolute_percentage_error: 7.6965\n",
            "Epoch 207/1000\n",
            "506/506 [==============================] - 0s 684us/step - loss: 7.1446 - mean_squared_error: 376658.0312 - mean_absolute_error: 300.2421 - mean_absolute_percentage_error: 7.1446 - val_loss: 7.6266 - val_mean_squared_error: 594391.1875 - val_mean_absolute_error: 312.3932 - val_mean_absolute_percentage_error: 7.6266\n",
            "Epoch 208/1000\n",
            "506/506 [==============================] - 0s 586us/step - loss: 7.1578 - mean_squared_error: 375692.3125 - mean_absolute_error: 300.4335 - mean_absolute_percentage_error: 7.1578 - val_loss: 7.6412 - val_mean_squared_error: 608250.4375 - val_mean_absolute_error: 301.5114 - val_mean_absolute_percentage_error: 7.6412\n",
            "Epoch 209/1000\n",
            "506/506 [==============================] - 0s 578us/step - loss: 7.1490 - mean_squared_error: 377063.2812 - mean_absolute_error: 300.2292 - mean_absolute_percentage_error: 7.1490 - val_loss: 7.5637 - val_mean_squared_error: 593124.2500 - val_mean_absolute_error: 303.2443 - val_mean_absolute_percentage_error: 7.5637\n",
            "Epoch 210/1000\n",
            "506/506 [==============================] - 0s 572us/step - loss: 7.1252 - mean_squared_error: 376023.3125 - mean_absolute_error: 300.0272 - mean_absolute_percentage_error: 7.1252 - val_loss: 7.5186 - val_mean_squared_error: 600064.8125 - val_mean_absolute_error: 303.2288 - val_mean_absolute_percentage_error: 7.5186\n",
            "Epoch 211/1000\n",
            "506/506 [==============================] - 0s 577us/step - loss: 7.1215 - mean_squared_error: 377602.3438 - mean_absolute_error: 300.4157 - mean_absolute_percentage_error: 7.1215 - val_loss: 7.6937 - val_mean_squared_error: 598021.0000 - val_mean_absolute_error: 313.2539 - val_mean_absolute_percentage_error: 7.6937\n",
            "Epoch 212/1000\n",
            "506/506 [==============================] - 0s 638us/step - loss: 7.1317 - mean_squared_error: 378093.4688 - mean_absolute_error: 300.4929 - mean_absolute_percentage_error: 7.1317 - val_loss: 7.5765 - val_mean_squared_error: 595456.6875 - val_mean_absolute_error: 302.8012 - val_mean_absolute_percentage_error: 7.5765\n",
            "Epoch 213/1000\n",
            "506/506 [==============================] - 0s 886us/step - loss: 7.1326 - mean_squared_error: 376883.8125 - mean_absolute_error: 300.7208 - mean_absolute_percentage_error: 7.1326 - val_loss: 7.4896 - val_mean_squared_error: 593493.8125 - val_mean_absolute_error: 301.5859 - val_mean_absolute_percentage_error: 7.4896\n",
            "Epoch 214/1000\n",
            "506/506 [==============================] - 0s 644us/step - loss: 7.1272 - mean_squared_error: 376524.0000 - mean_absolute_error: 300.6432 - mean_absolute_percentage_error: 7.1272 - val_loss: 7.4941 - val_mean_squared_error: 594822.8750 - val_mean_absolute_error: 300.3304 - val_mean_absolute_percentage_error: 7.4941\n",
            "Epoch 215/1000\n",
            "506/506 [==============================] - 0s 735us/step - loss: 7.1513 - mean_squared_error: 376085.0312 - mean_absolute_error: 300.7733 - mean_absolute_percentage_error: 7.1513 - val_loss: 7.4680 - val_mean_squared_error: 588019.5000 - val_mean_absolute_error: 302.0147 - val_mean_absolute_percentage_error: 7.4680\n",
            "Epoch 216/1000\n",
            "506/506 [==============================] - 0s 692us/step - loss: 7.1399 - mean_squared_error: 375577.2188 - mean_absolute_error: 300.9471 - mean_absolute_percentage_error: 7.1399 - val_loss: 7.4652 - val_mean_squared_error: 587914.7500 - val_mean_absolute_error: 301.6759 - val_mean_absolute_percentage_error: 7.4652\n",
            "Epoch 217/1000\n",
            "506/506 [==============================] - 0s 678us/step - loss: 7.1036 - mean_squared_error: 370711.3750 - mean_absolute_error: 298.8685 - mean_absolute_percentage_error: 7.1036 - val_loss: 7.4558 - val_mean_squared_error: 592285.2500 - val_mean_absolute_error: 302.3149 - val_mean_absolute_percentage_error: 7.4558\n",
            "Epoch 218/1000\n",
            "506/506 [==============================] - 0s 594us/step - loss: 7.1155 - mean_squared_error: 372802.8438 - mean_absolute_error: 299.7169 - mean_absolute_percentage_error: 7.1155 - val_loss: 7.6223 - val_mean_squared_error: 588117.7500 - val_mean_absolute_error: 303.8904 - val_mean_absolute_percentage_error: 7.6223\n",
            "Epoch 219/1000\n",
            "506/506 [==============================] - 0s 591us/step - loss: 7.1050 - mean_squared_error: 368036.5625 - mean_absolute_error: 299.4631 - mean_absolute_percentage_error: 7.1050 - val_loss: 7.6311 - val_mean_squared_error: 598746.1250 - val_mean_absolute_error: 300.0494 - val_mean_absolute_percentage_error: 7.6311\n",
            "Epoch 220/1000\n",
            "506/506 [==============================] - 0s 595us/step - loss: 7.0738 - mean_squared_error: 370142.9375 - mean_absolute_error: 299.3231 - mean_absolute_percentage_error: 7.0738 - val_loss: 7.8433 - val_mean_squared_error: 582236.7500 - val_mean_absolute_error: 311.8728 - val_mean_absolute_percentage_error: 7.8433\n",
            "Epoch 221/1000\n",
            "506/506 [==============================] - 0s 588us/step - loss: 7.0821 - mean_squared_error: 371663.4062 - mean_absolute_error: 298.9442 - mean_absolute_percentage_error: 7.0821 - val_loss: 7.5937 - val_mean_squared_error: 579782.8750 - val_mean_absolute_error: 303.5838 - val_mean_absolute_percentage_error: 7.5937\n",
            "Epoch 222/1000\n",
            "506/506 [==============================] - 0s 597us/step - loss: 7.0872 - mean_squared_error: 368115.1250 - mean_absolute_error: 298.3561 - mean_absolute_percentage_error: 7.0872 - val_loss: 7.4243 - val_mean_squared_error: 588767.3125 - val_mean_absolute_error: 299.4204 - val_mean_absolute_percentage_error: 7.4243\n",
            "Epoch 223/1000\n",
            "506/506 [==============================] - 0s 654us/step - loss: 7.0582 - mean_squared_error: 367706.7188 - mean_absolute_error: 298.6655 - mean_absolute_percentage_error: 7.0582 - val_loss: 7.4735 - val_mean_squared_error: 583167.0000 - val_mean_absolute_error: 303.0235 - val_mean_absolute_percentage_error: 7.4735\n",
            "Epoch 224/1000\n",
            "506/506 [==============================] - 0s 711us/step - loss: 7.0838 - mean_squared_error: 369418.0938 - mean_absolute_error: 299.2304 - mean_absolute_percentage_error: 7.0838 - val_loss: 7.5146 - val_mean_squared_error: 607484.3750 - val_mean_absolute_error: 298.9221 - val_mean_absolute_percentage_error: 7.5146\n",
            "Epoch 225/1000\n",
            "506/506 [==============================] - 0s 592us/step - loss: 7.0619 - mean_squared_error: 366863.7812 - mean_absolute_error: 298.2422 - mean_absolute_percentage_error: 7.0619 - val_loss: 7.4350 - val_mean_squared_error: 583869.4375 - val_mean_absolute_error: 299.3223 - val_mean_absolute_percentage_error: 7.4350\n",
            "Epoch 226/1000\n",
            "506/506 [==============================] - 0s 587us/step - loss: 7.0864 - mean_squared_error: 367133.8125 - mean_absolute_error: 298.4820 - mean_absolute_percentage_error: 7.0864 - val_loss: 7.4061 - val_mean_squared_error: 583326.6875 - val_mean_absolute_error: 298.9714 - val_mean_absolute_percentage_error: 7.4061\n",
            "Epoch 227/1000\n",
            "506/506 [==============================] - 0s 587us/step - loss: 7.0542 - mean_squared_error: 365386.3438 - mean_absolute_error: 298.3291 - mean_absolute_percentage_error: 7.0542 - val_loss: 7.4149 - val_mean_squared_error: 585860.1250 - val_mean_absolute_error: 300.3241 - val_mean_absolute_percentage_error: 7.4149\n",
            "Epoch 228/1000\n",
            "506/506 [==============================] - 0s 587us/step - loss: 7.0715 - mean_squared_error: 364409.3125 - mean_absolute_error: 298.4777 - mean_absolute_percentage_error: 7.0715 - val_loss: 7.5922 - val_mean_squared_error: 579965.8125 - val_mean_absolute_error: 304.6779 - val_mean_absolute_percentage_error: 7.5922\n",
            "Epoch 229/1000\n",
            "506/506 [==============================] - 0s 678us/step - loss: 7.0792 - mean_squared_error: 365668.1875 - mean_absolute_error: 298.5478 - mean_absolute_percentage_error: 7.0792 - val_loss: 7.4403 - val_mean_squared_error: 584731.4375 - val_mean_absolute_error: 299.3762 - val_mean_absolute_percentage_error: 7.4403\n",
            "Epoch 230/1000\n",
            "506/506 [==============================] - 0s 609us/step - loss: 7.0677 - mean_squared_error: 364588.4062 - mean_absolute_error: 297.8577 - mean_absolute_percentage_error: 7.0677 - val_loss: 7.9855 - val_mean_squared_error: 641612.8125 - val_mean_absolute_error: 309.6870 - val_mean_absolute_percentage_error: 7.9855\n",
            "Epoch 231/1000\n",
            "506/506 [==============================] - 0s 690us/step - loss: 7.0554 - mean_squared_error: 363764.2812 - mean_absolute_error: 297.6814 - mean_absolute_percentage_error: 7.0554 - val_loss: 7.4637 - val_mean_squared_error: 581163.1875 - val_mean_absolute_error: 307.1086 - val_mean_absolute_percentage_error: 7.4637\n",
            "Epoch 232/1000\n",
            "506/506 [==============================] - 0s 609us/step - loss: 7.0427 - mean_squared_error: 361450.2812 - mean_absolute_error: 297.1181 - mean_absolute_percentage_error: 7.0427 - val_loss: 7.6430 - val_mean_squared_error: 585717.7500 - val_mean_absolute_error: 311.5584 - val_mean_absolute_percentage_error: 7.6430\n",
            "Epoch 233/1000\n",
            "506/506 [==============================] - 0s 605us/step - loss: 7.0711 - mean_squared_error: 362742.5625 - mean_absolute_error: 298.1688 - mean_absolute_percentage_error: 7.0711 - val_loss: 7.5294 - val_mean_squared_error: 602119.8750 - val_mean_absolute_error: 297.0364 - val_mean_absolute_percentage_error: 7.5294\n",
            "Epoch 234/1000\n",
            "506/506 [==============================] - 0s 609us/step - loss: 7.0506 - mean_squared_error: 361635.6875 - mean_absolute_error: 296.9153 - mean_absolute_percentage_error: 7.0506 - val_loss: 7.4619 - val_mean_squared_error: 581309.6250 - val_mean_absolute_error: 300.2486 - val_mean_absolute_percentage_error: 7.4619\n",
            "Epoch 235/1000\n",
            "506/506 [==============================] - 0s 680us/step - loss: 7.0577 - mean_squared_error: 365155.9688 - mean_absolute_error: 298.4805 - mean_absolute_percentage_error: 7.0577 - val_loss: 7.5770 - val_mean_squared_error: 608362.6875 - val_mean_absolute_error: 299.4971 - val_mean_absolute_percentage_error: 7.5770\n",
            "Epoch 236/1000\n",
            "506/506 [==============================] - 0s 604us/step - loss: 7.0547 - mean_squared_error: 362119.5625 - mean_absolute_error: 297.1164 - mean_absolute_percentage_error: 7.0547 - val_loss: 7.5175 - val_mean_squared_error: 592792.7500 - val_mean_absolute_error: 298.6334 - val_mean_absolute_percentage_error: 7.5175\n",
            "Epoch 237/1000\n",
            "506/506 [==============================] - 0s 646us/step - loss: 7.0556 - mean_squared_error: 362704.6250 - mean_absolute_error: 298.0193 - mean_absolute_percentage_error: 7.0556 - val_loss: 7.3790 - val_mean_squared_error: 579051.0625 - val_mean_absolute_error: 301.0554 - val_mean_absolute_percentage_error: 7.3790\n",
            "Epoch 238/1000\n",
            "506/506 [==============================] - 0s 721us/step - loss: 7.0130 - mean_squared_error: 359791.0312 - mean_absolute_error: 296.7093 - mean_absolute_percentage_error: 7.0130 - val_loss: 7.4207 - val_mean_squared_error: 583170.6875 - val_mean_absolute_error: 298.5548 - val_mean_absolute_percentage_error: 7.4207\n",
            "Epoch 239/1000\n",
            "506/506 [==============================] - 0s 628us/step - loss: 7.0254 - mean_squared_error: 362564.2500 - mean_absolute_error: 297.0834 - mean_absolute_percentage_error: 7.0254 - val_loss: 7.5387 - val_mean_squared_error: 584126.3125 - val_mean_absolute_error: 297.1257 - val_mean_absolute_percentage_error: 7.5387\n",
            "Epoch 240/1000\n",
            "506/506 [==============================] - 0s 730us/step - loss: 7.0567 - mean_squared_error: 362850.8438 - mean_absolute_error: 297.8967 - mean_absolute_percentage_error: 7.0567 - val_loss: 7.4841 - val_mean_squared_error: 586991.0625 - val_mean_absolute_error: 300.0698 - val_mean_absolute_percentage_error: 7.4841\n",
            "Epoch 241/1000\n",
            "506/506 [==============================] - 0s 632us/step - loss: 7.0300 - mean_squared_error: 360086.8750 - mean_absolute_error: 296.4667 - mean_absolute_percentage_error: 7.0300 - val_loss: 7.4545 - val_mean_squared_error: 583471.9375 - val_mean_absolute_error: 299.2491 - val_mean_absolute_percentage_error: 7.4545\n",
            "Epoch 242/1000\n",
            "506/506 [==============================] - 0s 617us/step - loss: 7.0208 - mean_squared_error: 359257.0938 - mean_absolute_error: 296.3028 - mean_absolute_percentage_error: 7.0208 - val_loss: 7.4113 - val_mean_squared_error: 596125.5625 - val_mean_absolute_error: 296.7384 - val_mean_absolute_percentage_error: 7.4113\n",
            "Epoch 243/1000\n",
            "506/506 [==============================] - 0s 613us/step - loss: 7.0377 - mean_squared_error: 360257.2188 - mean_absolute_error: 296.9589 - mean_absolute_percentage_error: 7.0377 - val_loss: 7.5034 - val_mean_squared_error: 582820.0000 - val_mean_absolute_error: 305.1900 - val_mean_absolute_percentage_error: 7.5034\n",
            "Epoch 244/1000\n",
            "506/506 [==============================] - 0s 606us/step - loss: 7.0343 - mean_squared_error: 359536.2188 - mean_absolute_error: 297.1655 - mean_absolute_percentage_error: 7.0343 - val_loss: 7.4194 - val_mean_squared_error: 587482.2500 - val_mean_absolute_error: 297.1736 - val_mean_absolute_percentage_error: 7.4194\n",
            "Epoch 245/1000\n",
            "506/506 [==============================] - 0s 802us/step - loss: 7.0389 - mean_squared_error: 362321.1250 - mean_absolute_error: 297.7658 - mean_absolute_percentage_error: 7.0389 - val_loss: 7.5035 - val_mean_squared_error: 600327.7500 - val_mean_absolute_error: 296.3809 - val_mean_absolute_percentage_error: 7.5035\n",
            "Epoch 246/1000\n",
            "506/506 [==============================] - 0s 650us/step - loss: 7.0479 - mean_squared_error: 359102.3750 - mean_absolute_error: 296.6158 - mean_absolute_percentage_error: 7.0479 - val_loss: 7.5662 - val_mean_squared_error: 584591.5625 - val_mean_absolute_error: 309.7999 - val_mean_absolute_percentage_error: 7.5662\n",
            "Epoch 247/1000\n",
            "506/506 [==============================] - 0s 639us/step - loss: 7.0018 - mean_squared_error: 358619.2188 - mean_absolute_error: 295.5114 - mean_absolute_percentage_error: 7.0018 - val_loss: 7.4348 - val_mean_squared_error: 584142.8750 - val_mean_absolute_error: 295.8381 - val_mean_absolute_percentage_error: 7.4348\n",
            "Epoch 248/1000\n",
            "506/506 [==============================] - 0s 764us/step - loss: 7.0251 - mean_squared_error: 360256.4375 - mean_absolute_error: 296.4588 - mean_absolute_percentage_error: 7.0251 - val_loss: 7.4694 - val_mean_squared_error: 580195.5000 - val_mean_absolute_error: 300.4910 - val_mean_absolute_percentage_error: 7.4694\n",
            "Epoch 249/1000\n",
            "506/506 [==============================] - 0s 651us/step - loss: 7.0205 - mean_squared_error: 360078.3125 - mean_absolute_error: 297.3130 - mean_absolute_percentage_error: 7.0205 - val_loss: 7.4279 - val_mean_squared_error: 589536.2500 - val_mean_absolute_error: 295.4191 - val_mean_absolute_percentage_error: 7.4279\n",
            "Epoch 250/1000\n",
            "506/506 [==============================] - 0s 736us/step - loss: 6.9747 - mean_squared_error: 355998.6562 - mean_absolute_error: 295.5980 - mean_absolute_percentage_error: 6.9747 - val_loss: 7.3979 - val_mean_squared_error: 586516.0000 - val_mean_absolute_error: 296.1266 - val_mean_absolute_percentage_error: 7.3979\n",
            "Epoch 251/1000\n",
            "506/506 [==============================] - 0s 769us/step - loss: 7.0285 - mean_squared_error: 359477.9375 - mean_absolute_error: 296.8522 - mean_absolute_percentage_error: 7.0285 - val_loss: 7.4940 - val_mean_squared_error: 577719.0000 - val_mean_absolute_error: 299.1564 - val_mean_absolute_percentage_error: 7.4940\n",
            "Epoch 252/1000\n",
            "506/506 [==============================] - 0s 666us/step - loss: 7.0121 - mean_squared_error: 360638.1875 - mean_absolute_error: 296.6148 - mean_absolute_percentage_error: 7.0121 - val_loss: 7.3823 - val_mean_squared_error: 588266.3125 - val_mean_absolute_error: 295.2486 - val_mean_absolute_percentage_error: 7.3823\n",
            "Epoch 253/1000\n",
            "506/506 [==============================] - 0s 638us/step - loss: 7.0047 - mean_squared_error: 357218.4688 - mean_absolute_error: 296.1947 - mean_absolute_percentage_error: 7.0047 - val_loss: 7.5089 - val_mean_squared_error: 593202.4375 - val_mean_absolute_error: 295.9796 - val_mean_absolute_percentage_error: 7.5089\n",
            "Epoch 254/1000\n",
            "506/506 [==============================] - 0s 664us/step - loss: 6.9831 - mean_squared_error: 359344.4688 - mean_absolute_error: 295.7974 - mean_absolute_percentage_error: 6.9831 - val_loss: 7.4621 - val_mean_squared_error: 584049.1250 - val_mean_absolute_error: 297.3664 - val_mean_absolute_percentage_error: 7.4621\n",
            "Epoch 255/1000\n",
            "506/506 [==============================] - 0s 742us/step - loss: 7.0153 - mean_squared_error: 357860.3438 - mean_absolute_error: 296.4541 - mean_absolute_percentage_error: 7.0153 - val_loss: 7.3492 - val_mean_squared_error: 583711.5000 - val_mean_absolute_error: 297.2377 - val_mean_absolute_percentage_error: 7.3492\n",
            "Epoch 256/1000\n",
            "506/506 [==============================] - 0s 667us/step - loss: 6.9922 - mean_squared_error: 359647.5312 - mean_absolute_error: 296.3721 - mean_absolute_percentage_error: 6.9922 - val_loss: 7.6189 - val_mean_squared_error: 576327.4375 - val_mean_absolute_error: 307.0282 - val_mean_absolute_percentage_error: 7.6189\n",
            "Epoch 257/1000\n",
            "506/506 [==============================] - 0s 775us/step - loss: 6.9917 - mean_squared_error: 357075.0000 - mean_absolute_error: 295.7049 - mean_absolute_percentage_error: 6.9917 - val_loss: 7.5138 - val_mean_squared_error: 585718.5000 - val_mean_absolute_error: 310.7556 - val_mean_absolute_percentage_error: 7.5138\n",
            "Epoch 258/1000\n",
            "506/506 [==============================] - 0s 671us/step - loss: 6.9981 - mean_squared_error: 357054.8125 - mean_absolute_error: 296.1042 - mean_absolute_percentage_error: 6.9981 - val_loss: 7.4026 - val_mean_squared_error: 582753.1250 - val_mean_absolute_error: 298.3244 - val_mean_absolute_percentage_error: 7.4026\n",
            "Epoch 259/1000\n",
            "506/506 [==============================] - 0s 811us/step - loss: 6.9706 - mean_squared_error: 357007.0625 - mean_absolute_error: 295.3614 - mean_absolute_percentage_error: 6.9706 - val_loss: 7.4107 - val_mean_squared_error: 581924.3125 - val_mean_absolute_error: 296.6659 - val_mean_absolute_percentage_error: 7.4107\n",
            "Epoch 260/1000\n",
            "506/506 [==============================] - 0s 674us/step - loss: 6.9832 - mean_squared_error: 357900.5312 - mean_absolute_error: 296.1489 - mean_absolute_percentage_error: 6.9832 - val_loss: 7.4488 - val_mean_squared_error: 588881.9375 - val_mean_absolute_error: 295.5862 - val_mean_absolute_percentage_error: 7.4488\n",
            "Epoch 261/1000\n",
            "506/506 [==============================] - 0s 658us/step - loss: 6.9729 - mean_squared_error: 356037.7188 - mean_absolute_error: 294.8488 - mean_absolute_percentage_error: 6.9729 - val_loss: 7.4594 - val_mean_squared_error: 578910.6250 - val_mean_absolute_error: 300.0910 - val_mean_absolute_percentage_error: 7.4594\n",
            "Epoch 262/1000\n",
            "506/506 [==============================] - 0s 664us/step - loss: 6.9899 - mean_squared_error: 355265.9375 - mean_absolute_error: 295.5097 - mean_absolute_percentage_error: 6.9899 - val_loss: 7.5322 - val_mean_squared_error: 581791.1875 - val_mean_absolute_error: 299.1979 - val_mean_absolute_percentage_error: 7.5322\n",
            "Epoch 263/1000\n",
            "506/506 [==============================] - 0s 778us/step - loss: 6.9724 - mean_squared_error: 357160.6250 - mean_absolute_error: 295.4593 - mean_absolute_percentage_error: 6.9724 - val_loss: 7.3961 - val_mean_squared_error: 579709.5625 - val_mean_absolute_error: 297.4557 - val_mean_absolute_percentage_error: 7.3961\n",
            "Epoch 264/1000\n",
            "506/506 [==============================] - 0s 767us/step - loss: 6.9773 - mean_squared_error: 357413.4062 - mean_absolute_error: 295.5588 - mean_absolute_percentage_error: 6.9773 - val_loss: 7.4235 - val_mean_squared_error: 591456.1875 - val_mean_absolute_error: 295.5891 - val_mean_absolute_percentage_error: 7.4235\n",
            "Epoch 265/1000\n",
            "506/506 [==============================] - 0s 667us/step - loss: 6.9787 - mean_squared_error: 356642.8750 - mean_absolute_error: 295.6914 - mean_absolute_percentage_error: 6.9787 - val_loss: 7.4486 - val_mean_squared_error: 584062.9375 - val_mean_absolute_error: 298.0917 - val_mean_absolute_percentage_error: 7.4486\n",
            "Epoch 266/1000\n",
            "506/506 [==============================] - 0s 663us/step - loss: 6.9689 - mean_squared_error: 356538.6562 - mean_absolute_error: 295.2480 - mean_absolute_percentage_error: 6.9689 - val_loss: 7.6325 - val_mean_squared_error: 616970.0625 - val_mean_absolute_error: 301.3957 - val_mean_absolute_percentage_error: 7.6325\n",
            "Epoch 267/1000\n",
            "506/506 [==============================] - 0s 653us/step - loss: 6.9610 - mean_squared_error: 356392.5312 - mean_absolute_error: 294.6777 - mean_absolute_percentage_error: 6.9610 - val_loss: 7.3077 - val_mean_squared_error: 576653.6250 - val_mean_absolute_error: 299.0126 - val_mean_absolute_percentage_error: 7.3077\n",
            "Epoch 268/1000\n",
            "506/506 [==============================] - 0s 643us/step - loss: 6.9677 - mean_squared_error: 355672.9688 - mean_absolute_error: 295.2491 - mean_absolute_percentage_error: 6.9677 - val_loss: 7.3277 - val_mean_squared_error: 582473.0625 - val_mean_absolute_error: 295.1805 - val_mean_absolute_percentage_error: 7.3277\n",
            "Epoch 269/1000\n",
            "506/506 [==============================] - 0s 860us/step - loss: 6.9827 - mean_squared_error: 356968.0000 - mean_absolute_error: 295.4000 - mean_absolute_percentage_error: 6.9827 - val_loss: 7.4880 - val_mean_squared_error: 586725.0000 - val_mean_absolute_error: 297.2956 - val_mean_absolute_percentage_error: 7.4880\n",
            "Epoch 270/1000\n",
            "506/506 [==============================] - 0s 654us/step - loss: 6.9407 - mean_squared_error: 354321.5000 - mean_absolute_error: 294.6630 - mean_absolute_percentage_error: 6.9407 - val_loss: 7.3724 - val_mean_squared_error: 584918.2500 - val_mean_absolute_error: 297.4436 - val_mean_absolute_percentage_error: 7.3724\n",
            "Epoch 271/1000\n",
            "506/506 [==============================] - 0s 657us/step - loss: 6.9698 - mean_squared_error: 357003.5312 - mean_absolute_error: 295.6488 - mean_absolute_percentage_error: 6.9698 - val_loss: 7.3608 - val_mean_squared_error: 579558.4375 - val_mean_absolute_error: 296.9875 - val_mean_absolute_percentage_error: 7.3608\n",
            "Epoch 272/1000\n",
            "506/506 [==============================] - 0s 651us/step - loss: 6.9821 - mean_squared_error: 356903.2188 - mean_absolute_error: 295.1931 - mean_absolute_percentage_error: 6.9821 - val_loss: 7.5359 - val_mean_squared_error: 593766.5000 - val_mean_absolute_error: 296.3381 - val_mean_absolute_percentage_error: 7.5359\n",
            "Epoch 273/1000\n",
            "506/506 [==============================] - 0s 714us/step - loss: 6.9931 - mean_squared_error: 357693.2812 - mean_absolute_error: 295.9193 - mean_absolute_percentage_error: 6.9931 - val_loss: 7.4038 - val_mean_squared_error: 573678.7500 - val_mean_absolute_error: 296.5547 - val_mean_absolute_percentage_error: 7.4038\n",
            "Epoch 274/1000\n",
            "506/506 [==============================] - 0s 728us/step - loss: 6.9474 - mean_squared_error: 354570.1250 - mean_absolute_error: 295.0993 - mean_absolute_percentage_error: 6.9474 - val_loss: 7.3904 - val_mean_squared_error: 594770.6875 - val_mean_absolute_error: 294.5723 - val_mean_absolute_percentage_error: 7.3904\n",
            "Epoch 275/1000\n",
            "506/506 [==============================] - 0s 668us/step - loss: 6.9585 - mean_squared_error: 355910.6250 - mean_absolute_error: 294.6886 - mean_absolute_percentage_error: 6.9585 - val_loss: 7.4407 - val_mean_squared_error: 591123.6875 - val_mean_absolute_error: 295.4887 - val_mean_absolute_percentage_error: 7.4407\n",
            "Epoch 276/1000\n",
            "506/506 [==============================] - 0s 659us/step - loss: 6.9588 - mean_squared_error: 355198.4062 - mean_absolute_error: 295.4163 - mean_absolute_percentage_error: 6.9588 - val_loss: 7.3530 - val_mean_squared_error: 575179.3125 - val_mean_absolute_error: 295.9106 - val_mean_absolute_percentage_error: 7.3530\n",
            "Epoch 277/1000\n",
            "506/506 [==============================] - 0s 723us/step - loss: 6.9491 - mean_squared_error: 354374.4688 - mean_absolute_error: 294.2566 - mean_absolute_percentage_error: 6.9491 - val_loss: 7.4416 - val_mean_squared_error: 576662.5625 - val_mean_absolute_error: 306.8356 - val_mean_absolute_percentage_error: 7.4416\n",
            "Epoch 278/1000\n",
            "506/506 [==============================] - 0s 654us/step - loss: 6.9446 - mean_squared_error: 356171.8125 - mean_absolute_error: 294.7516 - mean_absolute_percentage_error: 6.9446 - val_loss: 7.3454 - val_mean_squared_error: 577427.0625 - val_mean_absolute_error: 301.6035 - val_mean_absolute_percentage_error: 7.3454\n",
            "Epoch 279/1000\n",
            "506/506 [==============================] - 0s 656us/step - loss: 6.9309 - mean_squared_error: 355144.1562 - mean_absolute_error: 294.8888 - mean_absolute_percentage_error: 6.9309 - val_loss: 7.2946 - val_mean_squared_error: 573472.6875 - val_mean_absolute_error: 294.9276 - val_mean_absolute_percentage_error: 7.2946\n",
            "Epoch 280/1000\n",
            "506/506 [==============================] - 0s 755us/step - loss: 6.9603 - mean_squared_error: 353001.4375 - mean_absolute_error: 294.4503 - mean_absolute_percentage_error: 6.9603 - val_loss: 7.5023 - val_mean_squared_error: 577938.2500 - val_mean_absolute_error: 296.2898 - val_mean_absolute_percentage_error: 7.5023\n",
            "Epoch 281/1000\n",
            "506/506 [==============================] - 0s 683us/step - loss: 6.9343 - mean_squared_error: 354269.1250 - mean_absolute_error: 294.7038 - mean_absolute_percentage_error: 6.9343 - val_loss: 7.3887 - val_mean_squared_error: 578464.0000 - val_mean_absolute_error: 296.3609 - val_mean_absolute_percentage_error: 7.3887\n",
            "Epoch 282/1000\n",
            "506/506 [==============================] - 0s 742us/step - loss: 6.9515 - mean_squared_error: 357963.7500 - mean_absolute_error: 295.0826 - mean_absolute_percentage_error: 6.9515 - val_loss: 7.4708 - val_mean_squared_error: 572844.9375 - val_mean_absolute_error: 298.0054 - val_mean_absolute_percentage_error: 7.4708\n",
            "Epoch 283/1000\n",
            "506/506 [==============================] - 0s 657us/step - loss: 6.9322 - mean_squared_error: 351929.0938 - mean_absolute_error: 294.1686 - mean_absolute_percentage_error: 6.9322 - val_loss: 7.3407 - val_mean_squared_error: 579290.9375 - val_mean_absolute_error: 294.3720 - val_mean_absolute_percentage_error: 7.3407\n",
            "Epoch 284/1000\n",
            "506/506 [==============================] - 0s 671us/step - loss: 6.9296 - mean_squared_error: 352251.9375 - mean_absolute_error: 293.7573 - mean_absolute_percentage_error: 6.9296 - val_loss: 7.4326 - val_mean_squared_error: 583223.0000 - val_mean_absolute_error: 297.6501 - val_mean_absolute_percentage_error: 7.4326\n",
            "Epoch 285/1000\n",
            "506/506 [==============================] - 0s 669us/step - loss: 6.9292 - mean_squared_error: 352358.5625 - mean_absolute_error: 294.3951 - mean_absolute_percentage_error: 6.9292 - val_loss: 7.4278 - val_mean_squared_error: 587240.1250 - val_mean_absolute_error: 295.2140 - val_mean_absolute_percentage_error: 7.4278\n",
            "Epoch 286/1000\n",
            "506/506 [==============================] - 0s 873us/step - loss: 6.9229 - mean_squared_error: 353415.2500 - mean_absolute_error: 293.8807 - mean_absolute_percentage_error: 6.9229 - val_loss: 7.3544 - val_mean_squared_error: 572505.5625 - val_mean_absolute_error: 298.2917 - val_mean_absolute_percentage_error: 7.3544\n",
            "Epoch 287/1000\n",
            "506/506 [==============================] - 0s 690us/step - loss: 6.9367 - mean_squared_error: 354309.0938 - mean_absolute_error: 294.3799 - mean_absolute_percentage_error: 6.9367 - val_loss: 7.3717 - val_mean_squared_error: 578510.5000 - val_mean_absolute_error: 293.6544 - val_mean_absolute_percentage_error: 7.3717\n",
            "Epoch 288/1000\n",
            "506/506 [==============================] - 0s 660us/step - loss: 6.9372 - mean_squared_error: 353223.5938 - mean_absolute_error: 294.4002 - mean_absolute_percentage_error: 6.9372 - val_loss: 7.3561 - val_mean_squared_error: 575449.1250 - val_mean_absolute_error: 297.2880 - val_mean_absolute_percentage_error: 7.3561\n",
            "Epoch 289/1000\n",
            "506/506 [==============================] - 0s 662us/step - loss: 6.9347 - mean_squared_error: 355364.4375 - mean_absolute_error: 294.7610 - mean_absolute_percentage_error: 6.9347 - val_loss: 7.4818 - val_mean_squared_error: 600382.7500 - val_mean_absolute_error: 298.5048 - val_mean_absolute_percentage_error: 7.4818\n",
            "Epoch 290/1000\n",
            "506/506 [==============================] - 0s 658us/step - loss: 6.9248 - mean_squared_error: 353922.4375 - mean_absolute_error: 294.7345 - mean_absolute_percentage_error: 6.9248 - val_loss: 7.3280 - val_mean_squared_error: 571899.5000 - val_mean_absolute_error: 300.0801 - val_mean_absolute_percentage_error: 7.3280\n",
            "Epoch 291/1000\n",
            "506/506 [==============================] - 0s 896us/step - loss: 6.9326 - mean_squared_error: 353197.9688 - mean_absolute_error: 294.2056 - mean_absolute_percentage_error: 6.9326 - val_loss: 7.3600 - val_mean_squared_error: 569818.6250 - val_mean_absolute_error: 298.1697 - val_mean_absolute_percentage_error: 7.3600\n",
            "Epoch 292/1000\n",
            "506/506 [==============================] - 0s 772us/step - loss: 6.9324 - mean_squared_error: 353988.2500 - mean_absolute_error: 294.4302 - mean_absolute_percentage_error: 6.9324 - val_loss: 7.4265 - val_mean_squared_error: 574243.7500 - val_mean_absolute_error: 301.3235 - val_mean_absolute_percentage_error: 7.4265\n",
            "Epoch 293/1000\n",
            "506/506 [==============================] - 0s 743us/step - loss: 6.9260 - mean_squared_error: 351944.5312 - mean_absolute_error: 293.7639 - mean_absolute_percentage_error: 6.9260 - val_loss: 7.3860 - val_mean_squared_error: 573753.8125 - val_mean_absolute_error: 294.0342 - val_mean_absolute_percentage_error: 7.3860\n",
            "Epoch 294/1000\n",
            "506/506 [==============================] - 0s 758us/step - loss: 6.9288 - mean_squared_error: 353876.2500 - mean_absolute_error: 294.3261 - mean_absolute_percentage_error: 6.9288 - val_loss: 7.4467 - val_mean_squared_error: 574817.5000 - val_mean_absolute_error: 301.3900 - val_mean_absolute_percentage_error: 7.4467\n",
            "Epoch 295/1000\n",
            "506/506 [==============================] - 0s 682us/step - loss: 6.9072 - mean_squared_error: 354575.5938 - mean_absolute_error: 294.4969 - mean_absolute_percentage_error: 6.9072 - val_loss: 7.3191 - val_mean_squared_error: 568610.2500 - val_mean_absolute_error: 294.0014 - val_mean_absolute_percentage_error: 7.3191\n",
            "Epoch 296/1000\n",
            "506/506 [==============================] - 0s 763us/step - loss: 6.9149 - mean_squared_error: 353135.2500 - mean_absolute_error: 294.2390 - mean_absolute_percentage_error: 6.9149 - val_loss: 7.3835 - val_mean_squared_error: 599532.5000 - val_mean_absolute_error: 297.3142 - val_mean_absolute_percentage_error: 7.3835\n",
            "Epoch 297/1000\n",
            "506/506 [==============================] - 0s 685us/step - loss: 6.9187 - mean_squared_error: 351556.4688 - mean_absolute_error: 293.8651 - mean_absolute_percentage_error: 6.9187 - val_loss: 7.3137 - val_mean_squared_error: 569911.5625 - val_mean_absolute_error: 293.8283 - val_mean_absolute_percentage_error: 7.3137\n",
            "Epoch 298/1000\n",
            "506/506 [==============================] - 0s 746us/step - loss: 6.9196 - mean_squared_error: 354039.5000 - mean_absolute_error: 294.6257 - mean_absolute_percentage_error: 6.9196 - val_loss: 7.3870 - val_mean_squared_error: 592142.8125 - val_mean_absolute_error: 294.8101 - val_mean_absolute_percentage_error: 7.3870\n",
            "Epoch 299/1000\n",
            "506/506 [==============================] - 0s 689us/step - loss: 6.9293 - mean_squared_error: 352730.0938 - mean_absolute_error: 293.9195 - mean_absolute_percentage_error: 6.9293 - val_loss: 7.5281 - val_mean_squared_error: 574946.4375 - val_mean_absolute_error: 315.0891 - val_mean_absolute_percentage_error: 7.5281\n",
            "422/422 [==============================] - 0s 338us/step - loss: 6.9627 - mean_squared_error: 398303.6875 - mean_absolute_error: 299.3170 - mean_absolute_percentage_error: 6.9627\n",
            "[6.962660312652588, 398303.6875, 299.31695556640625, 6.962660312652588]\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "#Taper Deep Model\n",
        "normalizer = tf.keras.layers.Normalization(axis=-1)\n",
        "normalizer.adapt(np.array(X_tr_ex))\n",
        "\n",
        "mod_ex = keras.Sequential()\n",
        "mod_ex.add(normalizer)\n",
        "mod_ex.add(InputLayer(input_shape=(start_width,)))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(Dense(start_width/2, activation='relu'))\n",
        "mod_ex.add(Dense(start_width/2, activation='relu'))\n",
        "mod_ex.add(Dense(start_width/3, activation='relu'))\n",
        "mod_ex.add(Dense(start_width/3, activation='relu'))\n",
        "mod_ex.add(Dense(start_width/4, activation='relu'))\n",
        "mod_ex.add(Dense(1))\n",
        "\n",
        "mod_ex.compile(optimizer='adam', loss=\"mean_absolute_percentage_error\", metrics=[metrics.mean_squared_error, \n",
        "                                                                        metrics.mean_absolute_error, \n",
        "                                                                        metrics.mean_absolute_percentage_error])\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True) \n",
        "\n",
        "hist_ex = mod_ex.fit(\n",
        "  X_tr_ex,\n",
        "  y_tr_ex,\n",
        "  epochs=1000,\n",
        "  batch_size=64,\n",
        "  validation_split=0.2,\n",
        "  callbacks=[callback],\n",
        "  verbose=1\n",
        ")\n",
        "print(mod_ex.evaluate(X_te_ex, y_te_ex))\n",
        "plot_loss(hist_ex)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Best Trial\n",
        "\n",
        "This may vary a bit, but what I saw in the results above was broadly:\n",
        "<ul>\n",
        "<li> Train and test results improved by adding layers. </li>\n",
        "<li> Adding dropouts didn't help much. </li>\n",
        "<li> Batch normalization helped a bit. </li>\n",
        "<li> Tapering size down tended to help. </li>\n",
        "</ul>\n",
        "\n",
        "I tried a combo of those things to see the results. In general, this seemed to work best with a larger model, lots of training, and some normalization to keep it learning. There may be other structures that work just as well, or better, but from my trials, these patterns emerged from the results. I made a model to mirror that:\n",
        "<ul>\n",
        "<li> Start with a wide layer. </li>\n",
        "<li> Taper the width down. </li>\n",
        "<li> Have several layers (the model seemed to keep learning with more layers in previous trails)). </li>\n",
        "<li> Add batch normalization. (The loss flatlined previously). </li>\n",
        "<li> Allow for many epochs, until improvement stops. </li>\n",
        "</ul>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/6000\n",
            "6/6 [==============================] - 1s 34ms/step - loss: 99.9793 - val_loss: 99.9964\n",
            "Epoch 2/6000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 99.9419 - val_loss: 99.9925\n",
            "Epoch 3/6000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 99.9163 - val_loss: 99.9879\n",
            "Epoch 4/6000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 99.8935 - val_loss: 99.9806\n",
            "Epoch 5/6000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 99.8725 - val_loss: 99.9718\n",
            "Epoch 6/6000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 99.8536 - val_loss: 99.9618\n",
            "Epoch 7/6000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 99.8354 - val_loss: 99.9515\n",
            "Epoch 8/6000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 99.8187 - val_loss: 99.9416\n",
            "Epoch 9/6000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 99.8031 - val_loss: 99.9323\n",
            "Epoch 10/6000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 99.7888 - val_loss: 99.9236\n",
            "Epoch 11/6000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 99.7758 - val_loss: 99.9148\n",
            "Epoch 12/6000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 99.7636 - val_loss: 99.9060\n",
            "Epoch 13/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 99.7526 - val_loss: 99.8988\n",
            "Epoch 14/6000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 99.7421 - val_loss: 99.8925\n",
            "Epoch 15/6000\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 99.7322 - val_loss: 99.8867\n",
            "Epoch 16/6000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 99.7224 - val_loss: 99.8805\n",
            "Epoch 17/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 99.7125 - val_loss: 99.8727\n",
            "Epoch 18/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 99.7027 - val_loss: 99.8658\n",
            "Epoch 19/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 99.6930 - val_loss: 99.8588\n",
            "Epoch 20/6000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 99.6831 - val_loss: 99.8524\n",
            "Epoch 21/6000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 99.6732 - val_loss: 99.8455\n",
            "Epoch 22/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 99.6631 - val_loss: 99.8385\n",
            "Epoch 23/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 99.6533 - val_loss: 99.8311\n",
            "Epoch 24/6000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 99.6436 - val_loss: 99.8229\n",
            "Epoch 25/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 99.6342 - val_loss: 99.8150\n",
            "Epoch 26/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 99.6248 - val_loss: 99.8070\n",
            "Epoch 27/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 99.6153 - val_loss: 99.7987\n",
            "Epoch 28/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 99.6058 - val_loss: 99.7874\n",
            "Epoch 29/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 99.5961 - val_loss: 99.7792\n",
            "Epoch 30/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 99.5862 - val_loss: 99.7754\n",
            "Epoch 31/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 99.5762 - val_loss: 99.7709\n",
            "Epoch 32/6000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 99.5663 - val_loss: 99.7665\n",
            "Epoch 33/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 99.5566 - val_loss: 99.7587\n",
            "Epoch 34/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 99.5467 - val_loss: 99.7496\n",
            "Epoch 35/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 99.5369 - val_loss: 99.7434\n",
            "Epoch 36/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 99.5270 - val_loss: 99.7371\n",
            "Epoch 37/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 99.5171 - val_loss: 99.7289\n",
            "Epoch 38/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 99.5069 - val_loss: 99.7151\n",
            "Epoch 39/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 99.4967 - val_loss: 99.7117\n",
            "Epoch 40/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 99.4865 - val_loss: 99.7103\n",
            "Epoch 41/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 99.4761 - val_loss: 99.7069\n",
            "Epoch 42/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 99.4657 - val_loss: 99.7006\n",
            "Epoch 43/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 99.4551 - val_loss: 99.7009\n",
            "Epoch 44/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 99.4442 - val_loss: 99.7003\n",
            "Epoch 45/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 99.4334 - val_loss: 99.6934\n",
            "Epoch 46/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 99.4223 - val_loss: 99.6906\n",
            "Epoch 47/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 99.4113 - val_loss: 99.6886\n",
            "Epoch 48/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 99.4001 - val_loss: 99.6860\n",
            "Epoch 49/6000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 99.3887 - val_loss: 99.6886\n",
            "Epoch 50/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 99.3774 - val_loss: 99.6922\n",
            "Epoch 51/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 99.3661 - val_loss: 99.6984\n",
            "Epoch 52/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 99.3545 - val_loss: 99.7012\n",
            "Epoch 53/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 99.3429 - val_loss: 99.6968\n",
            "Epoch 54/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 99.3312 - val_loss: 99.6983\n",
            "Epoch 55/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 99.3194 - val_loss: 99.6923\n",
            "Epoch 56/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 99.3076 - val_loss: 99.6923\n",
            "Epoch 57/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 99.2956 - val_loss: 99.6864\n",
            "Epoch 58/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 99.2836 - val_loss: 99.6838\n",
            "Epoch 59/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 99.2713 - val_loss: 99.6804\n",
            "Epoch 60/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 99.2592 - val_loss: 99.6772\n",
            "Epoch 61/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 99.2468 - val_loss: 99.6810\n",
            "Epoch 62/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 99.2345 - val_loss: 99.6629\n",
            "Epoch 63/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 99.2221 - val_loss: 99.6604\n",
            "Epoch 64/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 99.2095 - val_loss: 99.6423\n",
            "Epoch 65/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 99.1970 - val_loss: 99.6239\n",
            "Epoch 66/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 99.1843 - val_loss: 99.6097\n",
            "Epoch 67/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 99.1716 - val_loss: 99.5924\n",
            "Epoch 68/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 99.1589 - val_loss: 99.5899\n",
            "Epoch 69/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 99.1459 - val_loss: 99.5885\n",
            "Epoch 70/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 99.1329 - val_loss: 99.5666\n",
            "Epoch 71/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 99.1200 - val_loss: 99.5386\n",
            "Epoch 72/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 99.1070 - val_loss: 99.5195\n",
            "Epoch 73/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 99.0933 - val_loss: 99.5062\n",
            "Epoch 74/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 99.0800 - val_loss: 99.4803\n",
            "Epoch 75/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 99.0666 - val_loss: 99.4736\n",
            "Epoch 76/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 99.0529 - val_loss: 99.4697\n",
            "Epoch 77/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 99.0393 - val_loss: 99.4655\n",
            "Epoch 78/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 99.0256 - val_loss: 99.4351\n",
            "Epoch 79/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 99.0117 - val_loss: 99.3969\n",
            "Epoch 80/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 98.9978 - val_loss: 99.3800\n",
            "Epoch 81/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 98.9834 - val_loss: 99.3561\n",
            "Epoch 82/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 98.9693 - val_loss: 99.3393\n",
            "Epoch 83/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 98.9549 - val_loss: 99.3220\n",
            "Epoch 84/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 98.9403 - val_loss: 99.2976\n",
            "Epoch 85/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 98.9254 - val_loss: 99.2966\n",
            "Epoch 86/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 98.9105 - val_loss: 99.2744\n",
            "Epoch 87/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 98.8946 - val_loss: 99.2807\n",
            "Epoch 88/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 98.8781 - val_loss: 99.3057\n",
            "Epoch 89/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 98.8615 - val_loss: 99.3155\n",
            "Epoch 90/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 98.8452 - val_loss: 99.3082\n",
            "Epoch 91/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 98.8294 - val_loss: 99.3343\n",
            "Epoch 92/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 98.8141 - val_loss: 99.3093\n",
            "Epoch 93/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 98.7982 - val_loss: 99.3173\n",
            "Epoch 94/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 98.7821 - val_loss: 99.3112\n",
            "Epoch 95/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 98.7661 - val_loss: 99.3026\n",
            "Epoch 96/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 98.7498 - val_loss: 99.2801\n",
            "Epoch 97/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 98.7340 - val_loss: 99.2946\n",
            "Epoch 98/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 98.7176 - val_loss: 99.2810\n",
            "Epoch 99/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 98.7013 - val_loss: 99.2770\n",
            "Epoch 100/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 98.6850 - val_loss: 99.2600\n",
            "Epoch 101/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 98.6681 - val_loss: 99.2408\n",
            "Epoch 102/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 98.6517 - val_loss: 99.2373\n",
            "Epoch 103/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 98.6348 - val_loss: 99.2198\n",
            "Epoch 104/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 98.6181 - val_loss: 99.2115\n",
            "Epoch 105/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 98.6008 - val_loss: 99.1964\n",
            "Epoch 106/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 98.5833 - val_loss: 99.2116\n",
            "Epoch 107/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 98.5660 - val_loss: 99.2200\n",
            "Epoch 108/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 98.5485 - val_loss: 99.1702\n",
            "Epoch 109/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 98.5308 - val_loss: 99.1744\n",
            "Epoch 110/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 98.5134 - val_loss: 99.1649\n",
            "Epoch 111/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 98.4960 - val_loss: 99.1587\n",
            "Epoch 112/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 98.4784 - val_loss: 99.1161\n",
            "Epoch 113/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 98.4606 - val_loss: 99.0611\n",
            "Epoch 114/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 98.4429 - val_loss: 99.0144\n",
            "Epoch 115/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 98.4246 - val_loss: 99.0034\n",
            "Epoch 116/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 98.4064 - val_loss: 98.9689\n",
            "Epoch 117/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 98.3887 - val_loss: 99.0197\n",
            "Epoch 118/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 98.3699 - val_loss: 98.9080\n",
            "Epoch 119/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 98.3518 - val_loss: 98.9170\n",
            "Epoch 120/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 98.3335 - val_loss: 98.8646\n",
            "Epoch 121/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 98.3144 - val_loss: 98.8396\n",
            "Epoch 122/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 98.2955 - val_loss: 98.8686\n",
            "Epoch 123/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 98.2767 - val_loss: 98.7816\n",
            "Epoch 124/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 98.2577 - val_loss: 98.8113\n",
            "Epoch 125/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 98.2387 - val_loss: 98.7819\n",
            "Epoch 126/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 98.2195 - val_loss: 98.6889\n",
            "Epoch 127/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 98.2007 - val_loss: 98.7140\n",
            "Epoch 128/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 98.1812 - val_loss: 98.6821\n",
            "Epoch 129/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 98.1617 - val_loss: 98.6662\n",
            "Epoch 130/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 98.1421 - val_loss: 98.6066\n",
            "Epoch 131/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 98.1226 - val_loss: 98.6110\n",
            "Epoch 132/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 98.1026 - val_loss: 98.5807\n",
            "Epoch 133/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 98.0828 - val_loss: 98.5288\n",
            "Epoch 134/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 98.0631 - val_loss: 98.5314\n",
            "Epoch 135/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 98.0430 - val_loss: 98.4869\n",
            "Epoch 136/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 98.0227 - val_loss: 98.4574\n",
            "Epoch 137/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 98.0021 - val_loss: 98.4335\n",
            "Epoch 138/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 97.9813 - val_loss: 98.4608\n",
            "Epoch 139/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 97.9612 - val_loss: 98.3097\n",
            "Epoch 140/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 97.9407 - val_loss: 98.2815\n",
            "Epoch 141/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 97.9200 - val_loss: 98.2828\n",
            "Epoch 142/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 97.8994 - val_loss: 98.2478\n",
            "Epoch 143/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 97.8783 - val_loss: 98.2143\n",
            "Epoch 144/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 97.8573 - val_loss: 98.2668\n",
            "Epoch 145/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 97.8361 - val_loss: 98.1919\n",
            "Epoch 146/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 97.8151 - val_loss: 98.2586\n",
            "Epoch 147/6000\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 97.7934 - val_loss: 98.2076\n",
            "Epoch 148/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 97.7717 - val_loss: 98.1756\n",
            "Epoch 149/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 97.7502 - val_loss: 98.1963\n",
            "Epoch 150/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 97.7282 - val_loss: 98.1455\n",
            "Epoch 151/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 97.7063 - val_loss: 98.0875\n",
            "Epoch 152/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 97.6845 - val_loss: 98.0726\n",
            "Epoch 153/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 97.6634 - val_loss: 98.0558\n",
            "Epoch 154/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 97.6412 - val_loss: 98.0389\n",
            "Epoch 155/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 97.6187 - val_loss: 97.9860\n",
            "Epoch 156/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 97.5963 - val_loss: 97.9989\n",
            "Epoch 157/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 97.5739 - val_loss: 97.9241\n",
            "Epoch 158/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 97.5516 - val_loss: 97.8887\n",
            "Epoch 159/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 97.5293 - val_loss: 97.8820\n",
            "Epoch 160/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 97.5058 - val_loss: 97.8314\n",
            "Epoch 161/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 97.4824 - val_loss: 97.8490\n",
            "Epoch 162/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 97.4591 - val_loss: 97.8795\n",
            "Epoch 163/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 97.4358 - val_loss: 97.8657\n",
            "Epoch 164/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 97.4134 - val_loss: 97.8779\n",
            "Epoch 165/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 97.3908 - val_loss: 97.6759\n",
            "Epoch 166/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 97.3671 - val_loss: 97.6439\n",
            "Epoch 167/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 97.3432 - val_loss: 97.6688\n",
            "Epoch 168/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 97.3200 - val_loss: 97.6847\n",
            "Epoch 169/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 97.2967 - val_loss: 97.6259\n",
            "Epoch 170/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 97.2734 - val_loss: 97.3758\n",
            "Epoch 171/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 97.2486 - val_loss: 97.5000\n",
            "Epoch 172/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 97.2248 - val_loss: 97.5536\n",
            "Epoch 173/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 97.1998 - val_loss: 97.5375\n",
            "Epoch 174/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 97.1757 - val_loss: 97.5446\n",
            "Epoch 175/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 97.1514 - val_loss: 97.5100\n",
            "Epoch 176/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 97.1263 - val_loss: 97.5330\n",
            "Epoch 177/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 97.1021 - val_loss: 97.3659\n",
            "Epoch 178/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 97.0772 - val_loss: 97.2349\n",
            "Epoch 179/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 97.0539 - val_loss: 97.3265\n",
            "Epoch 180/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 97.0284 - val_loss: 97.2883\n",
            "Epoch 181/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 97.0039 - val_loss: 97.2673\n",
            "Epoch 182/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 96.9785 - val_loss: 97.3586\n",
            "Epoch 183/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 96.9530 - val_loss: 97.2817\n",
            "Epoch 184/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 96.9281 - val_loss: 97.2485\n",
            "Epoch 185/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 96.9019 - val_loss: 97.2965\n",
            "Epoch 186/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 96.8768 - val_loss: 97.3186\n",
            "Epoch 187/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 96.8507 - val_loss: 97.3080\n",
            "Epoch 188/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 96.8257 - val_loss: 97.2290\n",
            "Epoch 189/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 96.7997 - val_loss: 97.1911\n",
            "Epoch 190/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 96.7737 - val_loss: 97.0887\n",
            "Epoch 191/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 96.7471 - val_loss: 97.1372\n",
            "Epoch 192/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 96.7213 - val_loss: 97.1259\n",
            "Epoch 193/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 96.6967 - val_loss: 97.0414\n",
            "Epoch 194/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 96.6711 - val_loss: 96.9738\n",
            "Epoch 195/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 96.6448 - val_loss: 96.9369\n",
            "Epoch 196/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 96.6172 - val_loss: 96.8103\n",
            "Epoch 197/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 96.5903 - val_loss: 96.7496\n",
            "Epoch 198/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 96.5638 - val_loss: 96.8616\n",
            "Epoch 199/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 96.5372 - val_loss: 96.8539\n",
            "Epoch 200/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 96.5105 - val_loss: 96.8065\n",
            "Epoch 201/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 96.4843 - val_loss: 96.8448\n",
            "Epoch 202/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 96.4574 - val_loss: 96.6603\n",
            "Epoch 203/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 96.4297 - val_loss: 96.7510\n",
            "Epoch 204/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 96.4017 - val_loss: 96.7071\n",
            "Epoch 205/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 96.3745 - val_loss: 96.6993\n",
            "Epoch 206/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 96.3465 - val_loss: 96.7091\n",
            "Epoch 207/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 96.3201 - val_loss: 96.6536\n",
            "Epoch 208/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 96.2928 - val_loss: 96.4760\n",
            "Epoch 209/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 96.2648 - val_loss: 96.4230\n",
            "Epoch 210/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 96.2363 - val_loss: 96.4096\n",
            "Epoch 211/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 96.2083 - val_loss: 96.4393\n",
            "Epoch 212/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 96.1809 - val_loss: 96.3069\n",
            "Epoch 213/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 96.1522 - val_loss: 96.5116\n",
            "Epoch 214/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 96.1239 - val_loss: 96.4941\n",
            "Epoch 215/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 96.0954 - val_loss: 96.4712\n",
            "Epoch 216/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 96.0672 - val_loss: 96.3622\n",
            "Epoch 217/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 96.0382 - val_loss: 96.1192\n",
            "Epoch 218/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 96.0101 - val_loss: 96.0823\n",
            "Epoch 219/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 95.9818 - val_loss: 96.0576\n",
            "Epoch 220/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 95.9530 - val_loss: 96.1068\n",
            "Epoch 221/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 95.9262 - val_loss: 95.9558\n",
            "Epoch 222/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 95.8953 - val_loss: 95.9650\n",
            "Epoch 223/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 95.8660 - val_loss: 96.0674\n",
            "Epoch 224/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 95.8373 - val_loss: 96.0882\n",
            "Epoch 225/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 95.8081 - val_loss: 96.0108\n",
            "Epoch 226/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 95.7783 - val_loss: 96.0622\n",
            "Epoch 227/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 95.7485 - val_loss: 96.0383\n",
            "Epoch 228/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 95.7191 - val_loss: 96.1023\n",
            "Epoch 229/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 95.6885 - val_loss: 95.9804\n",
            "Epoch 230/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 95.6582 - val_loss: 95.9556\n",
            "Epoch 231/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 95.6288 - val_loss: 95.8546\n",
            "Epoch 232/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 95.5996 - val_loss: 95.9967\n",
            "Epoch 233/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 95.5687 - val_loss: 95.7494\n",
            "Epoch 234/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 95.5381 - val_loss: 95.8562\n",
            "Epoch 235/6000\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 95.5081 - val_loss: 95.7678\n",
            "Epoch 236/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 95.4777 - val_loss: 95.8201\n",
            "Epoch 237/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 95.4474 - val_loss: 95.6508\n",
            "Epoch 238/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 95.4168 - val_loss: 95.7544\n",
            "Epoch 239/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 95.3860 - val_loss: 95.6729\n",
            "Epoch 240/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 95.3565 - val_loss: 95.6262\n",
            "Epoch 241/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 95.3254 - val_loss: 95.7330\n",
            "Epoch 242/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 95.2951 - val_loss: 95.5306\n",
            "Epoch 243/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 95.2651 - val_loss: 95.5892\n",
            "Epoch 244/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 95.2322 - val_loss: 95.4382\n",
            "Epoch 245/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 95.2023 - val_loss: 95.2367\n",
            "Epoch 246/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 95.1706 - val_loss: 95.3029\n",
            "Epoch 247/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 95.1391 - val_loss: 95.2346\n",
            "Epoch 248/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 95.1060 - val_loss: 95.2700\n",
            "Epoch 249/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 95.0754 - val_loss: 95.2820\n",
            "Epoch 250/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 95.0435 - val_loss: 95.0797\n",
            "Epoch 251/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 95.0116 - val_loss: 95.0644\n",
            "Epoch 252/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 94.9789 - val_loss: 95.1839\n",
            "Epoch 253/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 94.9475 - val_loss: 95.1099\n",
            "Epoch 254/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 94.9162 - val_loss: 95.1992\n",
            "Epoch 255/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 94.8838 - val_loss: 94.8793\n",
            "Epoch 256/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 94.8511 - val_loss: 94.9508\n",
            "Epoch 257/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 94.8200 - val_loss: 94.8079\n",
            "Epoch 258/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 94.7872 - val_loss: 94.8838\n",
            "Epoch 259/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 94.7542 - val_loss: 94.7523\n",
            "Epoch 260/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 94.7208 - val_loss: 94.9708\n",
            "Epoch 261/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 94.6879 - val_loss: 94.9112\n",
            "Epoch 262/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 94.6551 - val_loss: 94.8952\n",
            "Epoch 263/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 94.6216 - val_loss: 94.8624\n",
            "Epoch 264/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 94.5892 - val_loss: 94.7847\n",
            "Epoch 265/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 94.5561 - val_loss: 94.7517\n",
            "Epoch 266/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 94.5230 - val_loss: 94.7175\n",
            "Epoch 267/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 94.4898 - val_loss: 94.7714\n",
            "Epoch 268/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 94.4565 - val_loss: 94.0056\n",
            "Epoch 269/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 94.4630 - val_loss: 92.1690\n",
            "Epoch 270/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 94.4277 - val_loss: 91.8439\n",
            "Epoch 271/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 94.3835 - val_loss: 91.6915\n",
            "Epoch 272/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 94.3435 - val_loss: 91.5611\n",
            "Epoch 273/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 94.3056 - val_loss: 91.7476\n",
            "Epoch 274/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 94.2702 - val_loss: 92.0329\n",
            "Epoch 275/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 94.2349 - val_loss: 92.3413\n",
            "Epoch 276/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 94.1986 - val_loss: 92.8251\n",
            "Epoch 277/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 94.1628 - val_loss: 93.1374\n",
            "Epoch 278/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 94.1281 - val_loss: 93.3042\n",
            "Epoch 279/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 94.0935 - val_loss: 93.4580\n",
            "Epoch 280/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 94.0579 - val_loss: 93.5492\n",
            "Epoch 281/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 94.0230 - val_loss: 93.6757\n",
            "Epoch 282/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 93.9885 - val_loss: 93.8151\n",
            "Epoch 283/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 93.9531 - val_loss: 93.9859\n",
            "Epoch 284/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 93.9170 - val_loss: 93.9570\n",
            "Epoch 285/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 93.8818 - val_loss: 94.1544\n",
            "Epoch 286/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 93.8458 - val_loss: 94.1082\n",
            "Epoch 287/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 93.8106 - val_loss: 94.1585\n",
            "Epoch 288/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 93.7768 - val_loss: 93.9348\n",
            "Epoch 289/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 93.7415 - val_loss: 94.1668\n",
            "Epoch 290/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 93.7041 - val_loss: 94.0360\n",
            "Epoch 291/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 93.6685 - val_loss: 94.1920\n",
            "Epoch 292/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 93.6337 - val_loss: 94.1621\n",
            "Epoch 293/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 93.5971 - val_loss: 94.0779\n",
            "Epoch 294/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 93.5608 - val_loss: 94.1061\n",
            "Epoch 295/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 93.5257 - val_loss: 94.0665\n",
            "Epoch 296/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 93.4897 - val_loss: 93.9734\n",
            "Epoch 297/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 93.4543 - val_loss: 93.9626\n",
            "Epoch 298/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 93.4216 - val_loss: 93.8759\n",
            "Epoch 299/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 93.3854 - val_loss: 93.8442\n",
            "Epoch 300/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 93.3466 - val_loss: 93.8600\n",
            "Epoch 301/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 93.3084 - val_loss: 93.7262\n",
            "Epoch 302/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 93.2725 - val_loss: 93.8151\n",
            "Epoch 303/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 93.2373 - val_loss: 93.6237\n",
            "Epoch 304/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 93.2004 - val_loss: 93.7916\n",
            "Epoch 305/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 93.1630 - val_loss: 93.6073\n",
            "Epoch 306/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 93.1250 - val_loss: 93.7444\n",
            "Epoch 307/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 93.0882 - val_loss: 93.4064\n",
            "Epoch 308/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 93.0546 - val_loss: 93.4331\n",
            "Epoch 309/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 93.0163 - val_loss: 93.3412\n",
            "Epoch 310/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 92.9800 - val_loss: 93.2997\n",
            "Epoch 311/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 92.9417 - val_loss: 93.3121\n",
            "Epoch 312/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 92.9038 - val_loss: 93.4373\n",
            "Epoch 313/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 92.8665 - val_loss: 93.1454\n",
            "Epoch 314/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 92.8283 - val_loss: 93.2104\n",
            "Epoch 315/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 92.7916 - val_loss: 93.3575\n",
            "Epoch 316/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 92.7532 - val_loss: 93.1678\n",
            "Epoch 317/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 92.7156 - val_loss: 93.3197\n",
            "Epoch 318/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 92.6770 - val_loss: 93.0508\n",
            "Epoch 319/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 92.6388 - val_loss: 93.0283\n",
            "Epoch 320/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 92.6004 - val_loss: 93.0626\n",
            "Epoch 321/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 92.5640 - val_loss: 92.9288\n",
            "Epoch 322/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 92.5263 - val_loss: 92.8695\n",
            "Epoch 323/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 92.4876 - val_loss: 92.7843\n",
            "Epoch 324/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 92.4477 - val_loss: 92.7539\n",
            "Epoch 325/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 92.4096 - val_loss: 92.8378\n",
            "Epoch 326/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 92.3706 - val_loss: 92.7457\n",
            "Epoch 327/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 92.3338 - val_loss: 92.6861\n",
            "Epoch 328/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 92.2940 - val_loss: 92.5320\n",
            "Epoch 329/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 92.2541 - val_loss: 92.6066\n",
            "Epoch 330/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 92.2160 - val_loss: 92.6555\n",
            "Epoch 331/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 92.1769 - val_loss: 92.7900\n",
            "Epoch 332/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 92.1384 - val_loss: 92.4312\n",
            "Epoch 333/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 92.1012 - val_loss: 92.3648\n",
            "Epoch 334/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 92.0613 - val_loss: 92.2921\n",
            "Epoch 335/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 92.0219 - val_loss: 92.3674\n",
            "Epoch 336/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 91.9810 - val_loss: 92.4398\n",
            "Epoch 337/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 91.9414 - val_loss: 92.0881\n",
            "Epoch 338/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 91.9012 - val_loss: 92.4128\n",
            "Epoch 339/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 91.8632 - val_loss: 92.3346\n",
            "Epoch 340/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 91.8218 - val_loss: 92.1509\n",
            "Epoch 341/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 91.7833 - val_loss: 92.3266\n",
            "Epoch 342/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 91.7439 - val_loss: 91.9502\n",
            "Epoch 343/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 91.7051 - val_loss: 92.0764\n",
            "Epoch 344/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 91.6649 - val_loss: 92.2626\n",
            "Epoch 345/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 91.6257 - val_loss: 91.8625\n",
            "Epoch 346/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 91.5847 - val_loss: 92.0385\n",
            "Epoch 347/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 91.5417 - val_loss: 91.8563\n",
            "Epoch 348/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 91.5038 - val_loss: 91.9616\n",
            "Epoch 349/6000\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 91.4609 - val_loss: 91.7505\n",
            "Epoch 350/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 91.4215 - val_loss: 91.7756\n",
            "Epoch 351/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 91.3820 - val_loss: 91.6368\n",
            "Epoch 352/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 91.3409 - val_loss: 91.4604\n",
            "Epoch 353/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 91.3008 - val_loss: 91.3973\n",
            "Epoch 354/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 91.2597 - val_loss: 91.3851\n",
            "Epoch 355/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 91.2192 - val_loss: 91.1625\n",
            "Epoch 356/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 91.1774 - val_loss: 91.3596\n",
            "Epoch 357/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 91.1360 - val_loss: 91.3208\n",
            "Epoch 358/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 91.0956 - val_loss: 91.2312\n",
            "Epoch 359/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 91.0530 - val_loss: 91.2175\n",
            "Epoch 360/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 91.0137 - val_loss: 91.0810\n",
            "Epoch 361/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 90.9727 - val_loss: 90.9413\n",
            "Epoch 362/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 90.9296 - val_loss: 90.9100\n",
            "Epoch 363/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 90.8887 - val_loss: 90.9546\n",
            "Epoch 364/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 90.8472 - val_loss: 90.7060\n",
            "Epoch 365/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 90.8071 - val_loss: 90.8275\n",
            "Epoch 366/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 90.7653 - val_loss: 90.7699\n",
            "Epoch 367/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 90.7219 - val_loss: 90.6575\n",
            "Epoch 368/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 90.6791 - val_loss: 90.7164\n",
            "Epoch 369/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 90.6385 - val_loss: 90.7327\n",
            "Epoch 370/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 90.5950 - val_loss: 90.7770\n",
            "Epoch 371/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 90.5537 - val_loss: 90.5891\n",
            "Epoch 372/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 90.5122 - val_loss: 90.4890\n",
            "Epoch 373/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 90.4715 - val_loss: 90.6065\n",
            "Epoch 374/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 90.4296 - val_loss: 90.3704\n",
            "Epoch 375/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 90.3863 - val_loss: 90.3616\n",
            "Epoch 376/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 90.3420 - val_loss: 90.1318\n",
            "Epoch 377/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 90.2984 - val_loss: 90.4917\n",
            "Epoch 378/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 90.2566 - val_loss: 90.1231\n",
            "Epoch 379/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 90.2149 - val_loss: 89.8969\n",
            "Epoch 380/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 90.1741 - val_loss: 90.1101\n",
            "Epoch 381/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 90.1306 - val_loss: 90.1546\n",
            "Epoch 382/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 90.0912 - val_loss: 89.9887\n",
            "Epoch 383/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 90.0443 - val_loss: 89.5286\n",
            "Epoch 384/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 90.0018 - val_loss: 89.8927\n",
            "Epoch 385/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 89.9587 - val_loss: 89.7758\n",
            "Epoch 386/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 89.9162 - val_loss: 89.7318\n",
            "Epoch 387/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 89.8725 - val_loss: 89.6099\n",
            "Epoch 388/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 89.8296 - val_loss: 89.4991\n",
            "Epoch 389/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 89.7873 - val_loss: 89.2193\n",
            "Epoch 390/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 89.7426 - val_loss: 89.5290\n",
            "Epoch 391/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 89.7002 - val_loss: 89.2613\n",
            "Epoch 392/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 89.6568 - val_loss: 89.4136\n",
            "Epoch 393/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 89.6120 - val_loss: 88.9105\n",
            "Epoch 394/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 89.5682 - val_loss: 89.2873\n",
            "Epoch 395/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 89.5265 - val_loss: 89.0524\n",
            "Epoch 396/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 89.4821 - val_loss: 89.0249\n",
            "Epoch 397/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 89.4383 - val_loss: 88.9271\n",
            "Epoch 398/6000\n",
            "6/6 [==============================] - 0s 39ms/step - loss: 89.3928 - val_loss: 89.0814\n",
            "Epoch 399/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 89.3499 - val_loss: 89.0196\n",
            "Epoch 400/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 89.3068 - val_loss: 88.6779\n",
            "Epoch 401/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 89.2612 - val_loss: 89.1069\n",
            "Epoch 402/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 89.2195 - val_loss: 88.5979\n",
            "Epoch 403/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 89.1731 - val_loss: 88.7800\n",
            "Epoch 404/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 89.1300 - val_loss: 88.8083\n",
            "Epoch 405/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 89.0843 - val_loss: 88.5184\n",
            "Epoch 406/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 89.0391 - val_loss: 88.7423\n",
            "Epoch 407/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 88.9937 - val_loss: 88.5950\n",
            "Epoch 408/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 88.9493 - val_loss: 88.3208\n",
            "Epoch 409/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 88.9069 - val_loss: 88.4967\n",
            "Epoch 410/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 88.8619 - val_loss: 88.7270\n",
            "Epoch 411/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 88.8181 - val_loss: 88.0132\n",
            "Epoch 412/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 88.7736 - val_loss: 88.3430\n",
            "Epoch 413/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 88.7287 - val_loss: 88.1032\n",
            "Epoch 414/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 88.6848 - val_loss: 88.0362\n",
            "Epoch 415/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 88.6401 - val_loss: 88.1058\n",
            "Epoch 416/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 88.5930 - val_loss: 87.8787\n",
            "Epoch 417/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 88.5510 - val_loss: 88.0440\n",
            "Epoch 418/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 88.5045 - val_loss: 88.0305\n",
            "Epoch 419/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 88.4587 - val_loss: 88.1693\n",
            "Epoch 420/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 88.4144 - val_loss: 88.1576\n",
            "Epoch 421/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 88.3687 - val_loss: 88.0844\n",
            "Epoch 422/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 88.3231 - val_loss: 87.7135\n",
            "Epoch 423/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 88.2779 - val_loss: 87.9426\n",
            "Epoch 424/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 88.2324 - val_loss: 87.6834\n",
            "Epoch 425/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 88.1847 - val_loss: 87.4735\n",
            "Epoch 426/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 88.1420 - val_loss: 87.5413\n",
            "Epoch 427/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 88.0949 - val_loss: 87.3566\n",
            "Epoch 428/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 88.0482 - val_loss: 87.2411\n",
            "Epoch 429/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 88.0021 - val_loss: 87.3349\n",
            "Epoch 430/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 87.9577 - val_loss: 87.4979\n",
            "Epoch 431/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 87.9124 - val_loss: 86.9453\n",
            "Epoch 432/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 87.8678 - val_loss: 87.4733\n",
            "Epoch 433/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 87.8232 - val_loss: 86.9473\n",
            "Epoch 434/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 87.7761 - val_loss: 86.9079\n",
            "Epoch 435/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 87.7270 - val_loss: 87.2109\n",
            "Epoch 436/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 87.6816 - val_loss: 87.1693\n",
            "Epoch 437/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 87.6388 - val_loss: 86.6628\n",
            "Epoch 438/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 87.5915 - val_loss: 86.9388\n",
            "Epoch 439/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 87.5450 - val_loss: 86.3108\n",
            "Epoch 440/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 87.5004 - val_loss: 86.5770\n",
            "Epoch 441/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 87.4517 - val_loss: 86.8728\n",
            "Epoch 442/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 87.4043 - val_loss: 86.5530\n",
            "Epoch 443/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 87.3576 - val_loss: 86.5865\n",
            "Epoch 444/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 87.3104 - val_loss: 86.5597\n",
            "Epoch 445/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 87.2654 - val_loss: 86.0256\n",
            "Epoch 446/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 87.2164 - val_loss: 86.4422\n",
            "Epoch 447/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 87.1711 - val_loss: 86.2074\n",
            "Epoch 448/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 87.1259 - val_loss: 86.0085\n",
            "Epoch 449/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 87.0775 - val_loss: 85.5590\n",
            "Epoch 450/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 87.0301 - val_loss: 86.2151\n",
            "Epoch 451/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 86.9825 - val_loss: 86.1004\n",
            "Epoch 452/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 86.9395 - val_loss: 85.5325\n",
            "Epoch 453/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 86.8924 - val_loss: 85.8585\n",
            "Epoch 454/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 86.8444 - val_loss: 85.6958\n",
            "Epoch 455/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 86.7980 - val_loss: 85.6982\n",
            "Epoch 456/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 86.7531 - val_loss: 85.4544\n",
            "Epoch 457/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 86.7053 - val_loss: 85.6991\n",
            "Epoch 458/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 86.6568 - val_loss: 85.2238\n",
            "Epoch 459/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 86.6077 - val_loss: 85.3801\n",
            "Epoch 460/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 86.5640 - val_loss: 85.5341\n",
            "Epoch 461/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 86.5174 - val_loss: 85.0930\n",
            "Epoch 462/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 86.4696 - val_loss: 85.2061\n",
            "Epoch 463/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 86.4229 - val_loss: 85.2541\n",
            "Epoch 464/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 86.3754 - val_loss: 85.1174\n",
            "Epoch 465/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 86.3240 - val_loss: 85.4592\n",
            "Epoch 466/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 86.2797 - val_loss: 85.2734\n",
            "Epoch 467/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 86.2343 - val_loss: 85.1125\n",
            "Epoch 468/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 86.1852 - val_loss: 84.6144\n",
            "Epoch 469/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 86.1395 - val_loss: 85.1533\n",
            "Epoch 470/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 86.0905 - val_loss: 85.1240\n",
            "Epoch 471/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 86.0420 - val_loss: 84.5506\n",
            "Epoch 472/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 85.9977 - val_loss: 84.6681\n",
            "Epoch 473/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 85.9491 - val_loss: 84.7458\n",
            "Epoch 474/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 85.9003 - val_loss: 84.4863\n",
            "Epoch 475/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 85.8548 - val_loss: 85.1219\n",
            "Epoch 476/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 85.8112 - val_loss: 84.3209\n",
            "Epoch 477/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 85.7622 - val_loss: 85.0421\n",
            "Epoch 478/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 85.7116 - val_loss: 84.4166\n",
            "Epoch 479/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 85.6622 - val_loss: 84.9986\n",
            "Epoch 480/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 85.6129 - val_loss: 84.3292\n",
            "Epoch 481/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 85.5689 - val_loss: 84.2849\n",
            "Epoch 482/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 85.5188 - val_loss: 84.5350\n",
            "Epoch 483/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 85.4683 - val_loss: 84.5928\n",
            "Epoch 484/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 85.4222 - val_loss: 84.1648\n",
            "Epoch 485/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 85.3727 - val_loss: 84.4789\n",
            "Epoch 486/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 85.3231 - val_loss: 84.1741\n",
            "Epoch 487/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 85.2803 - val_loss: 83.9263\n",
            "Epoch 488/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 85.2334 - val_loss: 84.1749\n",
            "Epoch 489/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 85.1814 - val_loss: 84.2143\n",
            "Epoch 490/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 85.1316 - val_loss: 84.0836\n",
            "Epoch 491/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 85.0847 - val_loss: 84.4208\n",
            "Epoch 492/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 85.0326 - val_loss: 83.9949\n",
            "Epoch 493/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 84.9890 - val_loss: 84.0555\n",
            "Epoch 494/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 84.9396 - val_loss: 83.6555\n",
            "Epoch 495/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 84.8942 - val_loss: 83.8784\n",
            "Epoch 496/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 84.8450 - val_loss: 83.6273\n",
            "Epoch 497/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 84.7977 - val_loss: 83.4660\n",
            "Epoch 498/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 84.7475 - val_loss: 83.3803\n",
            "Epoch 499/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 84.6999 - val_loss: 83.6596\n",
            "Epoch 500/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 84.6513 - val_loss: 83.4023\n",
            "Epoch 501/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 84.6035 - val_loss: 83.8000\n",
            "Epoch 502/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 84.5520 - val_loss: 83.3695\n",
            "Epoch 503/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 84.5009 - val_loss: 83.7230\n",
            "Epoch 504/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 84.4531 - val_loss: 82.6270\n",
            "Epoch 505/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 84.4096 - val_loss: 83.4162\n",
            "Epoch 506/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 84.3593 - val_loss: 83.1571\n",
            "Epoch 507/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 84.3115 - val_loss: 82.9109\n",
            "Epoch 508/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 84.2630 - val_loss: 83.4081\n",
            "Epoch 509/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 84.2135 - val_loss: 82.7555\n",
            "Epoch 510/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 84.1655 - val_loss: 83.0195\n",
            "Epoch 511/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 84.1176 - val_loss: 82.9639\n",
            "Epoch 512/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 84.0671 - val_loss: 82.7041\n",
            "Epoch 513/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 84.0193 - val_loss: 82.9116\n",
            "Epoch 514/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 83.9679 - val_loss: 82.6520\n",
            "Epoch 515/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 83.9186 - val_loss: 82.7380\n",
            "Epoch 516/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 83.8725 - val_loss: 82.9506\n",
            "Epoch 517/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 83.8226 - val_loss: 82.5404\n",
            "Epoch 518/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 83.7742 - val_loss: 82.7742\n",
            "Epoch 519/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 83.7232 - val_loss: 82.7725\n",
            "Epoch 520/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 83.6761 - val_loss: 82.8752\n",
            "Epoch 521/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 83.6281 - val_loss: 82.6078\n",
            "Epoch 522/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 83.5783 - val_loss: 82.7236\n",
            "Epoch 523/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 83.5282 - val_loss: 82.4115\n",
            "Epoch 524/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 83.4759 - val_loss: 82.4035\n",
            "Epoch 525/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 83.4285 - val_loss: 82.1838\n",
            "Epoch 526/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 83.3791 - val_loss: 82.7714\n",
            "Epoch 527/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 83.3313 - val_loss: 81.9568\n",
            "Epoch 528/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 83.2835 - val_loss: 82.8939\n",
            "Epoch 529/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 83.2355 - val_loss: 82.1784\n",
            "Epoch 530/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 83.1862 - val_loss: 81.9172\n",
            "Epoch 531/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 83.1354 - val_loss: 82.1171\n",
            "Epoch 532/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 83.0876 - val_loss: 82.1671\n",
            "Epoch 533/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 83.0405 - val_loss: 82.0458\n",
            "Epoch 534/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 82.9961 - val_loss: 81.3679\n",
            "Epoch 535/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 82.9525 - val_loss: 82.3509\n",
            "Epoch 536/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 82.9008 - val_loss: 81.9136\n",
            "Epoch 537/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 82.8491 - val_loss: 81.6960\n",
            "Epoch 538/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 82.8054 - val_loss: 81.7100\n",
            "Epoch 539/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 82.7491 - val_loss: 81.4627\n",
            "Epoch 540/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 82.6946 - val_loss: 81.8602\n",
            "Epoch 541/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 82.6412 - val_loss: 81.9766\n",
            "Epoch 542/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 82.5956 - val_loss: 81.5493\n",
            "Epoch 543/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 82.5547 - val_loss: 81.5210\n",
            "Epoch 544/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 82.5060 - val_loss: 80.9951\n",
            "Epoch 545/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 82.4553 - val_loss: 81.2716\n",
            "Epoch 546/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 82.4009 - val_loss: 81.1057\n",
            "Epoch 547/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 82.3509 - val_loss: 80.9937\n",
            "Epoch 548/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 82.3003 - val_loss: 81.5912\n",
            "Epoch 549/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 82.2510 - val_loss: 81.0263\n",
            "Epoch 550/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 82.2001 - val_loss: 81.5496\n",
            "Epoch 551/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 82.1596 - val_loss: 80.7633\n",
            "Epoch 552/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 82.1130 - val_loss: 81.1119\n",
            "Epoch 553/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 82.0679 - val_loss: 80.5386\n",
            "Epoch 554/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 82.0177 - val_loss: 80.7171\n",
            "Epoch 555/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 81.9638 - val_loss: 80.8693\n",
            "Epoch 556/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 81.9207 - val_loss: 80.6412\n",
            "Epoch 557/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 81.8712 - val_loss: 81.0109\n",
            "Epoch 558/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 81.8105 - val_loss: 80.6971\n",
            "Epoch 559/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 81.7599 - val_loss: 80.4747\n",
            "Epoch 560/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 81.7143 - val_loss: 80.5828\n",
            "Epoch 561/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 81.6693 - val_loss: 80.1735\n",
            "Epoch 562/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 81.6211 - val_loss: 80.8916\n",
            "Epoch 563/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 81.5681 - val_loss: 80.4058\n",
            "Epoch 564/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 81.5181 - val_loss: 80.0031\n",
            "Epoch 565/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 81.4695 - val_loss: 79.9268\n",
            "Epoch 566/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 81.4197 - val_loss: 80.4234\n",
            "Epoch 567/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 81.3714 - val_loss: 80.1888\n",
            "Epoch 568/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 81.3213 - val_loss: 80.0441\n",
            "Epoch 569/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 81.2735 - val_loss: 80.6499\n",
            "Epoch 570/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 81.2322 - val_loss: 80.0388\n",
            "Epoch 571/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 81.1791 - val_loss: 79.8940\n",
            "Epoch 572/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 81.1301 - val_loss: 80.2036\n",
            "Epoch 573/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 81.0749 - val_loss: 79.5705\n",
            "Epoch 574/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 81.0396 - val_loss: 79.8873\n",
            "Epoch 575/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 80.9884 - val_loss: 79.2575\n",
            "Epoch 576/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 80.9318 - val_loss: 79.3487\n",
            "Epoch 577/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 80.8910 - val_loss: 79.3967\n",
            "Epoch 578/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 80.8319 - val_loss: 79.4152\n",
            "Epoch 579/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 80.7822 - val_loss: 79.1446\n",
            "Epoch 580/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 80.7360 - val_loss: 79.7314\n",
            "Epoch 581/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 80.6820 - val_loss: 79.1550\n",
            "Epoch 582/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 80.6419 - val_loss: 79.4515\n",
            "Epoch 583/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 80.5869 - val_loss: 79.2188\n",
            "Epoch 584/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 80.5480 - val_loss: 79.5172\n",
            "Epoch 585/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 80.4901 - val_loss: 79.4127\n",
            "Epoch 586/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 80.4371 - val_loss: 79.0876\n",
            "Epoch 587/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 80.3860 - val_loss: 79.4141\n",
            "Epoch 588/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 80.3400 - val_loss: 78.6995\n",
            "Epoch 589/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 80.2969 - val_loss: 79.2517\n",
            "Epoch 590/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 80.2455 - val_loss: 78.9563\n",
            "Epoch 591/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 80.2037 - val_loss: 78.5661\n",
            "Epoch 592/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 80.1468 - val_loss: 79.0757\n",
            "Epoch 593/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 80.0933 - val_loss: 78.8235\n",
            "Epoch 594/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 80.0439 - val_loss: 79.1633\n",
            "Epoch 595/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 79.9954 - val_loss: 78.7899\n",
            "Epoch 596/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 79.9458 - val_loss: 78.7315\n",
            "Epoch 597/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 79.8986 - val_loss: 78.4157\n",
            "Epoch 598/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 79.8545 - val_loss: 78.4541\n",
            "Epoch 599/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 79.7979 - val_loss: 78.6704\n",
            "Epoch 600/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 79.7519 - val_loss: 78.7634\n",
            "Epoch 601/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 79.7053 - val_loss: 78.3586\n",
            "Epoch 602/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 79.6593 - val_loss: 78.8233\n",
            "Epoch 603/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 79.6086 - val_loss: 78.1219\n",
            "Epoch 604/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 79.5674 - val_loss: 78.7343\n",
            "Epoch 605/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 79.5219 - val_loss: 77.7235\n",
            "Epoch 606/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 79.4816 - val_loss: 78.6221\n",
            "Epoch 607/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 79.4247 - val_loss: 77.8320\n",
            "Epoch 608/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 79.3751 - val_loss: 78.2190\n",
            "Epoch 609/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 79.3200 - val_loss: 78.3508\n",
            "Epoch 610/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 79.2669 - val_loss: 78.1999\n",
            "Epoch 611/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 79.2223 - val_loss: 78.0121\n",
            "Epoch 612/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 79.1749 - val_loss: 77.8424\n",
            "Epoch 613/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 79.1272 - val_loss: 77.9872\n",
            "Epoch 614/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 79.0728 - val_loss: 77.8148\n",
            "Epoch 615/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 79.0261 - val_loss: 77.7662\n",
            "Epoch 616/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 78.9736 - val_loss: 77.8730\n",
            "Epoch 617/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 78.9304 - val_loss: 78.0387\n",
            "Epoch 618/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 78.8817 - val_loss: 77.7076\n",
            "Epoch 619/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 78.8267 - val_loss: 77.6386\n",
            "Epoch 620/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 78.7771 - val_loss: 77.9392\n",
            "Epoch 621/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 78.7261 - val_loss: 77.2929\n",
            "Epoch 622/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 78.6803 - val_loss: 77.8937\n",
            "Epoch 623/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 78.6290 - val_loss: 77.2565\n",
            "Epoch 624/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 78.5885 - val_loss: 77.6367\n",
            "Epoch 625/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 78.5542 - val_loss: 77.3704\n",
            "Epoch 626/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 78.4962 - val_loss: 77.3023\n",
            "Epoch 627/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 78.4499 - val_loss: 77.2358\n",
            "Epoch 628/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 78.3994 - val_loss: 77.0505\n",
            "Epoch 629/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 78.3442 - val_loss: 77.2502\n",
            "Epoch 630/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 78.2936 - val_loss: 77.0028\n",
            "Epoch 631/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 78.2490 - val_loss: 77.2833\n",
            "Epoch 632/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 78.2032 - val_loss: 76.9466\n",
            "Epoch 633/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 78.1441 - val_loss: 77.3603\n",
            "Epoch 634/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 78.1058 - val_loss: 76.9014\n",
            "Epoch 635/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 78.0470 - val_loss: 77.2882\n",
            "Epoch 636/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 77.9965 - val_loss: 76.6782\n",
            "Epoch 637/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 77.9511 - val_loss: 77.2481\n",
            "Epoch 638/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 77.9095 - val_loss: 76.6230\n",
            "Epoch 639/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 77.8556 - val_loss: 77.0207\n",
            "Epoch 640/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 77.8203 - val_loss: 76.4694\n",
            "Epoch 641/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 77.7734 - val_loss: 76.5575\n",
            "Epoch 642/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 77.7144 - val_loss: 76.5004\n",
            "Epoch 643/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 77.6690 - val_loss: 76.6085\n",
            "Epoch 644/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 77.6129 - val_loss: 76.3029\n",
            "Epoch 645/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 77.5587 - val_loss: 76.4104\n",
            "Epoch 646/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 77.5144 - val_loss: 76.3823\n",
            "Epoch 647/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 77.4822 - val_loss: 76.0528\n",
            "Epoch 648/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 77.4328 - val_loss: 76.1976\n",
            "Epoch 649/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 77.3863 - val_loss: 76.1527\n",
            "Epoch 650/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 77.3353 - val_loss: 76.4115\n",
            "Epoch 651/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 77.2876 - val_loss: 76.2967\n",
            "Epoch 652/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 77.2361 - val_loss: 76.4376\n",
            "Epoch 653/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 77.1875 - val_loss: 75.8472\n",
            "Epoch 654/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 77.1375 - val_loss: 76.2777\n",
            "Epoch 655/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 77.0864 - val_loss: 76.0674\n",
            "Epoch 656/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 77.0426 - val_loss: 75.9307\n",
            "Epoch 657/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 76.9944 - val_loss: 75.7484\n",
            "Epoch 658/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 76.9587 - val_loss: 75.8886\n",
            "Epoch 659/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 76.8979 - val_loss: 75.5608\n",
            "Epoch 660/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 76.8492 - val_loss: 76.0989\n",
            "Epoch 661/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 76.7988 - val_loss: 75.6433\n",
            "Epoch 662/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 76.7632 - val_loss: 75.8155\n",
            "Epoch 663/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 76.7061 - val_loss: 75.7754\n",
            "Epoch 664/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 76.6502 - val_loss: 75.7088\n",
            "Epoch 665/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 76.6139 - val_loss: 75.7725\n",
            "Epoch 666/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 76.5680 - val_loss: 75.4600\n",
            "Epoch 667/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 76.5183 - val_loss: 75.4670\n",
            "Epoch 668/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 76.4833 - val_loss: 75.2338\n",
            "Epoch 669/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 76.4187 - val_loss: 75.4108\n",
            "Epoch 670/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 76.3645 - val_loss: 75.2064\n",
            "Epoch 671/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 76.3222 - val_loss: 75.6112\n",
            "Epoch 672/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 76.2796 - val_loss: 75.1496\n",
            "Epoch 673/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 76.2341 - val_loss: 75.2291\n",
            "Epoch 674/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 76.1839 - val_loss: 75.2209\n",
            "Epoch 675/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 76.1466 - val_loss: 75.6821\n",
            "Epoch 676/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 76.0968 - val_loss: 74.9073\n",
            "Epoch 677/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 76.0482 - val_loss: 75.1227\n",
            "Epoch 678/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 75.9996 - val_loss: 74.8432\n",
            "Epoch 679/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 75.9544 - val_loss: 75.2417\n",
            "Epoch 680/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 75.8978 - val_loss: 74.8855\n",
            "Epoch 681/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 75.8709 - val_loss: 74.8788\n",
            "Epoch 682/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 75.8220 - val_loss: 74.8406\n",
            "Epoch 683/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 75.7710 - val_loss: 74.8657\n",
            "Epoch 684/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 75.7220 - val_loss: 74.7347\n",
            "Epoch 685/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 75.6695 - val_loss: 74.7943\n",
            "Epoch 686/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 75.6272 - val_loss: 74.7189\n",
            "Epoch 687/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 75.5709 - val_loss: 74.8205\n",
            "Epoch 688/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 75.5247 - val_loss: 74.5398\n",
            "Epoch 689/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 75.4818 - val_loss: 74.5054\n",
            "Epoch 690/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 75.4397 - val_loss: 74.3896\n",
            "Epoch 691/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 75.3974 - val_loss: 74.6194\n",
            "Epoch 692/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 75.3313 - val_loss: 74.4731\n",
            "Epoch 693/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 75.2926 - val_loss: 74.4826\n",
            "Epoch 694/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 75.2387 - val_loss: 74.3767\n",
            "Epoch 695/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 75.2044 - val_loss: 74.1737\n",
            "Epoch 696/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 75.1510 - val_loss: 74.1535\n",
            "Epoch 697/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 75.1112 - val_loss: 74.1335\n",
            "Epoch 698/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 75.0641 - val_loss: 74.3825\n",
            "Epoch 699/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 75.0224 - val_loss: 74.0087\n",
            "Epoch 700/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 74.9643 - val_loss: 74.1543\n",
            "Epoch 701/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 74.9139 - val_loss: 74.0533\n",
            "Epoch 702/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 74.8663 - val_loss: 73.9677\n",
            "Epoch 703/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 74.8228 - val_loss: 73.8516\n",
            "Epoch 704/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 74.7850 - val_loss: 73.7249\n",
            "Epoch 705/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 74.7394 - val_loss: 73.9660\n",
            "Epoch 706/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 74.6864 - val_loss: 73.6928\n",
            "Epoch 707/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 74.6352 - val_loss: 73.8793\n",
            "Epoch 708/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 74.5942 - val_loss: 73.6995\n",
            "Epoch 709/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 74.5525 - val_loss: 73.6326\n",
            "Epoch 710/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 74.5181 - val_loss: 73.5472\n",
            "Epoch 711/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 74.4563 - val_loss: 73.5865\n",
            "Epoch 712/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 74.4102 - val_loss: 73.5314\n",
            "Epoch 713/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 74.3612 - val_loss: 73.5224\n",
            "Epoch 714/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 74.3100 - val_loss: 73.6001\n",
            "Epoch 715/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 74.2691 - val_loss: 73.2539\n",
            "Epoch 716/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 74.2237 - val_loss: 73.5130\n",
            "Epoch 717/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 74.1854 - val_loss: 73.2208\n",
            "Epoch 718/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 74.1489 - val_loss: 73.3213\n",
            "Epoch 719/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 74.0967 - val_loss: 73.2276\n",
            "Epoch 720/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 74.0393 - val_loss: 73.2353\n",
            "Epoch 721/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 73.9905 - val_loss: 73.1040\n",
            "Epoch 722/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 73.9444 - val_loss: 73.0949\n",
            "Epoch 723/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 73.9045 - val_loss: 73.0988\n",
            "Epoch 724/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 73.8597 - val_loss: 72.9417\n",
            "Epoch 725/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 73.8087 - val_loss: 73.0026\n",
            "Epoch 726/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 73.7755 - val_loss: 72.8002\n",
            "Epoch 727/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 73.7258 - val_loss: 72.7963\n",
            "Epoch 728/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 73.6888 - val_loss: 72.6740\n",
            "Epoch 729/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 73.6473 - val_loss: 72.8527\n",
            "Epoch 730/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 73.5977 - val_loss: 72.6835\n",
            "Epoch 731/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 73.5317 - val_loss: 72.5565\n",
            "Epoch 732/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 73.4916 - val_loss: 72.6230\n",
            "Epoch 733/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 73.4496 - val_loss: 72.5714\n",
            "Epoch 734/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 73.3939 - val_loss: 72.4303\n",
            "Epoch 735/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 73.3588 - val_loss: 72.3951\n",
            "Epoch 736/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 73.3418 - val_loss: 72.3757\n",
            "Epoch 737/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 73.2840 - val_loss: 72.2853\n",
            "Epoch 738/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 73.2251 - val_loss: 72.2748\n",
            "Epoch 739/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 73.1778 - val_loss: 72.2055\n",
            "Epoch 740/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 73.1363 - val_loss: 72.1955\n",
            "Epoch 741/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 73.0843 - val_loss: 72.1119\n",
            "Epoch 742/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 73.0460 - val_loss: 72.0653\n",
            "Epoch 743/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 72.9968 - val_loss: 71.9087\n",
            "Epoch 744/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 72.9613 - val_loss: 71.9888\n",
            "Epoch 745/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 72.9084 - val_loss: 71.9802\n",
            "Epoch 746/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 72.8695 - val_loss: 71.7926\n",
            "Epoch 747/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 72.8249 - val_loss: 71.8474\n",
            "Epoch 748/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 72.7755 - val_loss: 71.7969\n",
            "Epoch 749/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 72.7400 - val_loss: 71.7204\n",
            "Epoch 750/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 72.6961 - val_loss: 71.8644\n",
            "Epoch 751/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 72.6418 - val_loss: 71.7696\n",
            "Epoch 752/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 72.6042 - val_loss: 71.4855\n",
            "Epoch 753/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 72.5776 - val_loss: 71.7762\n",
            "Epoch 754/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 72.5427 - val_loss: 71.4818\n",
            "Epoch 755/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 72.4914 - val_loss: 71.4274\n",
            "Epoch 756/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 72.4314 - val_loss: 71.4909\n",
            "Epoch 757/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 72.4020 - val_loss: 71.4656\n",
            "Epoch 758/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 72.3589 - val_loss: 71.2547\n",
            "Epoch 759/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 72.3008 - val_loss: 71.4053\n",
            "Epoch 760/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 72.2536 - val_loss: 71.4034\n",
            "Epoch 761/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 72.1955 - val_loss: 71.4082\n",
            "Epoch 762/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 72.1658 - val_loss: 71.3325\n",
            "Epoch 763/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 72.1235 - val_loss: 71.2134\n",
            "Epoch 764/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 72.0725 - val_loss: 71.2326\n",
            "Epoch 765/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 72.0390 - val_loss: 71.0817\n",
            "Epoch 766/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 72.0232 - val_loss: 71.0653\n",
            "Epoch 767/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 71.9566 - val_loss: 71.1593\n",
            "Epoch 768/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 71.9010 - val_loss: 71.1300\n",
            "Epoch 769/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 71.8380 - val_loss: 71.0291\n",
            "Epoch 770/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 71.8008 - val_loss: 71.0814\n",
            "Epoch 771/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 71.7473 - val_loss: 70.8982\n",
            "Epoch 772/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 71.7148 - val_loss: 70.8908\n",
            "Epoch 773/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 71.6792 - val_loss: 70.8489\n",
            "Epoch 774/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 71.6450 - val_loss: 70.8540\n",
            "Epoch 775/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 71.5683 - val_loss: 70.6562\n",
            "Epoch 776/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 71.5392 - val_loss: 70.6227\n",
            "Epoch 777/6000\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 71.4858 - val_loss: 70.5577\n",
            "Epoch 778/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 71.4485 - val_loss: 70.6290\n",
            "Epoch 779/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 71.4095 - val_loss: 70.3964\n",
            "Epoch 780/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 71.3860 - val_loss: 70.4730\n",
            "Epoch 781/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 71.3249 - val_loss: 70.4762\n",
            "Epoch 782/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 71.2909 - val_loss: 70.3492\n",
            "Epoch 783/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 71.2489 - val_loss: 70.2935\n",
            "Epoch 784/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 71.2129 - val_loss: 70.1791\n",
            "Epoch 785/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 71.1649 - val_loss: 70.1580\n",
            "Epoch 786/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 71.1048 - val_loss: 70.3029\n",
            "Epoch 787/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 71.0706 - val_loss: 70.2115\n",
            "Epoch 788/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 71.0253 - val_loss: 70.1624\n",
            "Epoch 789/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 70.9902 - val_loss: 70.0284\n",
            "Epoch 790/6000\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 70.9630 - val_loss: 70.0999\n",
            "Epoch 791/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 70.9052 - val_loss: 70.0140\n",
            "Epoch 792/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 70.8519 - val_loss: 69.8071\n",
            "Epoch 793/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 70.8059 - val_loss: 69.8208\n",
            "Epoch 794/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 70.7594 - val_loss: 69.9030\n",
            "Epoch 795/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 70.7211 - val_loss: 69.8590\n",
            "Epoch 796/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 70.6960 - val_loss: 69.7131\n",
            "Epoch 797/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 70.6446 - val_loss: 69.7057\n",
            "Epoch 798/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 70.5972 - val_loss: 69.8699\n",
            "Epoch 799/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 70.5765 - val_loss: 69.5544\n",
            "Epoch 800/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 70.5319 - val_loss: 69.6188\n",
            "Epoch 801/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 70.4815 - val_loss: 69.6329\n",
            "Epoch 802/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 70.4563 - val_loss: 69.5511\n",
            "Epoch 803/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 70.4068 - val_loss: 69.4694\n",
            "Epoch 804/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 70.3583 - val_loss: 69.5581\n",
            "Epoch 805/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 70.3051 - val_loss: 69.4317\n",
            "Epoch 806/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 70.2654 - val_loss: 69.3550\n",
            "Epoch 807/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 70.2254 - val_loss: 69.1913\n",
            "Epoch 808/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 70.1878 - val_loss: 69.3934\n",
            "Epoch 809/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 70.1310 - val_loss: 69.1885\n",
            "Epoch 810/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 70.0827 - val_loss: 69.4021\n",
            "Epoch 811/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 70.0526 - val_loss: 68.9940\n",
            "Epoch 812/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 69.9972 - val_loss: 69.2375\n",
            "Epoch 813/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 69.9619 - val_loss: 69.0398\n",
            "Epoch 814/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 69.9284 - val_loss: 69.1466\n",
            "Epoch 815/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 69.8818 - val_loss: 69.1145\n",
            "Epoch 816/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 69.8524 - val_loss: 68.8875\n",
            "Epoch 817/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 69.8082 - val_loss: 69.0808\n",
            "Epoch 818/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 69.7649 - val_loss: 68.7596\n",
            "Epoch 819/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 69.7429 - val_loss: 68.9014\n",
            "Epoch 820/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 69.6780 - val_loss: 68.6986\n",
            "Epoch 821/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 69.6508 - val_loss: 68.8830\n",
            "Epoch 822/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 69.6077 - val_loss: 68.7533\n",
            "Epoch 823/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 69.5599 - val_loss: 68.7566\n",
            "Epoch 824/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 69.5185 - val_loss: 68.6794\n",
            "Epoch 825/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 69.4834 - val_loss: 68.6558\n",
            "Epoch 826/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 69.4325 - val_loss: 68.7397\n",
            "Epoch 827/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 69.3881 - val_loss: 68.6641\n",
            "Epoch 828/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 69.3581 - val_loss: 68.6114\n",
            "Epoch 829/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 69.3420 - val_loss: 68.4455\n",
            "Epoch 830/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 69.2862 - val_loss: 68.5311\n",
            "Epoch 831/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 69.2589 - val_loss: 68.3101\n",
            "Epoch 832/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 69.1951 - val_loss: 68.3140\n",
            "Epoch 833/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 69.1694 - val_loss: 68.2895\n",
            "Epoch 834/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 69.1105 - val_loss: 68.4065\n",
            "Epoch 835/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 69.0909 - val_loss: 68.1468\n",
            "Epoch 836/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 69.0600 - val_loss: 68.3430\n",
            "Epoch 837/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 69.0044 - val_loss: 68.2256\n",
            "Epoch 838/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 68.9750 - val_loss: 68.2272\n",
            "Epoch 839/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 68.9176 - val_loss: 68.0356\n",
            "Epoch 840/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 68.8947 - val_loss: 68.1178\n",
            "Epoch 841/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 68.8480 - val_loss: 67.8132\n",
            "Epoch 842/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 68.7963 - val_loss: 68.0087\n",
            "Epoch 843/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 68.7629 - val_loss: 67.6901\n",
            "Epoch 844/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 68.7155 - val_loss: 68.0725\n",
            "Epoch 845/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 68.6826 - val_loss: 67.8526\n",
            "Epoch 846/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 68.6636 - val_loss: 67.9937\n",
            "Epoch 847/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 68.6194 - val_loss: 67.7762\n",
            "Epoch 848/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 68.5795 - val_loss: 68.0164\n",
            "Epoch 849/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 68.5442 - val_loss: 67.8344\n",
            "Epoch 850/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 68.4926 - val_loss: 67.7061\n",
            "Epoch 851/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 68.4399 - val_loss: 67.7133\n",
            "Epoch 852/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 68.4047 - val_loss: 67.5427\n",
            "Epoch 853/6000\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 68.3564 - val_loss: 67.6912\n",
            "Epoch 854/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 68.3351 - val_loss: 67.5641\n",
            "Epoch 855/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 68.2812 - val_loss: 67.5226\n",
            "Epoch 856/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 68.2361 - val_loss: 67.4608\n",
            "Epoch 857/6000\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 68.1886 - val_loss: 67.3470\n",
            "Epoch 858/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 68.1577 - val_loss: 67.3045\n",
            "Epoch 859/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 68.1157 - val_loss: 67.5789\n",
            "Epoch 860/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 68.0848 - val_loss: 67.2461\n",
            "Epoch 861/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 68.0395 - val_loss: 67.3492\n",
            "Epoch 862/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 68.0317 - val_loss: 67.2984\n",
            "Epoch 863/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 67.9815 - val_loss: 67.1321\n",
            "Epoch 864/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 67.9368 - val_loss: 67.2214\n",
            "Epoch 865/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 67.9154 - val_loss: 67.1274\n",
            "Epoch 866/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 67.8434 - val_loss: 67.2400\n",
            "Epoch 867/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 67.8039 - val_loss: 66.9771\n",
            "Epoch 868/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 67.7630 - val_loss: 67.0633\n",
            "Epoch 869/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 67.7248 - val_loss: 66.9658\n",
            "Epoch 870/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 67.6933 - val_loss: 66.8652\n",
            "Epoch 871/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 67.6668 - val_loss: 66.8736\n",
            "Epoch 872/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 67.6311 - val_loss: 66.9355\n",
            "Epoch 873/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 67.5834 - val_loss: 66.9590\n",
            "Epoch 874/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 67.5772 - val_loss: 66.7164\n",
            "Epoch 875/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 67.5424 - val_loss: 66.7822\n",
            "Epoch 876/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 67.4681 - val_loss: 66.7070\n",
            "Epoch 877/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 67.4167 - val_loss: 66.6848\n",
            "Epoch 878/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 67.3928 - val_loss: 66.7099\n",
            "Epoch 879/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 67.3460 - val_loss: 66.5963\n",
            "Epoch 880/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 67.3147 - val_loss: 66.7421\n",
            "Epoch 881/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 67.2901 - val_loss: 66.5687\n",
            "Epoch 882/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 67.2384 - val_loss: 66.5054\n",
            "Epoch 883/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 67.1912 - val_loss: 66.4760\n",
            "Epoch 884/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 67.1657 - val_loss: 66.6401\n",
            "Epoch 885/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 67.1376 - val_loss: 66.3274\n",
            "Epoch 886/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 67.0778 - val_loss: 66.3696\n",
            "Epoch 887/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 67.0641 - val_loss: 66.7325\n",
            "Epoch 888/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 67.0203 - val_loss: 66.4436\n",
            "Epoch 889/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 67.0071 - val_loss: 66.5888\n",
            "Epoch 890/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 66.9597 - val_loss: 66.4449\n",
            "Epoch 891/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 66.9168 - val_loss: 66.3066\n",
            "Epoch 892/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 66.8698 - val_loss: 66.0823\n",
            "Epoch 893/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 66.8261 - val_loss: 66.2755\n",
            "Epoch 894/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 66.7899 - val_loss: 66.1258\n",
            "Epoch 895/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 66.7541 - val_loss: 66.2077\n",
            "Epoch 896/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 66.7468 - val_loss: 65.9515\n",
            "Epoch 897/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 66.6868 - val_loss: 66.1434\n",
            "Epoch 898/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 66.6438 - val_loss: 66.0065\n",
            "Epoch 899/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 66.5962 - val_loss: 65.7603\n",
            "Epoch 900/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 66.5589 - val_loss: 66.1298\n",
            "Epoch 901/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 66.5217 - val_loss: 65.9147\n",
            "Epoch 902/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 66.4857 - val_loss: 66.0501\n",
            "Epoch 903/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 66.4370 - val_loss: 65.7898\n",
            "Epoch 904/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 66.3951 - val_loss: 65.7665\n",
            "Epoch 905/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 66.3617 - val_loss: 65.8152\n",
            "Epoch 906/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 66.3348 - val_loss: 65.7911\n",
            "Epoch 907/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 66.3086 - val_loss: 65.6583\n",
            "Epoch 908/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 66.2778 - val_loss: 65.5854\n",
            "Epoch 909/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 66.2259 - val_loss: 65.7245\n",
            "Epoch 910/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 66.2148 - val_loss: 65.4959\n",
            "Epoch 911/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 66.1685 - val_loss: 65.7908\n",
            "Epoch 912/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 66.1485 - val_loss: 65.5830\n",
            "Epoch 913/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 66.0781 - val_loss: 65.5823\n",
            "Epoch 914/6000\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 66.0354 - val_loss: 65.4349\n",
            "Epoch 915/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 66.0323 - val_loss: 65.3497\n",
            "Epoch 916/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 65.9885 - val_loss: 65.4637\n",
            "Epoch 917/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 65.9409 - val_loss: 65.3649\n",
            "Epoch 918/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 65.9004 - val_loss: 65.1657\n",
            "Epoch 919/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 65.8807 - val_loss: 65.4864\n",
            "Epoch 920/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 65.8330 - val_loss: 65.3309\n",
            "Epoch 921/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 65.8068 - val_loss: 65.4060\n",
            "Epoch 922/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 65.8000 - val_loss: 65.2544\n",
            "Epoch 923/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 65.7377 - val_loss: 65.1588\n",
            "Epoch 924/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 65.6906 - val_loss: 65.0922\n",
            "Epoch 925/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 65.6549 - val_loss: 65.1180\n",
            "Epoch 926/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 65.6908 - val_loss: 65.3829\n",
            "Epoch 927/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 65.6401 - val_loss: 65.1826\n",
            "Epoch 928/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 65.5917 - val_loss: 65.2835\n",
            "Epoch 929/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 65.5568 - val_loss: 64.9846\n",
            "Epoch 930/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 65.4949 - val_loss: 65.0976\n",
            "Epoch 931/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 65.4673 - val_loss: 65.1012\n",
            "Epoch 932/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 65.4309 - val_loss: 64.9818\n",
            "Epoch 933/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 65.4082 - val_loss: 64.7867\n",
            "Epoch 934/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 65.3373 - val_loss: 64.7924\n",
            "Epoch 935/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 65.2952 - val_loss: 64.7828\n",
            "Epoch 936/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 65.2449 - val_loss: 64.7887\n",
            "Epoch 937/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 65.2293 - val_loss: 64.8441\n",
            "Epoch 938/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 65.2207 - val_loss: 64.9603\n",
            "Epoch 939/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 65.1936 - val_loss: 64.9645\n",
            "Epoch 940/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 65.1366 - val_loss: 64.7965\n",
            "Epoch 941/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 65.0868 - val_loss: 64.5936\n",
            "Epoch 942/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 65.0438 - val_loss: 64.6755\n",
            "Epoch 943/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 65.0357 - val_loss: 64.5880\n",
            "Epoch 944/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 64.9995 - val_loss: 64.4743\n",
            "Epoch 945/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 64.9571 - val_loss: 64.4525\n",
            "Epoch 946/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 64.9323 - val_loss: 64.3661\n",
            "Epoch 947/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 64.8945 - val_loss: 64.3140\n",
            "Epoch 948/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 64.8647 - val_loss: 64.2450\n",
            "Epoch 949/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 64.8076 - val_loss: 64.2909\n",
            "Epoch 950/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 64.7770 - val_loss: 64.0843\n",
            "Epoch 951/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 64.7443 - val_loss: 64.2295\n",
            "Epoch 952/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 64.7221 - val_loss: 64.3044\n",
            "Epoch 953/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 64.7001 - val_loss: 64.0636\n",
            "Epoch 954/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 64.6540 - val_loss: 63.9735\n",
            "Epoch 955/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 64.6011 - val_loss: 64.0686\n",
            "Epoch 956/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 64.5804 - val_loss: 64.0712\n",
            "Epoch 957/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 64.5365 - val_loss: 63.9633\n",
            "Epoch 958/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 64.4951 - val_loss: 64.1505\n",
            "Epoch 959/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 64.4696 - val_loss: 63.9466\n",
            "Epoch 960/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 64.4573 - val_loss: 64.0431\n",
            "Epoch 961/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 64.3805 - val_loss: 63.6498\n",
            "Epoch 962/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 64.4107 - val_loss: 63.6923\n",
            "Epoch 963/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 64.3276 - val_loss: 63.7589\n",
            "Epoch 964/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 64.3074 - val_loss: 63.4564\n",
            "Epoch 965/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 64.2684 - val_loss: 63.6615\n",
            "Epoch 966/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 64.2096 - val_loss: 63.4973\n",
            "Epoch 967/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 64.1876 - val_loss: 63.6387\n",
            "Epoch 968/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 64.1402 - val_loss: 63.4689\n",
            "Epoch 969/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 64.1531 - val_loss: 63.9720\n",
            "Epoch 970/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 64.1248 - val_loss: 63.4684\n",
            "Epoch 971/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 64.1101 - val_loss: 63.9037\n",
            "Epoch 972/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 64.1128 - val_loss: 63.4526\n",
            "Epoch 973/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 64.0775 - val_loss: 63.8073\n",
            "Epoch 974/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 64.0083 - val_loss: 63.3814\n",
            "Epoch 975/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 63.9969 - val_loss: 63.6622\n",
            "Epoch 976/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 63.9403 - val_loss: 63.5505\n",
            "Epoch 977/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 63.8945 - val_loss: 63.4837\n",
            "Epoch 978/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 63.8293 - val_loss: 63.5136\n",
            "Epoch 979/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 63.8074 - val_loss: 63.2066\n",
            "Epoch 980/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 63.8014 - val_loss: 63.4734\n",
            "Epoch 981/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 63.7276 - val_loss: 63.3061\n",
            "Epoch 982/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 63.7106 - val_loss: 63.2281\n",
            "Epoch 983/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 63.6691 - val_loss: 63.3210\n",
            "Epoch 984/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 63.6396 - val_loss: 63.1098\n",
            "Epoch 985/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 63.6043 - val_loss: 63.0275\n",
            "Epoch 986/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 63.5689 - val_loss: 63.2390\n",
            "Epoch 987/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 63.5493 - val_loss: 62.9885\n",
            "Epoch 988/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 63.5236 - val_loss: 63.2532\n",
            "Epoch 989/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 63.4772 - val_loss: 63.1550\n",
            "Epoch 990/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 63.4483 - val_loss: 63.0403\n",
            "Epoch 991/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 63.3975 - val_loss: 63.0377\n",
            "Epoch 992/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 63.4084 - val_loss: 63.1748\n",
            "Epoch 993/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 63.3379 - val_loss: 62.9477\n",
            "Epoch 994/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 63.3031 - val_loss: 63.0461\n",
            "Epoch 995/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 63.2670 - val_loss: 62.9738\n",
            "Epoch 996/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 63.2273 - val_loss: 63.0625\n",
            "Epoch 997/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 63.1982 - val_loss: 62.7886\n",
            "Epoch 998/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 63.1762 - val_loss: 62.9487\n",
            "Epoch 999/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 63.1596 - val_loss: 62.5784\n",
            "Epoch 1000/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 63.1257 - val_loss: 63.0669\n",
            "Epoch 1001/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 63.1231 - val_loss: 62.4595\n",
            "Epoch 1002/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 63.0422 - val_loss: 62.7558\n",
            "Epoch 1003/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 62.9991 - val_loss: 62.4702\n",
            "Epoch 1004/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 63.0090 - val_loss: 62.6512\n",
            "Epoch 1005/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 62.9383 - val_loss: 62.6050\n",
            "Epoch 1006/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 62.9217 - val_loss: 62.5070\n",
            "Epoch 1007/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 62.8727 - val_loss: 62.6220\n",
            "Epoch 1008/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 62.8324 - val_loss: 62.5592\n",
            "Epoch 1009/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 62.8164 - val_loss: 62.5183\n",
            "Epoch 1010/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 62.7711 - val_loss: 62.3230\n",
            "Epoch 1011/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 62.7464 - val_loss: 62.8138\n",
            "Epoch 1012/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 62.7311 - val_loss: 62.2519\n",
            "Epoch 1013/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 62.6992 - val_loss: 62.3842\n",
            "Epoch 1014/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 62.6424 - val_loss: 62.1785\n",
            "Epoch 1015/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 62.6297 - val_loss: 62.4251\n",
            "Epoch 1016/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 62.6166 - val_loss: 62.1289\n",
            "Epoch 1017/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 62.5997 - val_loss: 62.5655\n",
            "Epoch 1018/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 62.5392 - val_loss: 62.0595\n",
            "Epoch 1019/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 62.4977 - val_loss: 62.2751\n",
            "Epoch 1020/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 62.4748 - val_loss: 62.0193\n",
            "Epoch 1021/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 62.4304 - val_loss: 62.2460\n",
            "Epoch 1022/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 62.4081 - val_loss: 61.7803\n",
            "Epoch 1023/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 62.3635 - val_loss: 62.1271\n",
            "Epoch 1024/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 62.3362 - val_loss: 61.9649\n",
            "Epoch 1025/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 62.2913 - val_loss: 61.8388\n",
            "Epoch 1026/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 62.2394 - val_loss: 61.9751\n",
            "Epoch 1027/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 62.2188 - val_loss: 61.7217\n",
            "Epoch 1028/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 62.1795 - val_loss: 62.0346\n",
            "Epoch 1029/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 62.1490 - val_loss: 61.7041\n",
            "Epoch 1030/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 62.1077 - val_loss: 61.7725\n",
            "Epoch 1031/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 62.1270 - val_loss: 61.8716\n",
            "Epoch 1032/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 62.0662 - val_loss: 61.8218\n",
            "Epoch 1033/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 62.0244 - val_loss: 61.8635\n",
            "Epoch 1034/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 62.1033 - val_loss: 61.7825\n",
            "Epoch 1035/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 62.0272 - val_loss: 61.6526\n",
            "Epoch 1036/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 61.9985 - val_loss: 61.9852\n",
            "Epoch 1037/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 61.9674 - val_loss: 61.4066\n",
            "Epoch 1038/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 61.9296 - val_loss: 61.7567\n",
            "Epoch 1039/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 61.8693 - val_loss: 61.5816\n",
            "Epoch 1040/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 61.8510 - val_loss: 61.4937\n",
            "Epoch 1041/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 61.8032 - val_loss: 61.4687\n",
            "Epoch 1042/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 61.7725 - val_loss: 61.8977\n",
            "Epoch 1043/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 61.7431 - val_loss: 61.3391\n",
            "Epoch 1044/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 61.6984 - val_loss: 61.5358\n",
            "Epoch 1045/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 61.6463 - val_loss: 61.3801\n",
            "Epoch 1046/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 61.6267 - val_loss: 61.1388\n",
            "Epoch 1047/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 61.6100 - val_loss: 61.5757\n",
            "Epoch 1048/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 61.5853 - val_loss: 61.0680\n",
            "Epoch 1049/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 61.5649 - val_loss: 61.2981\n",
            "Epoch 1050/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 61.5071 - val_loss: 61.1159\n",
            "Epoch 1051/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 61.4763 - val_loss: 61.1491\n",
            "Epoch 1052/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 61.4376 - val_loss: 61.0884\n",
            "Epoch 1053/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 61.4021 - val_loss: 61.0427\n",
            "Epoch 1054/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 61.3678 - val_loss: 61.0302\n",
            "Epoch 1055/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 61.3260 - val_loss: 60.9994\n",
            "Epoch 1056/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 61.3231 - val_loss: 61.0135\n",
            "Epoch 1057/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 61.2864 - val_loss: 60.9200\n",
            "Epoch 1058/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 61.2286 - val_loss: 60.7309\n",
            "Epoch 1059/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 61.2390 - val_loss: 61.0119\n",
            "Epoch 1060/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 61.2101 - val_loss: 60.9130\n",
            "Epoch 1061/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 61.1716 - val_loss: 60.6477\n",
            "Epoch 1062/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 61.1759 - val_loss: 60.9442\n",
            "Epoch 1063/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 61.1603 - val_loss: 60.5415\n",
            "Epoch 1064/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 61.1598 - val_loss: 61.0345\n",
            "Epoch 1065/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 61.1324 - val_loss: 60.7372\n",
            "Epoch 1066/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 61.0701 - val_loss: 60.9787\n",
            "Epoch 1067/6000\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 61.0277 - val_loss: 60.7199\n",
            "Epoch 1068/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 60.9640 - val_loss: 60.8247\n",
            "Epoch 1069/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 60.9338 - val_loss: 60.7197\n",
            "Epoch 1070/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 60.9076 - val_loss: 60.6224\n",
            "Epoch 1071/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 60.8840 - val_loss: 60.6583\n",
            "Epoch 1072/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 60.8561 - val_loss: 60.4720\n",
            "Epoch 1073/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 60.8368 - val_loss: 60.5312\n",
            "Epoch 1074/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 60.7920 - val_loss: 60.5204\n",
            "Epoch 1075/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 60.7924 - val_loss: 60.5880\n",
            "Epoch 1076/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 60.7384 - val_loss: 60.3136\n",
            "Epoch 1077/6000\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 60.7115 - val_loss: 60.6471\n",
            "Epoch 1078/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 60.7072 - val_loss: 60.2756\n",
            "Epoch 1079/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 60.6577 - val_loss: 60.5593\n",
            "Epoch 1080/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 60.6264 - val_loss: 60.1818\n",
            "Epoch 1081/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 60.6180 - val_loss: 60.6256\n",
            "Epoch 1082/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 60.6497 - val_loss: 60.1738\n",
            "Epoch 1083/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 60.5719 - val_loss: 60.4819\n",
            "Epoch 1084/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 60.5369 - val_loss: 60.0910\n",
            "Epoch 1085/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 60.4841 - val_loss: 60.4327\n",
            "Epoch 1086/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 60.4781 - val_loss: 59.9350\n",
            "Epoch 1087/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 60.4238 - val_loss: 60.0854\n",
            "Epoch 1088/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 60.3596 - val_loss: 59.8181\n",
            "Epoch 1089/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 60.3241 - val_loss: 60.1658\n",
            "Epoch 1090/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 60.3422 - val_loss: 59.8072\n",
            "Epoch 1091/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 60.2948 - val_loss: 59.9115\n",
            "Epoch 1092/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 60.2396 - val_loss: 59.7606\n",
            "Epoch 1093/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 60.1933 - val_loss: 60.0412\n",
            "Epoch 1094/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 60.1935 - val_loss: 59.7292\n",
            "Epoch 1095/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 60.1637 - val_loss: 59.8761\n",
            "Epoch 1096/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 60.1628 - val_loss: 59.7033\n",
            "Epoch 1097/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 60.1299 - val_loss: 59.8886\n",
            "Epoch 1098/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 60.0679 - val_loss: 59.8929\n",
            "Epoch 1099/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 60.0351 - val_loss: 59.7112\n",
            "Epoch 1100/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 60.0099 - val_loss: 59.7164\n",
            "Epoch 1101/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 60.0151 - val_loss: 59.6052\n",
            "Epoch 1102/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 60.0045 - val_loss: 59.4855\n",
            "Epoch 1103/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 59.9506 - val_loss: 59.7705\n",
            "Epoch 1104/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 59.8951 - val_loss: 59.4157\n",
            "Epoch 1105/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 59.8828 - val_loss: 59.4926\n",
            "Epoch 1106/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 59.8545 - val_loss: 59.3336\n",
            "Epoch 1107/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 59.8049 - val_loss: 59.4979\n",
            "Epoch 1108/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 59.8167 - val_loss: 59.3017\n",
            "Epoch 1109/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 59.7507 - val_loss: 59.4018\n",
            "Epoch 1110/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 59.7256 - val_loss: 59.1138\n",
            "Epoch 1111/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 59.7652 - val_loss: 59.4267\n",
            "Epoch 1112/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 59.6682 - val_loss: 59.2059\n",
            "Epoch 1113/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 59.6406 - val_loss: 59.3288\n",
            "Epoch 1114/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 59.6416 - val_loss: 59.2960\n",
            "Epoch 1115/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 59.6424 - val_loss: 59.2372\n",
            "Epoch 1116/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 59.5632 - val_loss: 59.0387\n",
            "Epoch 1117/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 59.5298 - val_loss: 59.3451\n",
            "Epoch 1118/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 59.5155 - val_loss: 59.0581\n",
            "Epoch 1119/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 59.4526 - val_loss: 59.2593\n",
            "Epoch 1120/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 59.4840 - val_loss: 58.6703\n",
            "Epoch 1121/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 59.4514 - val_loss: 59.1329\n",
            "Epoch 1122/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 59.4289 - val_loss: 58.9022\n",
            "Epoch 1123/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 59.3975 - val_loss: 58.8148\n",
            "Epoch 1124/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 59.3316 - val_loss: 58.9160\n",
            "Epoch 1125/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 59.3218 - val_loss: 58.7977\n",
            "Epoch 1126/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 59.2893 - val_loss: 58.9377\n",
            "Epoch 1127/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 59.2669 - val_loss: 58.7506\n",
            "Epoch 1128/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 59.2652 - val_loss: 58.8585\n",
            "Epoch 1129/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 59.2355 - val_loss: 58.8427\n",
            "Epoch 1130/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 59.2152 - val_loss: 58.4965\n",
            "Epoch 1131/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 59.2365 - val_loss: 58.8692\n",
            "Epoch 1132/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 59.1747 - val_loss: 58.6746\n",
            "Epoch 1133/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 59.1586 - val_loss: 58.8913\n",
            "Epoch 1134/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 59.0968 - val_loss: 58.7107\n",
            "Epoch 1135/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 59.0533 - val_loss: 58.6671\n",
            "Epoch 1136/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 59.0618 - val_loss: 58.9097\n",
            "Epoch 1137/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 59.0127 - val_loss: 58.6528\n",
            "Epoch 1138/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 58.9805 - val_loss: 58.6800\n",
            "Epoch 1139/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 58.9491 - val_loss: 58.5025\n",
            "Epoch 1140/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 58.9257 - val_loss: 58.5691\n",
            "Epoch 1141/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 58.8941 - val_loss: 58.4686\n",
            "Epoch 1142/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 58.8262 - val_loss: 58.6660\n",
            "Epoch 1143/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 58.7740 - val_loss: 58.3313\n",
            "Epoch 1144/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 58.7565 - val_loss: 58.3919\n",
            "Epoch 1145/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 58.7741 - val_loss: 58.1906\n",
            "Epoch 1146/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 58.7425 - val_loss: 58.5718\n",
            "Epoch 1147/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 58.6933 - val_loss: 58.3856\n",
            "Epoch 1148/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 58.6547 - val_loss: 58.4687\n",
            "Epoch 1149/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 58.6639 - val_loss: 58.1024\n",
            "Epoch 1150/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 58.6658 - val_loss: 58.2597\n",
            "Epoch 1151/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 58.6851 - val_loss: 58.4204\n",
            "Epoch 1152/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 58.6455 - val_loss: 58.2413\n",
            "Epoch 1153/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 58.5822 - val_loss: 58.4076\n",
            "Epoch 1154/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 58.5549 - val_loss: 58.1874\n",
            "Epoch 1155/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 58.5201 - val_loss: 58.2859\n",
            "Epoch 1156/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 58.4868 - val_loss: 58.2695\n",
            "Epoch 1157/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 58.4170 - val_loss: 58.0619\n",
            "Epoch 1158/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 58.4182 - val_loss: 58.0842\n",
            "Epoch 1159/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 58.3739 - val_loss: 58.0272\n",
            "Epoch 1160/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 58.3594 - val_loss: 58.0340\n",
            "Epoch 1161/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 58.3195 - val_loss: 57.9333\n",
            "Epoch 1162/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 58.2990 - val_loss: 57.8766\n",
            "Epoch 1163/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 58.2760 - val_loss: 58.1016\n",
            "Epoch 1164/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 58.2583 - val_loss: 57.8672\n",
            "Epoch 1165/6000\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 58.2122 - val_loss: 57.7389\n",
            "Epoch 1166/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 58.2146 - val_loss: 58.0002\n",
            "Epoch 1167/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 58.2487 - val_loss: 57.5474\n",
            "Epoch 1168/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 58.1825 - val_loss: 58.0007\n",
            "Epoch 1169/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 58.1510 - val_loss: 57.5651\n",
            "Epoch 1170/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 58.1202 - val_loss: 57.7675\n",
            "Epoch 1171/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 58.0916 - val_loss: 57.6934\n",
            "Epoch 1172/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 58.0497 - val_loss: 57.5129\n",
            "Epoch 1173/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 58.0360 - val_loss: 57.6089\n",
            "Epoch 1174/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 57.9752 - val_loss: 57.6252\n",
            "Epoch 1175/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 57.9459 - val_loss: 57.5359\n",
            "Epoch 1176/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 57.9224 - val_loss: 57.4797\n",
            "Epoch 1177/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 57.8965 - val_loss: 57.5743\n",
            "Epoch 1178/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 57.8984 - val_loss: 57.5898\n",
            "Epoch 1179/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 57.8689 - val_loss: 57.5186\n",
            "Epoch 1180/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 57.8640 - val_loss: 57.5718\n",
            "Epoch 1181/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 57.8262 - val_loss: 57.5069\n",
            "Epoch 1182/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 57.7938 - val_loss: 57.2446\n",
            "Epoch 1183/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 57.8225 - val_loss: 57.7002\n",
            "Epoch 1184/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 57.7899 - val_loss: 57.5158\n",
            "Epoch 1185/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 57.7292 - val_loss: 57.4744\n",
            "Epoch 1186/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 57.7490 - val_loss: 57.3177\n",
            "Epoch 1187/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 57.7034 - val_loss: 57.4758\n",
            "Epoch 1188/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 57.6455 - val_loss: 57.4652\n",
            "Epoch 1189/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 57.6119 - val_loss: 57.2358\n",
            "Epoch 1190/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 57.5727 - val_loss: 57.3947\n",
            "Epoch 1191/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 57.5391 - val_loss: 57.1999\n",
            "Epoch 1192/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 57.5100 - val_loss: 57.2880\n",
            "Epoch 1193/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 57.4839 - val_loss: 57.1276\n",
            "Epoch 1194/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 57.4946 - val_loss: 57.3343\n",
            "Epoch 1195/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 57.4439 - val_loss: 57.1599\n",
            "Epoch 1196/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 57.4332 - val_loss: 57.1522\n",
            "Epoch 1197/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 57.4087 - val_loss: 57.0679\n",
            "Epoch 1198/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 57.3541 - val_loss: 56.9525\n",
            "Epoch 1199/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 57.3085 - val_loss: 57.0806\n",
            "Epoch 1200/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 57.3357 - val_loss: 56.7812\n",
            "Epoch 1201/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 57.2720 - val_loss: 57.1054\n",
            "Epoch 1202/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 57.2389 - val_loss: 56.8354\n",
            "Epoch 1203/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 57.2219 - val_loss: 56.8818\n",
            "Epoch 1204/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 57.1928 - val_loss: 56.7567\n",
            "Epoch 1205/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 57.1658 - val_loss: 56.8153\n",
            "Epoch 1206/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 57.1741 - val_loss: 56.6903\n",
            "Epoch 1207/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 57.1599 - val_loss: 56.9223\n",
            "Epoch 1208/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 57.0644 - val_loss: 56.8775\n",
            "Epoch 1209/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 57.1269 - val_loss: 56.5694\n",
            "Epoch 1210/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 57.0564 - val_loss: 56.8039\n",
            "Epoch 1211/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 57.0047 - val_loss: 56.5932\n",
            "Epoch 1212/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 57.0779 - val_loss: 56.7433\n",
            "Epoch 1213/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 57.0424 - val_loss: 56.8229\n",
            "Epoch 1214/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 57.0341 - val_loss: 56.6068\n",
            "Epoch 1215/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 56.9563 - val_loss: 56.5230\n",
            "Epoch 1216/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 56.9078 - val_loss: 56.5830\n",
            "Epoch 1217/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 56.8640 - val_loss: 56.4531\n",
            "Epoch 1218/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 56.8704 - val_loss: 56.6112\n",
            "Epoch 1219/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 56.8394 - val_loss: 56.4116\n",
            "Epoch 1220/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 56.7953 - val_loss: 56.5923\n",
            "Epoch 1221/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 56.7812 - val_loss: 56.5146\n",
            "Epoch 1222/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 56.7341 - val_loss: 56.5820\n",
            "Epoch 1223/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 56.7117 - val_loss: 56.4339\n",
            "Epoch 1224/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 56.6803 - val_loss: 56.4100\n",
            "Epoch 1225/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 56.6861 - val_loss: 56.4224\n",
            "Epoch 1226/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 56.6269 - val_loss: 56.4795\n",
            "Epoch 1227/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 56.5945 - val_loss: 56.2709\n",
            "Epoch 1228/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 56.6229 - val_loss: 56.5394\n",
            "Epoch 1229/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 56.6059 - val_loss: 56.2378\n",
            "Epoch 1230/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 56.5805 - val_loss: 56.4951\n",
            "Epoch 1231/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 56.5491 - val_loss: 56.2165\n",
            "Epoch 1232/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 56.5290 - val_loss: 56.3111\n",
            "Epoch 1233/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 56.4795 - val_loss: 56.0248\n",
            "Epoch 1234/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 56.4416 - val_loss: 56.3422\n",
            "Epoch 1235/6000\n",
            "6/6 [==============================] - 0s 40ms/step - loss: 56.4266 - val_loss: 56.0849\n",
            "Epoch 1236/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 56.3635 - val_loss: 55.9954\n",
            "Epoch 1237/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 56.3575 - val_loss: 56.1029\n",
            "Epoch 1238/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 56.3828 - val_loss: 56.3910\n",
            "Epoch 1239/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 56.3053 - val_loss: 55.9790\n",
            "Epoch 1240/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 56.3402 - val_loss: 56.3771\n",
            "Epoch 1241/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 56.2893 - val_loss: 56.1456\n",
            "Epoch 1242/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 56.2306 - val_loss: 56.1122\n",
            "Epoch 1243/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 56.2084 - val_loss: 55.9198\n",
            "Epoch 1244/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 56.1984 - val_loss: 55.9022\n",
            "Epoch 1245/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 56.2352 - val_loss: 55.9944\n",
            "Epoch 1246/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 56.1732 - val_loss: 56.1329\n",
            "Epoch 1247/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 56.1141 - val_loss: 55.9930\n",
            "Epoch 1248/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 56.0756 - val_loss: 55.7403\n",
            "Epoch 1249/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 56.0795 - val_loss: 56.0570\n",
            "Epoch 1250/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 56.0639 - val_loss: 55.7868\n",
            "Epoch 1251/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 56.0655 - val_loss: 55.9700\n",
            "Epoch 1252/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 55.9928 - val_loss: 55.8777\n",
            "Epoch 1253/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 55.9871 - val_loss: 55.8842\n",
            "Epoch 1254/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 55.9200 - val_loss: 55.7899\n",
            "Epoch 1255/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 55.9639 - val_loss: 56.0509\n",
            "Epoch 1256/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 55.8898 - val_loss: 55.8858\n",
            "Epoch 1257/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 55.9160 - val_loss: 55.8519\n",
            "Epoch 1258/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 55.8635 - val_loss: 55.6303\n",
            "Epoch 1259/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 55.8134 - val_loss: 55.7024\n",
            "Epoch 1260/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 55.8050 - val_loss: 55.5156\n",
            "Epoch 1261/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 55.8124 - val_loss: 56.2699\n",
            "Epoch 1262/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 55.7996 - val_loss: 55.3571\n",
            "Epoch 1263/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 55.7212 - val_loss: 55.8217\n",
            "Epoch 1264/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 55.7240 - val_loss: 55.4331\n",
            "Epoch 1265/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 55.6720 - val_loss: 55.7355\n",
            "Epoch 1266/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 55.6937 - val_loss: 55.2741\n",
            "Epoch 1267/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 55.6527 - val_loss: 55.7370\n",
            "Epoch 1268/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 55.6124 - val_loss: 55.5492\n",
            "Epoch 1269/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 55.5909 - val_loss: 55.4788\n",
            "Epoch 1270/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 55.5346 - val_loss: 55.4860\n",
            "Epoch 1271/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 55.5621 - val_loss: 55.5378\n",
            "Epoch 1272/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 55.5090 - val_loss: 55.5016\n",
            "Epoch 1273/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 55.4735 - val_loss: 55.4047\n",
            "Epoch 1274/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 55.4743 - val_loss: 55.3794\n",
            "Epoch 1275/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 55.4030 - val_loss: 55.3997\n",
            "Epoch 1276/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 55.3997 - val_loss: 55.2210\n",
            "Epoch 1277/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 55.3497 - val_loss: 55.0510\n",
            "Epoch 1278/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 55.3580 - val_loss: 55.1818\n",
            "Epoch 1279/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 55.3588 - val_loss: 55.1980\n",
            "Epoch 1280/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 55.3279 - val_loss: 55.2648\n",
            "Epoch 1281/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 55.2642 - val_loss: 55.2369\n",
            "Epoch 1282/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 55.2585 - val_loss: 55.3141\n",
            "Epoch 1283/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 55.2376 - val_loss: 55.1346\n",
            "Epoch 1284/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 55.2377 - val_loss: 55.0265\n",
            "Epoch 1285/6000\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 55.2080 - val_loss: 55.0468\n",
            "Epoch 1286/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 55.1498 - val_loss: 54.8566\n",
            "Epoch 1287/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 55.1578 - val_loss: 55.0419\n",
            "Epoch 1288/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 55.0987 - val_loss: 54.9009\n",
            "Epoch 1289/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 55.1111 - val_loss: 55.1278\n",
            "Epoch 1290/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 55.0396 - val_loss: 54.8598\n",
            "Epoch 1291/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 55.0061 - val_loss: 54.9416\n",
            "Epoch 1292/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 55.0393 - val_loss: 54.8101\n",
            "Epoch 1293/6000\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 54.9672 - val_loss: 55.0036\n",
            "Epoch 1294/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 54.9515 - val_loss: 54.7690\n",
            "Epoch 1295/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 54.9119 - val_loss: 54.8387\n",
            "Epoch 1296/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 54.9164 - val_loss: 54.5402\n",
            "Epoch 1297/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 54.9218 - val_loss: 54.7429\n",
            "Epoch 1298/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 54.8736 - val_loss: 54.6700\n",
            "Epoch 1299/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 54.8505 - val_loss: 54.6147\n",
            "Epoch 1300/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 54.8579 - val_loss: 54.6601\n",
            "Epoch 1301/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 54.8264 - val_loss: 54.7639\n",
            "Epoch 1302/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 54.7735 - val_loss: 54.6617\n",
            "Epoch 1303/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 54.7349 - val_loss: 54.5372\n",
            "Epoch 1304/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 54.7454 - val_loss: 54.2861\n",
            "Epoch 1305/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 54.6796 - val_loss: 54.5241\n",
            "Epoch 1306/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 54.6683 - val_loss: 54.3412\n",
            "Epoch 1307/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 54.6494 - val_loss: 54.4137\n",
            "Epoch 1308/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 54.6411 - val_loss: 54.2522\n",
            "Epoch 1309/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 54.5875 - val_loss: 54.5408\n",
            "Epoch 1310/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 54.5866 - val_loss: 54.1844\n",
            "Epoch 1311/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 54.6049 - val_loss: 54.3698\n",
            "Epoch 1312/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 54.5023 - val_loss: 54.4582\n",
            "Epoch 1313/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 54.5432 - val_loss: 54.4084\n",
            "Epoch 1314/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 54.4630 - val_loss: 54.4219\n",
            "Epoch 1315/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 54.4889 - val_loss: 54.1501\n",
            "Epoch 1316/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 54.4394 - val_loss: 54.3146\n",
            "Epoch 1317/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 54.4135 - val_loss: 54.0962\n",
            "Epoch 1318/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 54.3707 - val_loss: 54.1659\n",
            "Epoch 1319/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 54.3735 - val_loss: 54.0353\n",
            "Epoch 1320/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 54.3492 - val_loss: 54.2686\n",
            "Epoch 1321/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 54.4358 - val_loss: 54.1989\n",
            "Epoch 1322/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 54.3835 - val_loss: 54.2123\n",
            "Epoch 1323/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 54.3475 - val_loss: 54.0244\n",
            "Epoch 1324/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 54.2790 - val_loss: 54.1199\n",
            "Epoch 1325/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 54.2501 - val_loss: 54.0678\n",
            "Epoch 1326/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 54.2818 - val_loss: 53.9745\n",
            "Epoch 1327/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 54.1806 - val_loss: 54.0620\n",
            "Epoch 1328/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 54.1458 - val_loss: 53.9989\n",
            "Epoch 1329/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 54.2248 - val_loss: 54.1635\n",
            "Epoch 1330/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 54.1490 - val_loss: 53.9511\n",
            "Epoch 1331/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 54.0912 - val_loss: 53.9835\n",
            "Epoch 1332/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 54.0634 - val_loss: 53.9814\n",
            "Epoch 1333/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 54.0741 - val_loss: 54.0746\n",
            "Epoch 1334/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 54.0538 - val_loss: 53.9051\n",
            "Epoch 1335/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 54.0203 - val_loss: 54.0697\n",
            "Epoch 1336/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 53.9771 - val_loss: 53.8664\n",
            "Epoch 1337/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 53.9254 - val_loss: 53.9817\n",
            "Epoch 1338/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 53.9684 - val_loss: 53.7909\n",
            "Epoch 1339/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 53.9644 - val_loss: 53.8353\n",
            "Epoch 1340/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 53.9051 - val_loss: 53.8421\n",
            "Epoch 1341/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 53.8883 - val_loss: 53.8591\n",
            "Epoch 1342/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 53.8255 - val_loss: 53.5991\n",
            "Epoch 1343/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 53.7836 - val_loss: 53.5588\n",
            "Epoch 1344/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 53.7837 - val_loss: 53.7849\n",
            "Epoch 1345/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 53.7865 - val_loss: 53.3198\n",
            "Epoch 1346/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 53.7768 - val_loss: 53.6723\n",
            "Epoch 1347/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 53.7037 - val_loss: 53.5223\n",
            "Epoch 1348/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 53.7130 - val_loss: 53.5812\n",
            "Epoch 1349/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 53.7076 - val_loss: 53.6713\n",
            "Epoch 1350/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 53.6683 - val_loss: 53.4371\n",
            "Epoch 1351/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 53.6422 - val_loss: 53.5368\n",
            "Epoch 1352/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 53.6462 - val_loss: 53.5241\n",
            "Epoch 1353/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 53.6182 - val_loss: 53.3912\n",
            "Epoch 1354/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 53.5388 - val_loss: 53.4046\n",
            "Epoch 1355/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 53.5201 - val_loss: 53.4018\n",
            "Epoch 1356/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 53.5661 - val_loss: 53.4680\n",
            "Epoch 1357/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 53.4752 - val_loss: 53.3380\n",
            "Epoch 1358/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 53.5426 - val_loss: 53.3313\n",
            "Epoch 1359/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 53.4199 - val_loss: 53.3424\n",
            "Epoch 1360/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 53.4049 - val_loss: 53.1865\n",
            "Epoch 1361/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 53.4294 - val_loss: 53.1755\n",
            "Epoch 1362/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 53.4223 - val_loss: 53.1916\n",
            "Epoch 1363/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 53.3824 - val_loss: 53.1468\n",
            "Epoch 1364/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 53.2970 - val_loss: 53.1206\n",
            "Epoch 1365/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 53.2960 - val_loss: 53.1601\n",
            "Epoch 1366/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 53.2975 - val_loss: 53.1142\n",
            "Epoch 1367/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 53.2731 - val_loss: 53.1925\n",
            "Epoch 1368/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 53.2708 - val_loss: 52.9712\n",
            "Epoch 1369/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 53.2717 - val_loss: 53.1240\n",
            "Epoch 1370/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 53.2069 - val_loss: 53.1500\n",
            "Epoch 1371/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 53.1926 - val_loss: 53.0151\n",
            "Epoch 1372/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 53.2216 - val_loss: 52.9799\n",
            "Epoch 1373/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 53.1447 - val_loss: 52.9742\n",
            "Epoch 1374/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 53.1276 - val_loss: 52.7710\n",
            "Epoch 1375/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 53.0719 - val_loss: 52.8585\n",
            "Epoch 1376/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 53.0877 - val_loss: 52.8440\n",
            "Epoch 1377/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 53.0766 - val_loss: 52.9554\n",
            "Epoch 1378/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 53.1437 - val_loss: 52.7343\n",
            "Epoch 1379/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 53.0772 - val_loss: 52.9455\n",
            "Epoch 1380/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 53.0216 - val_loss: 52.9043\n",
            "Epoch 1381/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 52.9761 - val_loss: 52.6863\n",
            "Epoch 1382/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 53.0318 - val_loss: 52.8517\n",
            "Epoch 1383/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 52.9491 - val_loss: 52.7895\n",
            "Epoch 1384/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 52.9001 - val_loss: 52.8774\n",
            "Epoch 1385/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 52.8730 - val_loss: 52.7280\n",
            "Epoch 1386/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 52.8547 - val_loss: 52.6066\n",
            "Epoch 1387/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 52.8313 - val_loss: 52.6468\n",
            "Epoch 1388/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 52.7997 - val_loss: 52.7825\n",
            "Epoch 1389/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 52.8596 - val_loss: 52.5051\n",
            "Epoch 1390/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 52.7789 - val_loss: 52.8932\n",
            "Epoch 1391/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 52.8086 - val_loss: 52.7625\n",
            "Epoch 1392/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 52.7341 - val_loss: 52.5767\n",
            "Epoch 1393/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 52.6845 - val_loss: 52.5520\n",
            "Epoch 1394/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 52.6605 - val_loss: 52.4455\n",
            "Epoch 1395/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 52.6667 - val_loss: 52.8507\n",
            "Epoch 1396/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 52.6955 - val_loss: 52.2461\n",
            "Epoch 1397/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 52.6156 - val_loss: 52.4532\n",
            "Epoch 1398/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 52.5929 - val_loss: 52.3544\n",
            "Epoch 1399/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 52.5731 - val_loss: 52.2712\n",
            "Epoch 1400/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 52.5089 - val_loss: 52.4142\n",
            "Epoch 1401/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 52.5442 - val_loss: 52.3112\n",
            "Epoch 1402/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 52.5308 - val_loss: 52.4332\n",
            "Epoch 1403/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 52.4905 - val_loss: 52.1601\n",
            "Epoch 1404/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 52.4959 - val_loss: 52.3370\n",
            "Epoch 1405/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 52.4450 - val_loss: 52.2673\n",
            "Epoch 1406/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 52.4027 - val_loss: 52.1561\n",
            "Epoch 1407/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 52.3847 - val_loss: 52.2130\n",
            "Epoch 1408/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 52.3577 - val_loss: 52.1191\n",
            "Epoch 1409/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 52.3256 - val_loss: 52.0248\n",
            "Epoch 1410/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 52.3387 - val_loss: 52.1007\n",
            "Epoch 1411/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 52.3816 - val_loss: 52.1257\n",
            "Epoch 1412/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 52.3191 - val_loss: 52.2521\n",
            "Epoch 1413/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 52.3388 - val_loss: 52.4021\n",
            "Epoch 1414/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 52.2667 - val_loss: 52.3812\n",
            "Epoch 1415/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 52.2493 - val_loss: 52.2300\n",
            "Epoch 1416/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 52.2007 - val_loss: 52.2962\n",
            "Epoch 1417/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 52.2265 - val_loss: 52.2066\n",
            "Epoch 1418/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 52.1886 - val_loss: 52.3539\n",
            "Epoch 1419/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 52.1428 - val_loss: 51.9442\n",
            "Epoch 1420/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 52.1413 - val_loss: 51.9355\n",
            "Epoch 1421/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 52.0715 - val_loss: 51.9056\n",
            "Epoch 1422/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 52.1141 - val_loss: 52.1766\n",
            "Epoch 1423/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 52.0987 - val_loss: 51.8887\n",
            "Epoch 1424/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 52.0717 - val_loss: 52.0306\n",
            "Epoch 1425/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 52.0412 - val_loss: 52.1187\n",
            "Epoch 1426/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 52.0193 - val_loss: 51.8748\n",
            "Epoch 1427/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 52.0081 - val_loss: 51.9192\n",
            "Epoch 1428/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 51.9903 - val_loss: 51.9838\n",
            "Epoch 1429/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 51.9075 - val_loss: 51.8231\n",
            "Epoch 1430/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 51.8599 - val_loss: 52.0129\n",
            "Epoch 1431/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 51.8745 - val_loss: 51.7470\n",
            "Epoch 1432/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 51.8424 - val_loss: 51.7176\n",
            "Epoch 1433/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 51.8715 - val_loss: 51.7554\n",
            "Epoch 1434/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 51.8131 - val_loss: 51.4281\n",
            "Epoch 1435/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 51.8053 - val_loss: 51.5657\n",
            "Epoch 1436/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 51.7526 - val_loss: 51.5875\n",
            "Epoch 1437/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 51.7208 - val_loss: 51.5791\n",
            "Epoch 1438/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 51.6927 - val_loss: 51.7180\n",
            "Epoch 1439/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 51.7326 - val_loss: 51.4862\n",
            "Epoch 1440/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 51.7249 - val_loss: 51.4594\n",
            "Epoch 1441/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 51.6564 - val_loss: 51.6944\n",
            "Epoch 1442/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 51.6383 - val_loss: 51.5869\n",
            "Epoch 1443/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 51.5900 - val_loss: 51.5116\n",
            "Epoch 1444/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 51.5512 - val_loss: 51.3626\n",
            "Epoch 1445/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 51.5534 - val_loss: 51.3759\n",
            "Epoch 1446/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 51.6081 - val_loss: 51.4121\n",
            "Epoch 1447/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 51.5538 - val_loss: 51.3843\n",
            "Epoch 1448/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 51.4883 - val_loss: 51.2591\n",
            "Epoch 1449/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 51.4477 - val_loss: 51.2783\n",
            "Epoch 1450/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 51.5446 - val_loss: 51.1932\n",
            "Epoch 1451/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 51.4268 - val_loss: 51.1154\n",
            "Epoch 1452/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 51.4222 - val_loss: 51.2736\n",
            "Epoch 1453/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 51.4158 - val_loss: 51.0272\n",
            "Epoch 1454/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 51.3495 - val_loss: 51.0693\n",
            "Epoch 1455/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 51.3520 - val_loss: 51.1373\n",
            "Epoch 1456/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 51.3587 - val_loss: 51.0068\n",
            "Epoch 1457/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 51.2766 - val_loss: 51.0366\n",
            "Epoch 1458/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 51.3431 - val_loss: 50.9527\n",
            "Epoch 1459/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 51.2970 - val_loss: 50.8577\n",
            "Epoch 1460/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 51.2335 - val_loss: 51.1650\n",
            "Epoch 1461/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 51.2514 - val_loss: 50.9635\n",
            "Epoch 1462/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 51.2157 - val_loss: 51.2605\n",
            "Epoch 1463/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 51.1546 - val_loss: 50.9264\n",
            "Epoch 1464/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 51.2500 - val_loss: 51.0514\n",
            "Epoch 1465/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 51.1868 - val_loss: 50.9739\n",
            "Epoch 1466/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 51.1440 - val_loss: 50.9959\n",
            "Epoch 1467/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 51.1444 - val_loss: 51.1592\n",
            "Epoch 1468/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 51.1412 - val_loss: 51.0532\n",
            "Epoch 1469/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 51.0909 - val_loss: 50.8792\n",
            "Epoch 1470/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 51.0153 - val_loss: 50.9212\n",
            "Epoch 1471/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 51.0075 - val_loss: 50.9319\n",
            "Epoch 1472/6000\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 51.0156 - val_loss: 50.6950\n",
            "Epoch 1473/6000\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 50.9270 - val_loss: 50.9605\n",
            "Epoch 1474/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 50.9616 - val_loss: 50.8474\n",
            "Epoch 1475/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 50.9771 - val_loss: 50.6406\n",
            "Epoch 1476/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 50.9202 - val_loss: 50.8051\n",
            "Epoch 1477/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 50.9165 - val_loss: 50.4719\n",
            "Epoch 1478/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 50.8475 - val_loss: 50.7907\n",
            "Epoch 1479/6000\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 50.8779 - val_loss: 50.4436\n",
            "Epoch 1480/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 50.8535 - val_loss: 50.5933\n",
            "Epoch 1481/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 50.7828 - val_loss: 50.7008\n",
            "Epoch 1482/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 50.8560 - val_loss: 50.5035\n",
            "Epoch 1483/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 50.8036 - val_loss: 50.5582\n",
            "Epoch 1484/6000\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 50.7555 - val_loss: 50.6525\n",
            "Epoch 1485/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 50.7501 - val_loss: 50.6618\n",
            "Epoch 1486/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 50.7006 - val_loss: 50.5052\n",
            "Epoch 1487/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 50.6822 - val_loss: 50.3752\n",
            "Epoch 1488/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 50.6479 - val_loss: 50.6279\n",
            "Epoch 1489/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 50.6103 - val_loss: 50.4421\n",
            "Epoch 1490/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 50.6257 - val_loss: 50.4361\n",
            "Epoch 1491/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 50.5728 - val_loss: 50.3749\n",
            "Epoch 1492/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 50.6057 - val_loss: 50.4054\n",
            "Epoch 1493/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 50.5692 - val_loss: 50.2538\n",
            "Epoch 1494/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 50.5790 - val_loss: 50.3842\n",
            "Epoch 1495/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 50.4878 - val_loss: 50.1947\n",
            "Epoch 1496/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 50.4899 - val_loss: 50.3520\n",
            "Epoch 1497/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 50.5148 - val_loss: 50.1040\n",
            "Epoch 1498/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 50.5272 - val_loss: 50.2508\n",
            "Epoch 1499/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 50.4114 - val_loss: 50.2698\n",
            "Epoch 1500/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 50.4142 - val_loss: 50.1505\n",
            "Epoch 1501/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 50.4253 - val_loss: 50.1939\n",
            "Epoch 1502/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 50.3641 - val_loss: 50.2203\n",
            "Epoch 1503/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 50.3906 - val_loss: 50.1430\n",
            "Epoch 1504/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 50.3101 - val_loss: 50.3153\n",
            "Epoch 1505/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 50.2832 - val_loss: 50.3699\n",
            "Epoch 1506/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 50.2529 - val_loss: 50.1658\n",
            "Epoch 1507/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 50.2800 - val_loss: 50.1053\n",
            "Epoch 1508/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 50.2734 - val_loss: 50.2735\n",
            "Epoch 1509/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 50.2332 - val_loss: 50.0603\n",
            "Epoch 1510/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 50.1911 - val_loss: 49.9396\n",
            "Epoch 1511/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 50.2040 - val_loss: 50.1210\n",
            "Epoch 1512/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 50.1792 - val_loss: 50.1196\n",
            "Epoch 1513/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 50.1279 - val_loss: 50.0255\n",
            "Epoch 1514/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 50.1251 - val_loss: 49.9855\n",
            "Epoch 1515/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 50.0848 - val_loss: 50.0811\n",
            "Epoch 1516/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 50.0897 - val_loss: 49.9294\n",
            "Epoch 1517/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 50.1180 - val_loss: 50.1781\n",
            "Epoch 1518/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 50.0163 - val_loss: 49.8705\n",
            "Epoch 1519/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 49.9977 - val_loss: 49.8697\n",
            "Epoch 1520/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 49.9981 - val_loss: 49.8618\n",
            "Epoch 1521/6000\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 50.0287 - val_loss: 49.7707\n",
            "Epoch 1522/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 49.9632 - val_loss: 49.7887\n",
            "Epoch 1523/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 49.9692 - val_loss: 49.8262\n",
            "Epoch 1524/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 49.9211 - val_loss: 49.7577\n",
            "Epoch 1525/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 49.9242 - val_loss: 49.9424\n",
            "Epoch 1526/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 49.8965 - val_loss: 49.7004\n",
            "Epoch 1527/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 49.8275 - val_loss: 49.6012\n",
            "Epoch 1528/6000\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 49.8431 - val_loss: 49.5471\n",
            "Epoch 1529/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 49.8497 - val_loss: 49.5555\n",
            "Epoch 1530/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 49.7922 - val_loss: 49.4987\n",
            "Epoch 1531/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 49.9066 - val_loss: 49.8669\n",
            "Epoch 1532/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 49.7890 - val_loss: 49.6878\n",
            "Epoch 1533/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 49.8586 - val_loss: 49.5526\n",
            "Epoch 1534/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 49.7443 - val_loss: 49.4167\n",
            "Epoch 1535/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 49.7011 - val_loss: 49.5065\n",
            "Epoch 1536/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 49.7460 - val_loss: 49.6401\n",
            "Epoch 1537/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 49.6623 - val_loss: 49.5057\n",
            "Epoch 1538/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 49.6814 - val_loss: 49.3662\n",
            "Epoch 1539/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 49.6187 - val_loss: 49.4359\n",
            "Epoch 1540/6000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 49.6426 - val_loss: 49.4718\n",
            "Epoch 1541/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 49.5601 - val_loss: 49.6071\n",
            "Epoch 1542/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 49.5328 - val_loss: 49.3920\n",
            "Epoch 1543/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 49.5511 - val_loss: 49.3949\n",
            "Epoch 1544/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 49.5161 - val_loss: 49.2685\n",
            "Epoch 1545/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 49.5297 - val_loss: 49.3171\n",
            "Epoch 1546/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 49.5162 - val_loss: 49.6422\n",
            "Epoch 1547/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 49.4720 - val_loss: 49.3885\n",
            "Epoch 1548/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 49.4471 - val_loss: 49.3103\n",
            "Epoch 1549/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 49.4741 - val_loss: 49.4268\n",
            "Epoch 1550/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 49.4407 - val_loss: 49.3855\n",
            "Epoch 1551/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 49.3677 - val_loss: 49.3434\n",
            "Epoch 1552/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 49.4071 - val_loss: 49.1788\n",
            "Epoch 1553/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 49.4220 - val_loss: 49.0973\n",
            "Epoch 1554/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 49.3849 - val_loss: 49.3485\n",
            "Epoch 1555/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 49.2614 - val_loss: 49.2750\n",
            "Epoch 1556/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 49.2894 - val_loss: 49.2021\n",
            "Epoch 1557/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 49.2540 - val_loss: 49.2609\n",
            "Epoch 1558/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 49.2939 - val_loss: 49.1828\n",
            "Epoch 1559/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 49.2244 - val_loss: 49.0530\n",
            "Epoch 1560/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 49.1818 - val_loss: 49.2261\n",
            "Epoch 1561/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 49.2256 - val_loss: 49.0485\n",
            "Epoch 1562/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 49.2659 - val_loss: 49.2915\n",
            "Epoch 1563/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 49.1618 - val_loss: 49.4036\n",
            "Epoch 1564/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 49.2147 - val_loss: 49.0875\n",
            "Epoch 1565/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 49.1322 - val_loss: 49.1048\n",
            "Epoch 1566/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 49.0486 - val_loss: 49.1724\n",
            "Epoch 1567/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 49.0867 - val_loss: 48.9805\n",
            "Epoch 1568/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 49.0517 - val_loss: 48.9849\n",
            "Epoch 1569/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 49.0240 - val_loss: 48.6876\n",
            "Epoch 1570/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 49.0842 - val_loss: 49.1558\n",
            "Epoch 1571/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 48.9737 - val_loss: 48.8240\n",
            "Epoch 1572/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 48.9694 - val_loss: 48.9618\n",
            "Epoch 1573/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 48.9311 - val_loss: 48.7445\n",
            "Epoch 1574/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 48.9431 - val_loss: 48.9483\n",
            "Epoch 1575/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 48.9517 - val_loss: 48.9367\n",
            "Epoch 1576/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 48.8651 - val_loss: 48.6969\n",
            "Epoch 1577/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 48.8610 - val_loss: 48.7050\n",
            "Epoch 1578/6000\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 48.9541 - val_loss: 48.9564\n",
            "Epoch 1579/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 48.8554 - val_loss: 48.8342\n",
            "Epoch 1580/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 48.7758 - val_loss: 48.6834\n",
            "Epoch 1581/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 48.7729 - val_loss: 48.5996\n",
            "Epoch 1582/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 48.7811 - val_loss: 48.6398\n",
            "Epoch 1583/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 48.8100 - val_loss: 48.7287\n",
            "Epoch 1584/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 48.7161 - val_loss: 48.5762\n",
            "Epoch 1585/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 48.7340 - val_loss: 48.6103\n",
            "Epoch 1586/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 48.7906 - val_loss: 48.4085\n",
            "Epoch 1587/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 48.7712 - val_loss: 48.4868\n",
            "Epoch 1588/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 48.6750 - val_loss: 48.4948\n",
            "Epoch 1589/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 48.6573 - val_loss: 48.7599\n",
            "Epoch 1590/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 48.6126 - val_loss: 48.2335\n",
            "Epoch 1591/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 48.6472 - val_loss: 48.6636\n",
            "Epoch 1592/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 48.6509 - val_loss: 48.6050\n",
            "Epoch 1593/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 48.5748 - val_loss: 48.5012\n",
            "Epoch 1594/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 48.5277 - val_loss: 48.5243\n",
            "Epoch 1595/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 48.5462 - val_loss: 48.4023\n",
            "Epoch 1596/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 48.5461 - val_loss: 48.4426\n",
            "Epoch 1597/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 48.4414 - val_loss: 48.3614\n",
            "Epoch 1598/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 48.5173 - val_loss: 48.3873\n",
            "Epoch 1599/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 48.4829 - val_loss: 48.3831\n",
            "Epoch 1600/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 48.4166 - val_loss: 48.4602\n",
            "Epoch 1601/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 48.4268 - val_loss: 48.2445\n",
            "Epoch 1602/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 48.4368 - val_loss: 48.3154\n",
            "Epoch 1603/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 48.4260 - val_loss: 48.3762\n",
            "Epoch 1604/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 48.3743 - val_loss: 48.3180\n",
            "Epoch 1605/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 48.2907 - val_loss: 48.2257\n",
            "Epoch 1606/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 48.3466 - val_loss: 48.0393\n",
            "Epoch 1607/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 48.2861 - val_loss: 48.2852\n",
            "Epoch 1608/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 48.2686 - val_loss: 48.0558\n",
            "Epoch 1609/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 48.2463 - val_loss: 48.2359\n",
            "Epoch 1610/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 48.2440 - val_loss: 48.1758\n",
            "Epoch 1611/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 48.2587 - val_loss: 48.0538\n",
            "Epoch 1612/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 48.2115 - val_loss: 47.8930\n",
            "Epoch 1613/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 48.1098 - val_loss: 48.0563\n",
            "Epoch 1614/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 48.2590 - val_loss: 47.9159\n",
            "Epoch 1615/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 48.1466 - val_loss: 47.9369\n",
            "Epoch 1616/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 48.0542 - val_loss: 47.8518\n",
            "Epoch 1617/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 48.0431 - val_loss: 47.9950\n",
            "Epoch 1618/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 48.0942 - val_loss: 47.9556\n",
            "Epoch 1619/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 48.1517 - val_loss: 47.8725\n",
            "Epoch 1620/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 48.0836 - val_loss: 47.6587\n",
            "Epoch 1621/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 48.0209 - val_loss: 47.7804\n",
            "Epoch 1622/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 47.9762 - val_loss: 47.7426\n",
            "Epoch 1623/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 47.9724 - val_loss: 47.6479\n",
            "Epoch 1624/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 47.9372 - val_loss: 47.6116\n",
            "Epoch 1625/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 47.9400 - val_loss: 47.7240\n",
            "Epoch 1626/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 47.9740 - val_loss: 47.5339\n",
            "Epoch 1627/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 47.9309 - val_loss: 47.7397\n",
            "Epoch 1628/6000\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 47.8404 - val_loss: 47.6324\n",
            "Epoch 1629/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 47.8299 - val_loss: 47.6415\n",
            "Epoch 1630/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 48.0121 - val_loss: 47.8550\n",
            "Epoch 1631/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 47.8089 - val_loss: 47.6867\n",
            "Epoch 1632/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 47.7809 - val_loss: 47.7367\n",
            "Epoch 1633/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 47.8485 - val_loss: 47.5857\n",
            "Epoch 1634/6000\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 47.9027 - val_loss: 47.6442\n",
            "Epoch 1635/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 47.7741 - val_loss: 47.4296\n",
            "Epoch 1636/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 47.7129 - val_loss: 47.4892\n",
            "Epoch 1637/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 47.6980 - val_loss: 47.5273\n",
            "Epoch 1638/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 47.7132 - val_loss: 47.4754\n",
            "Epoch 1639/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 47.7023 - val_loss: 47.5339\n",
            "Epoch 1640/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 47.6063 - val_loss: 47.5280\n",
            "Epoch 1641/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 47.6665 - val_loss: 47.5240\n",
            "Epoch 1642/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 47.7254 - val_loss: 47.5258\n",
            "Epoch 1643/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 47.6131 - val_loss: 47.5029\n",
            "Epoch 1644/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 47.5327 - val_loss: 47.4073\n",
            "Epoch 1645/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 47.5430 - val_loss: 47.2207\n",
            "Epoch 1646/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 47.5270 - val_loss: 47.2856\n",
            "Epoch 1647/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 47.5451 - val_loss: 47.5495\n",
            "Epoch 1648/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 47.5861 - val_loss: 47.4774\n",
            "Epoch 1649/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 47.4342 - val_loss: 47.4790\n",
            "Epoch 1650/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 47.5133 - val_loss: 47.2645\n",
            "Epoch 1651/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 47.4952 - val_loss: 47.4799\n",
            "Epoch 1652/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 47.4546 - val_loss: 47.2191\n",
            "Epoch 1653/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 47.4350 - val_loss: 47.3480\n",
            "Epoch 1654/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 47.3966 - val_loss: 47.2972\n",
            "Epoch 1655/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 47.3228 - val_loss: 47.2538\n",
            "Epoch 1656/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 47.3589 - val_loss: 47.1526\n",
            "Epoch 1657/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 47.2880 - val_loss: 47.1821\n",
            "Epoch 1658/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 47.3263 - val_loss: 47.0825\n",
            "Epoch 1659/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 47.2802 - val_loss: 47.2207\n",
            "Epoch 1660/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 47.2582 - val_loss: 47.3820\n",
            "Epoch 1661/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 47.2281 - val_loss: 47.2254\n",
            "Epoch 1662/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 47.2307 - val_loss: 47.1642\n",
            "Epoch 1663/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 47.1851 - val_loss: 47.1184\n",
            "Epoch 1664/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 47.2169 - val_loss: 47.0600\n",
            "Epoch 1665/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 47.1298 - val_loss: 47.0039\n",
            "Epoch 1666/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 47.1318 - val_loss: 47.2525\n",
            "Epoch 1667/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 47.1274 - val_loss: 47.1034\n",
            "Epoch 1668/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 47.1321 - val_loss: 47.1718\n",
            "Epoch 1669/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 47.0992 - val_loss: 47.0453\n",
            "Epoch 1670/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 47.0290 - val_loss: 47.0685\n",
            "Epoch 1671/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 47.0090 - val_loss: 46.9540\n",
            "Epoch 1672/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 47.0142 - val_loss: 46.9402\n",
            "Epoch 1673/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 46.9705 - val_loss: 46.9978\n",
            "Epoch 1674/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 47.0128 - val_loss: 46.9516\n",
            "Epoch 1675/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 46.9843 - val_loss: 47.0130\n",
            "Epoch 1676/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 47.0022 - val_loss: 46.9658\n",
            "Epoch 1677/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 46.9911 - val_loss: 47.0419\n",
            "Epoch 1678/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 46.9678 - val_loss: 46.8722\n",
            "Epoch 1679/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 46.9183 - val_loss: 47.0601\n",
            "Epoch 1680/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 47.0059 - val_loss: 46.8575\n",
            "Epoch 1681/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 46.9509 - val_loss: 46.9901\n",
            "Epoch 1682/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 46.8593 - val_loss: 46.7925\n",
            "Epoch 1683/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 46.8176 - val_loss: 46.9762\n",
            "Epoch 1684/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 46.9041 - val_loss: 46.7469\n",
            "Epoch 1685/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 46.7994 - val_loss: 47.0305\n",
            "Epoch 1686/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 46.7776 - val_loss: 47.0020\n",
            "Epoch 1687/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 46.7837 - val_loss: 46.7776\n",
            "Epoch 1688/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 46.7412 - val_loss: 46.7907\n",
            "Epoch 1689/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 46.7122 - val_loss: 47.1032\n",
            "Epoch 1690/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 46.7640 - val_loss: 46.8145\n",
            "Epoch 1691/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 46.6675 - val_loss: 46.6213\n",
            "Epoch 1692/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 46.6852 - val_loss: 46.6894\n",
            "Epoch 1693/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 46.6507 - val_loss: 46.8124\n",
            "Epoch 1694/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 46.6439 - val_loss: 46.7274\n",
            "Epoch 1695/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 46.6089 - val_loss: 46.5682\n",
            "Epoch 1696/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 46.5874 - val_loss: 46.7204\n",
            "Epoch 1697/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 46.5405 - val_loss: 46.6912\n",
            "Epoch 1698/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 46.5746 - val_loss: 46.6838\n",
            "Epoch 1699/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 46.4921 - val_loss: 46.6138\n",
            "Epoch 1700/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 46.4733 - val_loss: 46.6915\n",
            "Epoch 1701/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 46.4695 - val_loss: 46.6245\n",
            "Epoch 1702/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 46.4384 - val_loss: 46.6621\n",
            "Epoch 1703/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 46.4064 - val_loss: 46.4833\n",
            "Epoch 1704/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 46.4748 - val_loss: 46.5693\n",
            "Epoch 1705/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 46.4045 - val_loss: 46.5289\n",
            "Epoch 1706/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 46.4111 - val_loss: 46.4600\n",
            "Epoch 1707/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 46.3580 - val_loss: 46.4478\n",
            "Epoch 1708/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 46.3614 - val_loss: 46.4225\n",
            "Epoch 1709/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 46.3669 - val_loss: 46.4012\n",
            "Epoch 1710/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 46.2882 - val_loss: 46.4020\n",
            "Epoch 1711/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 46.2939 - val_loss: 46.3199\n",
            "Epoch 1712/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 46.3548 - val_loss: 46.5066\n",
            "Epoch 1713/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 46.2790 - val_loss: 46.3594\n",
            "Epoch 1714/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 46.2534 - val_loss: 46.2039\n",
            "Epoch 1715/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 46.3288 - val_loss: 46.1423\n",
            "Epoch 1716/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 46.2432 - val_loss: 46.2989\n",
            "Epoch 1717/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 46.2013 - val_loss: 46.2453\n",
            "Epoch 1718/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 46.2018 - val_loss: 46.1430\n",
            "Epoch 1719/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 46.1798 - val_loss: 46.4530\n",
            "Epoch 1720/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 46.1886 - val_loss: 46.1305\n",
            "Epoch 1721/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 46.2007 - val_loss: 46.4133\n",
            "Epoch 1722/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 46.2322 - val_loss: 46.4008\n",
            "Epoch 1723/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 46.1229 - val_loss: 46.1187\n",
            "Epoch 1724/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 46.1436 - val_loss: 46.2249\n",
            "Epoch 1725/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 46.0688 - val_loss: 46.2244\n",
            "Epoch 1726/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 46.0298 - val_loss: 46.0124\n",
            "Epoch 1727/6000\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 46.0058 - val_loss: 46.3181\n",
            "Epoch 1728/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 46.0055 - val_loss: 46.2327\n",
            "Epoch 1729/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 46.0914 - val_loss: 46.0228\n",
            "Epoch 1730/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 45.9118 - val_loss: 45.9105\n",
            "Epoch 1731/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 45.9898 - val_loss: 45.9796\n",
            "Epoch 1732/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 45.9196 - val_loss: 46.1806\n",
            "Epoch 1733/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 45.9726 - val_loss: 45.8112\n",
            "Epoch 1734/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 45.8686 - val_loss: 45.9839\n",
            "Epoch 1735/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 45.8331 - val_loss: 45.8256\n",
            "Epoch 1736/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 45.9042 - val_loss: 45.7935\n",
            "Epoch 1737/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 45.8805 - val_loss: 45.7782\n",
            "Epoch 1738/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 45.7837 - val_loss: 45.7384\n",
            "Epoch 1739/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 45.7767 - val_loss: 45.7346\n",
            "Epoch 1740/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 45.7254 - val_loss: 45.6428\n",
            "Epoch 1741/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 45.9008 - val_loss: 45.6089\n",
            "Epoch 1742/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 45.6863 - val_loss: 45.7895\n",
            "Epoch 1743/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 45.7067 - val_loss: 45.5944\n",
            "Epoch 1744/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 45.6295 - val_loss: 45.5351\n",
            "Epoch 1745/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 45.6854 - val_loss: 45.5511\n",
            "Epoch 1746/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 45.6186 - val_loss: 45.5909\n",
            "Epoch 1747/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 45.6483 - val_loss: 45.3728\n",
            "Epoch 1748/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 45.5972 - val_loss: 45.5030\n",
            "Epoch 1749/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 45.6966 - val_loss: 45.4613\n",
            "Epoch 1750/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 45.5442 - val_loss: 45.4749\n",
            "Epoch 1751/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 45.6045 - val_loss: 45.5481\n",
            "Epoch 1752/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 45.6263 - val_loss: 45.5487\n",
            "Epoch 1753/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 45.6491 - val_loss: 45.4042\n",
            "Epoch 1754/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 45.5457 - val_loss: 45.5089\n",
            "Epoch 1755/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 45.4924 - val_loss: 45.2977\n",
            "Epoch 1756/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 45.5298 - val_loss: 45.4982\n",
            "Epoch 1757/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 45.4575 - val_loss: 45.4395\n",
            "Epoch 1758/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 45.5460 - val_loss: 45.3192\n",
            "Epoch 1759/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 45.4730 - val_loss: 45.3437\n",
            "Epoch 1760/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 45.4117 - val_loss: 45.3206\n",
            "Epoch 1761/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 45.3974 - val_loss: 45.2147\n",
            "Epoch 1762/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 45.3590 - val_loss: 45.2584\n",
            "Epoch 1763/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 45.4574 - val_loss: 45.4362\n",
            "Epoch 1764/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 45.3590 - val_loss: 45.3926\n",
            "Epoch 1765/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 45.3584 - val_loss: 45.0744\n",
            "Epoch 1766/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 45.2829 - val_loss: 45.0921\n",
            "Epoch 1767/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 45.2540 - val_loss: 45.2171\n",
            "Epoch 1768/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 45.3615 - val_loss: 45.2056\n",
            "Epoch 1769/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 45.2965 - val_loss: 45.1831\n",
            "Epoch 1770/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 45.1944 - val_loss: 45.0460\n",
            "Epoch 1771/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 45.2161 - val_loss: 45.0811\n",
            "Epoch 1772/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 45.2321 - val_loss: 45.0169\n",
            "Epoch 1773/6000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 45.2036 - val_loss: 45.1139\n",
            "Epoch 1774/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 45.1961 - val_loss: 45.0749\n",
            "Epoch 1775/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 45.0929 - val_loss: 44.9211\n",
            "Epoch 1776/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 45.1759 - val_loss: 45.0824\n",
            "Epoch 1777/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 45.0776 - val_loss: 44.8626\n",
            "Epoch 1778/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 45.1643 - val_loss: 45.0020\n",
            "Epoch 1779/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 45.0319 - val_loss: 44.7464\n",
            "Epoch 1780/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 45.0494 - val_loss: 45.0427\n",
            "Epoch 1781/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 44.9794 - val_loss: 44.8828\n",
            "Epoch 1782/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 44.9920 - val_loss: 44.8979\n",
            "Epoch 1783/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 44.9988 - val_loss: 45.0044\n",
            "Epoch 1784/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 45.0082 - val_loss: 44.9176\n",
            "Epoch 1785/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 45.0179 - val_loss: 44.7969\n",
            "Epoch 1786/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 44.9628 - val_loss: 44.7904\n",
            "Epoch 1787/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 44.9194 - val_loss: 44.8945\n",
            "Epoch 1788/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 44.8997 - val_loss: 44.7005\n",
            "Epoch 1789/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 44.9638 - val_loss: 44.5892\n",
            "Epoch 1790/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 45.0194 - val_loss: 44.8354\n",
            "Epoch 1791/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 44.8545 - val_loss: 44.8721\n",
            "Epoch 1792/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 44.8760 - val_loss: 44.6711\n",
            "Epoch 1793/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 44.8464 - val_loss: 44.7356\n",
            "Epoch 1794/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 44.7863 - val_loss: 44.5549\n",
            "Epoch 1795/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 44.8221 - val_loss: 44.5824\n",
            "Epoch 1796/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 44.7262 - val_loss: 44.6047\n",
            "Epoch 1797/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 44.7310 - val_loss: 44.5802\n",
            "Epoch 1798/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 44.6736 - val_loss: 44.5096\n",
            "Epoch 1799/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 44.6818 - val_loss: 44.5578\n",
            "Epoch 1800/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 44.8198 - val_loss: 44.5184\n",
            "Epoch 1801/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 44.6356 - val_loss: 44.3391\n",
            "Epoch 1802/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 44.6469 - val_loss: 44.5039\n",
            "Epoch 1803/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 44.6741 - val_loss: 44.5163\n",
            "Epoch 1804/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 44.7007 - val_loss: 44.3646\n",
            "Epoch 1805/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 44.6387 - val_loss: 44.3974\n",
            "Epoch 1806/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 44.5541 - val_loss: 44.2994\n",
            "Epoch 1807/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 44.6144 - val_loss: 44.3580\n",
            "Epoch 1808/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 44.5213 - val_loss: 44.3359\n",
            "Epoch 1809/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 44.5085 - val_loss: 44.1789\n",
            "Epoch 1810/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 44.5267 - val_loss: 44.3894\n",
            "Epoch 1811/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 44.5352 - val_loss: 44.2127\n",
            "Epoch 1812/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 44.5054 - val_loss: 44.1431\n",
            "Epoch 1813/6000\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 44.4898 - val_loss: 44.2242\n",
            "Epoch 1814/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 44.4297 - val_loss: 44.1930\n",
            "Epoch 1815/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 44.4098 - val_loss: 44.1161\n",
            "Epoch 1816/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 44.3669 - val_loss: 44.0262\n",
            "Epoch 1817/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 44.4482 - val_loss: 44.2017\n",
            "Epoch 1818/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 44.3420 - val_loss: 43.9721\n",
            "Epoch 1819/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 44.3010 - val_loss: 44.1890\n",
            "Epoch 1820/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 44.3966 - val_loss: 43.9655\n",
            "Epoch 1821/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 44.3346 - val_loss: 44.0757\n",
            "Epoch 1822/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 44.2882 - val_loss: 44.0891\n",
            "Epoch 1823/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 44.3329 - val_loss: 44.2443\n",
            "Epoch 1824/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 44.3292 - val_loss: 43.9404\n",
            "Epoch 1825/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 44.2510 - val_loss: 43.9843\n",
            "Epoch 1826/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 44.2736 - val_loss: 44.1269\n",
            "Epoch 1827/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 44.1841 - val_loss: 44.2445\n",
            "Epoch 1828/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 44.2011 - val_loss: 43.9794\n",
            "Epoch 1829/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 44.1646 - val_loss: 44.0405\n",
            "Epoch 1830/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 44.1654 - val_loss: 43.9430\n",
            "Epoch 1831/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 44.1666 - val_loss: 43.8617\n",
            "Epoch 1832/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 44.1817 - val_loss: 43.9421\n",
            "Epoch 1833/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 44.0866 - val_loss: 43.9608\n",
            "Epoch 1834/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 44.1564 - val_loss: 44.0631\n",
            "Epoch 1835/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 44.0426 - val_loss: 43.7974\n",
            "Epoch 1836/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 44.1454 - val_loss: 43.8899\n",
            "Epoch 1837/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 44.0505 - val_loss: 43.9260\n",
            "Epoch 1838/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 44.0567 - val_loss: 43.8725\n",
            "Epoch 1839/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 43.9624 - val_loss: 43.9138\n",
            "Epoch 1840/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 44.0319 - val_loss: 43.9638\n",
            "Epoch 1841/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 43.9496 - val_loss: 43.6358\n",
            "Epoch 1842/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 44.0469 - val_loss: 43.8775\n",
            "Epoch 1843/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 43.9385 - val_loss: 43.7515\n",
            "Epoch 1844/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 43.9340 - val_loss: 43.8081\n",
            "Epoch 1845/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 43.9180 - val_loss: 43.8048\n",
            "Epoch 1846/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 43.8892 - val_loss: 43.7287\n",
            "Epoch 1847/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 43.8646 - val_loss: 43.7487\n",
            "Epoch 1848/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 43.8563 - val_loss: 43.8067\n",
            "Epoch 1849/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 43.8688 - val_loss: 43.7324\n",
            "Epoch 1850/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 43.8889 - val_loss: 43.8480\n",
            "Epoch 1851/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 43.7864 - val_loss: 43.6668\n",
            "Epoch 1852/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 43.8056 - val_loss: 43.8844\n",
            "Epoch 1853/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 43.7461 - val_loss: 43.7694\n",
            "Epoch 1854/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 43.6922 - val_loss: 43.7120\n",
            "Epoch 1855/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 43.6792 - val_loss: 43.9202\n",
            "Epoch 1856/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 43.7063 - val_loss: 43.8718\n",
            "Epoch 1857/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 43.6685 - val_loss: 43.8831\n",
            "Epoch 1858/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 43.6446 - val_loss: 44.0372\n",
            "Epoch 1859/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 43.5601 - val_loss: 43.7626\n",
            "Epoch 1860/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 43.6424 - val_loss: 43.9582\n",
            "Epoch 1861/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 43.5765 - val_loss: 43.9890\n",
            "Epoch 1862/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 43.5011 - val_loss: 43.9119\n",
            "Epoch 1863/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 43.4848 - val_loss: 44.0219\n",
            "Epoch 1864/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 43.4110 - val_loss: 44.1567\n",
            "Epoch 1865/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 43.4007 - val_loss: 44.2810\n",
            "Epoch 1866/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 43.3170 - val_loss: 44.1377\n",
            "Epoch 1867/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 43.3276 - val_loss: 44.2457\n",
            "Epoch 1868/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 43.3251 - val_loss: 44.2351\n",
            "Epoch 1869/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 43.2705 - val_loss: 44.2796\n",
            "Epoch 1870/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 43.1891 - val_loss: 44.4861\n",
            "Epoch 1871/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 43.2247 - val_loss: 44.2040\n",
            "Epoch 1872/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 43.2075 - val_loss: 44.1705\n",
            "Epoch 1873/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 43.1397 - val_loss: 44.2435\n",
            "Epoch 1874/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 43.1610 - val_loss: 44.1162\n",
            "Epoch 1875/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 43.1842 - val_loss: 44.2379\n",
            "Epoch 1876/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 43.0442 - val_loss: 44.0421\n",
            "Epoch 1877/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 43.0520 - val_loss: 44.1701\n",
            "Epoch 1878/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 42.9578 - val_loss: 44.3946\n",
            "Epoch 1879/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 43.0420 - val_loss: 44.3018\n",
            "Epoch 1880/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 42.9670 - val_loss: 44.3530\n",
            "Epoch 1881/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 42.9035 - val_loss: 44.3218\n",
            "Epoch 1882/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 42.9067 - val_loss: 44.3047\n",
            "Epoch 1883/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 42.7860 - val_loss: 44.2357\n",
            "Epoch 1884/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 42.7734 - val_loss: 44.2923\n",
            "Epoch 1885/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 42.7220 - val_loss: 44.4605\n",
            "Epoch 1886/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 42.6608 - val_loss: 44.1673\n",
            "Epoch 1887/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 42.7378 - val_loss: 44.0712\n",
            "Epoch 1888/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 42.9244 - val_loss: 44.3458\n",
            "Epoch 1889/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 42.7481 - val_loss: 44.0236\n",
            "Epoch 1890/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 42.7152 - val_loss: 44.1728\n",
            "Epoch 1891/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 42.5761 - val_loss: 44.2715\n",
            "Epoch 1892/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 42.4792 - val_loss: 44.3542\n",
            "Epoch 1893/6000\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 42.4636 - val_loss: 44.4947\n",
            "Epoch 1894/6000\n",
            "6/6 [==============================] - 0s 60ms/step - loss: 42.4589 - val_loss: 44.3656\n",
            "Epoch 1895/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 42.3580 - val_loss: 44.3680\n",
            "Epoch 1896/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 42.3684 - val_loss: 44.2246\n",
            "Epoch 1897/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 42.2830 - val_loss: 43.9605\n",
            "Epoch 1898/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 42.3660 - val_loss: 44.0186\n",
            "Epoch 1899/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 42.2907 - val_loss: 43.8928\n",
            "Epoch 1900/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 42.2658 - val_loss: 43.8166\n",
            "Epoch 1901/6000\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 42.3488 - val_loss: 43.8935\n",
            "Epoch 1902/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 42.1952 - val_loss: 44.0337\n",
            "Epoch 1903/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 42.1637 - val_loss: 43.7561\n",
            "Epoch 1904/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 42.1050 - val_loss: 43.6521\n",
            "Epoch 1905/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 42.1682 - val_loss: 43.8350\n",
            "Epoch 1906/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 42.1137 - val_loss: 43.5296\n",
            "Epoch 1907/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 42.0704 - val_loss: 43.6287\n",
            "Epoch 1908/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 42.1275 - val_loss: 43.2821\n",
            "Epoch 1909/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 42.1361 - val_loss: 43.1303\n",
            "Epoch 1910/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 42.0375 - val_loss: 43.1862\n",
            "Epoch 1911/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 41.9953 - val_loss: 43.2830\n",
            "Epoch 1912/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 41.9837 - val_loss: 42.9784\n",
            "Epoch 1913/6000\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 41.9033 - val_loss: 43.0305\n",
            "Epoch 1914/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 41.9171 - val_loss: 42.9319\n",
            "Epoch 1915/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 41.9230 - val_loss: 42.8969\n",
            "Epoch 1916/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 41.8123 - val_loss: 42.9433\n",
            "Epoch 1917/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 41.8073 - val_loss: 42.8815\n",
            "Epoch 1918/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 41.7672 - val_loss: 42.7269\n",
            "Epoch 1919/6000\n",
            "6/6 [==============================] - 0s 41ms/step - loss: 41.8473 - val_loss: 42.5296\n",
            "Epoch 1920/6000\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 41.7731 - val_loss: 42.7343\n",
            "Epoch 1921/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 41.7572 - val_loss: 42.8125\n",
            "Epoch 1922/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 41.7712 - val_loss: 42.8344\n",
            "Epoch 1923/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 41.6827 - val_loss: 42.9516\n",
            "Epoch 1924/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 41.7591 - val_loss: 42.6168\n",
            "Epoch 1925/6000\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 41.6977 - val_loss: 42.7575\n",
            "Epoch 1926/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 41.6105 - val_loss: 42.7353\n",
            "Epoch 1927/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 41.6237 - val_loss: 42.5728\n",
            "Epoch 1928/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 41.6409 - val_loss: 42.6345\n",
            "Epoch 1929/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 41.6375 - val_loss: 42.2842\n",
            "Epoch 1930/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 41.5163 - val_loss: 42.5297\n",
            "Epoch 1931/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 41.5582 - val_loss: 42.4439\n",
            "Epoch 1932/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 41.4950 - val_loss: 42.2453\n",
            "Epoch 1933/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 41.5022 - val_loss: 42.2304\n",
            "Epoch 1934/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 41.4332 - val_loss: 42.0644\n",
            "Epoch 1935/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 41.3063 - val_loss: 41.9083\n",
            "Epoch 1936/6000\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 41.2959 - val_loss: 42.1453\n",
            "Epoch 1937/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 41.3959 - val_loss: 42.1745\n",
            "Epoch 1938/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 41.2252 - val_loss: 42.0807\n",
            "Epoch 1939/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 41.3018 - val_loss: 41.9856\n",
            "Epoch 1940/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 41.2838 - val_loss: 42.0055\n",
            "Epoch 1941/6000\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 41.4677 - val_loss: 41.8086\n",
            "Epoch 1942/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 41.2459 - val_loss: 41.8161\n",
            "Epoch 1943/6000\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 41.3212 - val_loss: 42.0093\n",
            "Epoch 1944/6000\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 41.2331 - val_loss: 41.9661\n",
            "Epoch 1945/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 41.2733 - val_loss: 41.8703\n",
            "Epoch 1946/6000\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 41.1260 - val_loss: 41.9590\n",
            "Epoch 1947/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 41.0468 - val_loss: 41.9078\n",
            "Epoch 1948/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 41.1196 - val_loss: 41.8222\n",
            "Epoch 1949/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 41.0272 - val_loss: 41.8308\n",
            "Epoch 1950/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 41.0313 - val_loss: 41.9046\n",
            "Epoch 1951/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 40.9240 - val_loss: 41.8366\n",
            "Epoch 1952/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 40.9349 - val_loss: 42.0056\n",
            "Epoch 1953/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 41.0791 - val_loss: 42.0256\n",
            "Epoch 1954/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 40.8477 - val_loss: 41.8229\n",
            "Epoch 1955/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 40.7869 - val_loss: 41.7106\n",
            "Epoch 1956/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 40.8635 - val_loss: 41.6585\n",
            "Epoch 1957/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 40.8528 - val_loss: 41.9913\n",
            "Epoch 1958/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 40.8057 - val_loss: 41.8330\n",
            "Epoch 1959/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 40.8641 - val_loss: 41.9279\n",
            "Epoch 1960/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 40.8598 - val_loss: 42.1138\n",
            "Epoch 1961/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 40.7630 - val_loss: 41.8988\n",
            "Epoch 1962/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 40.6786 - val_loss: 41.6747\n",
            "Epoch 1963/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 40.7681 - val_loss: 41.6712\n",
            "Epoch 1964/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 40.7946 - val_loss: 41.7085\n",
            "Epoch 1965/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 40.7229 - val_loss: 41.9129\n",
            "Epoch 1966/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 40.6256 - val_loss: 41.5464\n",
            "Epoch 1967/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 40.4975 - val_loss: 41.7750\n",
            "Epoch 1968/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 40.4974 - val_loss: 41.6645\n",
            "Epoch 1969/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 40.4770 - val_loss: 41.7207\n",
            "Epoch 1970/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 40.4901 - val_loss: 41.5558\n",
            "Epoch 1971/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 40.4616 - val_loss: 41.7111\n",
            "Epoch 1972/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 40.4561 - val_loss: 41.2785\n",
            "Epoch 1973/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 40.5037 - val_loss: 41.5897\n",
            "Epoch 1974/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 40.5243 - val_loss: 41.7391\n",
            "Epoch 1975/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 40.4406 - val_loss: 41.3747\n",
            "Epoch 1976/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 40.4107 - val_loss: 41.5316\n",
            "Epoch 1977/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 40.3610 - val_loss: 41.7660\n",
            "Epoch 1978/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 40.2938 - val_loss: 41.1743\n",
            "Epoch 1979/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 40.3841 - val_loss: 41.6095\n",
            "Epoch 1980/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 40.3891 - val_loss: 41.7078\n",
            "Epoch 1981/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 40.3958 - val_loss: 41.4251\n",
            "Epoch 1982/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 40.3210 - val_loss: 41.4931\n",
            "Epoch 1983/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 40.2117 - val_loss: 41.6095\n",
            "Epoch 1984/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 40.4124 - val_loss: 41.3387\n",
            "Epoch 1985/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 40.2785 - val_loss: 41.9041\n",
            "Epoch 1986/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 40.2103 - val_loss: 41.6514\n",
            "Epoch 1987/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 40.2920 - val_loss: 41.4579\n",
            "Epoch 1988/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 40.1943 - val_loss: 41.6088\n",
            "Epoch 1989/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 40.0753 - val_loss: 41.5794\n",
            "Epoch 1990/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 39.9939 - val_loss: 41.2929\n",
            "Epoch 1991/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 40.0244 - val_loss: 41.5854\n",
            "Epoch 1992/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 40.0873 - val_loss: 41.7266\n",
            "Epoch 1993/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 39.9431 - val_loss: 41.2454\n",
            "Epoch 1994/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 40.0020 - val_loss: 41.5757\n",
            "Epoch 1995/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 39.9109 - val_loss: 41.3448\n",
            "Epoch 1996/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 39.8613 - val_loss: 41.4884\n",
            "Epoch 1997/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 39.8397 - val_loss: 41.3332\n",
            "Epoch 1998/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 39.8288 - val_loss: 41.3962\n",
            "Epoch 1999/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 39.7640 - val_loss: 41.5759\n",
            "Epoch 2000/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 39.7711 - val_loss: 41.5974\n",
            "Epoch 2001/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 39.8373 - val_loss: 41.2035\n",
            "Epoch 2002/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 39.6487 - val_loss: 40.9365\n",
            "Epoch 2003/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 39.7778 - val_loss: 41.3791\n",
            "Epoch 2004/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 39.7431 - val_loss: 41.2753\n",
            "Epoch 2005/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 39.7117 - val_loss: 41.5595\n",
            "Epoch 2006/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 39.6775 - val_loss: 41.2063\n",
            "Epoch 2007/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 39.7616 - val_loss: 41.2952\n",
            "Epoch 2008/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 39.7456 - val_loss: 41.3100\n",
            "Epoch 2009/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 39.7589 - val_loss: 41.3336\n",
            "Epoch 2010/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 39.5999 - val_loss: 41.1177\n",
            "Epoch 2011/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 39.6042 - val_loss: 41.1101\n",
            "Epoch 2012/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 39.6764 - val_loss: 40.5141\n",
            "Epoch 2013/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 39.6159 - val_loss: 41.3174\n",
            "Epoch 2014/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 39.4838 - val_loss: 41.0647\n",
            "Epoch 2015/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 39.4285 - val_loss: 41.0423\n",
            "Epoch 2016/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 39.4816 - val_loss: 40.7442\n",
            "Epoch 2017/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 39.5621 - val_loss: 41.4098\n",
            "Epoch 2018/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 39.3950 - val_loss: 40.9084\n",
            "Epoch 2019/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 39.4414 - val_loss: 41.0286\n",
            "Epoch 2020/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 39.3989 - val_loss: 40.6803\n",
            "Epoch 2021/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 39.3466 - val_loss: 40.8318\n",
            "Epoch 2022/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 39.2672 - val_loss: 40.5959\n",
            "Epoch 2023/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 39.1885 - val_loss: 40.6808\n",
            "Epoch 2024/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 39.2620 - val_loss: 40.5646\n",
            "Epoch 2025/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 39.2358 - val_loss: 40.5761\n",
            "Epoch 2026/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 39.3072 - val_loss: 40.6242\n",
            "Epoch 2027/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 39.2561 - val_loss: 40.6595\n",
            "Epoch 2028/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 39.1965 - val_loss: 40.5386\n",
            "Epoch 2029/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 39.0926 - val_loss: 40.6244\n",
            "Epoch 2030/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 39.1473 - val_loss: 40.4139\n",
            "Epoch 2031/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 39.1849 - val_loss: 40.5641\n",
            "Epoch 2032/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 39.0388 - val_loss: 40.1057\n",
            "Epoch 2033/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 39.0652 - val_loss: 40.4538\n",
            "Epoch 2034/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 39.1429 - val_loss: 40.4151\n",
            "Epoch 2035/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 39.0680 - val_loss: 40.1132\n",
            "Epoch 2036/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 39.2682 - val_loss: 40.7575\n",
            "Epoch 2037/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 39.0138 - val_loss: 40.6124\n",
            "Epoch 2038/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 39.0356 - val_loss: 40.4074\n",
            "Epoch 2039/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 38.9331 - val_loss: 40.5237\n",
            "Epoch 2040/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 39.0914 - val_loss: 40.4441\n",
            "Epoch 2041/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 38.9439 - val_loss: 40.2624\n",
            "Epoch 2042/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 38.8129 - val_loss: 40.3853\n",
            "Epoch 2043/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 38.9140 - val_loss: 40.3058\n",
            "Epoch 2044/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 38.8486 - val_loss: 39.9391\n",
            "Epoch 2045/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 38.8649 - val_loss: 40.5634\n",
            "Epoch 2046/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 38.7859 - val_loss: 40.1484\n",
            "Epoch 2047/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 38.8424 - val_loss: 40.1784\n",
            "Epoch 2048/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 38.7546 - val_loss: 40.1500\n",
            "Epoch 2049/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 38.8358 - val_loss: 40.2801\n",
            "Epoch 2050/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 38.7716 - val_loss: 40.1368\n",
            "Epoch 2051/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 38.6672 - val_loss: 40.3058\n",
            "Epoch 2052/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 38.6047 - val_loss: 40.0333\n",
            "Epoch 2053/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 38.6111 - val_loss: 40.2625\n",
            "Epoch 2054/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 38.5679 - val_loss: 39.9872\n",
            "Epoch 2055/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 38.6104 - val_loss: 40.5328\n",
            "Epoch 2056/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 38.7447 - val_loss: 39.7895\n",
            "Epoch 2057/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 38.7379 - val_loss: 40.8511\n",
            "Epoch 2058/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 38.8976 - val_loss: 39.8948\n",
            "Epoch 2059/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 38.6961 - val_loss: 40.3351\n",
            "Epoch 2060/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 38.6635 - val_loss: 39.9923\n",
            "Epoch 2061/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 38.5895 - val_loss: 40.1898\n",
            "Epoch 2062/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 38.6506 - val_loss: 39.9041\n",
            "Epoch 2063/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 38.5104 - val_loss: 39.6564\n",
            "Epoch 2064/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 38.6466 - val_loss: 40.3715\n",
            "Epoch 2065/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 38.5141 - val_loss: 39.8016\n",
            "Epoch 2066/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 38.4634 - val_loss: 39.9834\n",
            "Epoch 2067/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 38.4246 - val_loss: 39.7649\n",
            "Epoch 2068/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 38.2980 - val_loss: 39.6843\n",
            "Epoch 2069/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 38.4108 - val_loss: 39.6668\n",
            "Epoch 2070/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 38.3565 - val_loss: 39.4970\n",
            "Epoch 2071/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 38.3566 - val_loss: 39.4773\n",
            "Epoch 2072/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 38.3735 - val_loss: 39.9281\n",
            "Epoch 2073/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 38.3160 - val_loss: 39.4406\n",
            "Epoch 2074/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 38.4013 - val_loss: 39.1042\n",
            "Epoch 2075/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 38.2100 - val_loss: 39.2919\n",
            "Epoch 2076/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 38.1634 - val_loss: 39.0173\n",
            "Epoch 2077/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 38.2094 - val_loss: 39.3829\n",
            "Epoch 2078/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 38.1787 - val_loss: 39.0850\n",
            "Epoch 2079/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 38.1858 - val_loss: 39.3523\n",
            "Epoch 2080/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 38.4956 - val_loss: 39.1097\n",
            "Epoch 2081/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 38.1731 - val_loss: 39.2579\n",
            "Epoch 2082/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 38.1495 - val_loss: 38.6961\n",
            "Epoch 2083/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 38.0334 - val_loss: 38.9165\n",
            "Epoch 2084/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 38.1259 - val_loss: 38.6469\n",
            "Epoch 2085/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 38.0195 - val_loss: 38.7243\n",
            "Epoch 2086/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 38.0406 - val_loss: 38.5821\n",
            "Epoch 2087/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 37.9343 - val_loss: 38.9751\n",
            "Epoch 2088/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 37.9925 - val_loss: 38.6352\n",
            "Epoch 2089/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 37.9513 - val_loss: 38.5548\n",
            "Epoch 2090/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 37.9377 - val_loss: 39.0331\n",
            "Epoch 2091/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 38.1073 - val_loss: 38.6128\n",
            "Epoch 2092/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 38.0395 - val_loss: 38.4017\n",
            "Epoch 2093/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 37.8694 - val_loss: 38.5809\n",
            "Epoch 2094/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 37.9554 - val_loss: 38.7610\n",
            "Epoch 2095/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 37.8797 - val_loss: 38.4123\n",
            "Epoch 2096/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 37.8677 - val_loss: 38.9375\n",
            "Epoch 2097/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 37.8792 - val_loss: 38.3050\n",
            "Epoch 2098/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 37.7967 - val_loss: 38.3654\n",
            "Epoch 2099/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 37.8498 - val_loss: 38.4218\n",
            "Epoch 2100/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 37.7698 - val_loss: 38.2915\n",
            "Epoch 2101/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 37.7492 - val_loss: 38.5308\n",
            "Epoch 2102/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 37.8171 - val_loss: 38.2855\n",
            "Epoch 2103/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 37.7745 - val_loss: 38.6878\n",
            "Epoch 2104/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 37.6530 - val_loss: 38.1859\n",
            "Epoch 2105/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 37.6741 - val_loss: 38.2539\n",
            "Epoch 2106/6000\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 37.8444 - val_loss: 37.9379\n",
            "Epoch 2107/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 37.6279 - val_loss: 38.2071\n",
            "Epoch 2108/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 37.6290 - val_loss: 38.1989\n",
            "Epoch 2109/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 37.6882 - val_loss: 38.2037\n",
            "Epoch 2110/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 37.6052 - val_loss: 38.1647\n",
            "Epoch 2111/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 37.5589 - val_loss: 38.1300\n",
            "Epoch 2112/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 37.4656 - val_loss: 38.0013\n",
            "Epoch 2113/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 37.5650 - val_loss: 38.1346\n",
            "Epoch 2114/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 37.4846 - val_loss: 38.1965\n",
            "Epoch 2115/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 37.5789 - val_loss: 37.8151\n",
            "Epoch 2116/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 37.5652 - val_loss: 38.1055\n",
            "Epoch 2117/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 37.4292 - val_loss: 37.9179\n",
            "Epoch 2118/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 37.3883 - val_loss: 37.9031\n",
            "Epoch 2119/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 37.3975 - val_loss: 38.0501\n",
            "Epoch 2120/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 37.3632 - val_loss: 37.9497\n",
            "Epoch 2121/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 37.3874 - val_loss: 37.9879\n",
            "Epoch 2122/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 37.3520 - val_loss: 38.0640\n",
            "Epoch 2123/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 37.2827 - val_loss: 37.6870\n",
            "Epoch 2124/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 37.2552 - val_loss: 37.9152\n",
            "Epoch 2125/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 37.3153 - val_loss: 37.6716\n",
            "Epoch 2126/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 37.3054 - val_loss: 37.9618\n",
            "Epoch 2127/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 37.2742 - val_loss: 37.8613\n",
            "Epoch 2128/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 37.1819 - val_loss: 37.5019\n",
            "Epoch 2129/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 37.3468 - val_loss: 37.9177\n",
            "Epoch 2130/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 37.3144 - val_loss: 37.6578\n",
            "Epoch 2131/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 37.4159 - val_loss: 37.4947\n",
            "Epoch 2132/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 37.3666 - val_loss: 37.5974\n",
            "Epoch 2133/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 37.2536 - val_loss: 37.5293\n",
            "Epoch 2134/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 37.1698 - val_loss: 37.7262\n",
            "Epoch 2135/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 37.2741 - val_loss: 37.5439\n",
            "Epoch 2136/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 37.1585 - val_loss: 37.8308\n",
            "Epoch 2137/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 37.2251 - val_loss: 37.4498\n",
            "Epoch 2138/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 37.1902 - val_loss: 37.7630\n",
            "Epoch 2139/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 37.1390 - val_loss: 37.4692\n",
            "Epoch 2140/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 37.0563 - val_loss: 37.5153\n",
            "Epoch 2141/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 36.9882 - val_loss: 37.1640\n",
            "Epoch 2142/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 37.1831 - val_loss: 37.4660\n",
            "Epoch 2143/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 36.9890 - val_loss: 37.5594\n",
            "Epoch 2144/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 37.0487 - val_loss: 37.3193\n",
            "Epoch 2145/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 37.0101 - val_loss: 37.4495\n",
            "Epoch 2146/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 36.9750 - val_loss: 37.1721\n",
            "Epoch 2147/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 36.8859 - val_loss: 37.2202\n",
            "Epoch 2148/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 36.7995 - val_loss: 37.1192\n",
            "Epoch 2149/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 36.8882 - val_loss: 37.2008\n",
            "Epoch 2150/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 36.7945 - val_loss: 37.3944\n",
            "Epoch 2151/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 36.7824 - val_loss: 37.1711\n",
            "Epoch 2152/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 36.7379 - val_loss: 37.2764\n",
            "Epoch 2153/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 36.8737 - val_loss: 37.0246\n",
            "Epoch 2154/6000\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 36.8289 - val_loss: 37.1861\n",
            "Epoch 2155/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 36.7354 - val_loss: 37.2683\n",
            "Epoch 2156/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 36.6773 - val_loss: 36.9479\n",
            "Epoch 2157/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 36.7450 - val_loss: 37.1323\n",
            "Epoch 2158/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 36.6898 - val_loss: 36.8240\n",
            "Epoch 2159/6000\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 36.7455 - val_loss: 37.0798\n",
            "Epoch 2160/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 36.6490 - val_loss: 37.2547\n",
            "Epoch 2161/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 36.6360 - val_loss: 36.7812\n",
            "Epoch 2162/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 36.7746 - val_loss: 37.0786\n",
            "Epoch 2163/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 36.6791 - val_loss: 37.0159\n",
            "Epoch 2164/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 36.7457 - val_loss: 36.8387\n",
            "Epoch 2165/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 36.6737 - val_loss: 37.2138\n",
            "Epoch 2166/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 36.7037 - val_loss: 36.7798\n",
            "Epoch 2167/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 36.5585 - val_loss: 36.9018\n",
            "Epoch 2168/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 36.6461 - val_loss: 36.9153\n",
            "Epoch 2169/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 36.5777 - val_loss: 36.9701\n",
            "Epoch 2170/6000\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 36.5068 - val_loss: 36.9702\n",
            "Epoch 2171/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 36.5220 - val_loss: 36.5498\n",
            "Epoch 2172/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 36.4879 - val_loss: 36.7554\n",
            "Epoch 2173/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 36.5961 - val_loss: 36.6977\n",
            "Epoch 2174/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 36.4850 - val_loss: 36.9278\n",
            "Epoch 2175/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 36.4052 - val_loss: 36.7704\n",
            "Epoch 2176/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 36.3439 - val_loss: 36.8358\n",
            "Epoch 2177/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 36.4723 - val_loss: 36.7001\n",
            "Epoch 2178/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 36.4041 - val_loss: 37.1270\n",
            "Epoch 2179/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 36.3740 - val_loss: 37.2316\n",
            "Epoch 2180/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 36.2472 - val_loss: 36.7440\n",
            "Epoch 2181/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 36.3304 - val_loss: 36.7853\n",
            "Epoch 2182/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 36.2442 - val_loss: 36.6555\n",
            "Epoch 2183/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 36.2884 - val_loss: 36.8114\n",
            "Epoch 2184/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 36.2105 - val_loss: 36.7367\n",
            "Epoch 2185/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 36.2482 - val_loss: 36.5007\n",
            "Epoch 2186/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 36.3433 - val_loss: 36.7263\n",
            "Epoch 2187/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 36.2029 - val_loss: 36.9702\n",
            "Epoch 2188/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 36.2818 - val_loss: 36.7879\n",
            "Epoch 2189/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 36.1135 - val_loss: 36.5581\n",
            "Epoch 2190/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 36.2199 - val_loss: 36.5700\n",
            "Epoch 2191/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 36.2870 - val_loss: 36.4169\n",
            "Epoch 2192/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 36.1512 - val_loss: 36.8553\n",
            "Epoch 2193/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 36.2219 - val_loss: 36.5044\n",
            "Epoch 2194/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 36.2874 - val_loss: 36.3259\n",
            "Epoch 2195/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 36.1150 - val_loss: 36.7294\n",
            "Epoch 2196/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 36.0369 - val_loss: 36.4260\n",
            "Epoch 2197/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 36.1708 - val_loss: 36.6614\n",
            "Epoch 2198/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 36.1850 - val_loss: 36.3804\n",
            "Epoch 2199/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 35.9926 - val_loss: 36.7235\n",
            "Epoch 2200/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 36.0079 - val_loss: 36.3298\n",
            "Epoch 2201/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 35.8833 - val_loss: 36.4805\n",
            "Epoch 2202/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 35.9650 - val_loss: 36.3721\n",
            "Epoch 2203/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 36.0179 - val_loss: 36.2787\n",
            "Epoch 2204/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 35.9531 - val_loss: 36.2457\n",
            "Epoch 2205/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 35.9044 - val_loss: 36.1937\n",
            "Epoch 2206/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 35.8577 - val_loss: 36.2939\n",
            "Epoch 2207/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 35.8141 - val_loss: 36.2395\n",
            "Epoch 2208/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 35.9353 - val_loss: 36.1662\n",
            "Epoch 2209/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 35.8685 - val_loss: 36.6596\n",
            "Epoch 2210/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 35.9447 - val_loss: 36.2398\n",
            "Epoch 2211/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 35.8141 - val_loss: 36.1823\n",
            "Epoch 2212/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 35.8136 - val_loss: 36.3157\n",
            "Epoch 2213/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 35.7506 - val_loss: 36.3302\n",
            "Epoch 2214/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 35.8995 - val_loss: 36.3354\n",
            "Epoch 2215/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 35.7274 - val_loss: 36.5033\n",
            "Epoch 2216/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 35.9122 - val_loss: 36.2615\n",
            "Epoch 2217/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 35.6621 - val_loss: 36.1365\n",
            "Epoch 2218/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 35.7400 - val_loss: 36.2996\n",
            "Epoch 2219/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 35.7629 - val_loss: 36.2184\n",
            "Epoch 2220/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 35.6820 - val_loss: 36.2936\n",
            "Epoch 2221/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 35.7273 - val_loss: 36.4433\n",
            "Epoch 2222/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 35.6552 - val_loss: 36.0790\n",
            "Epoch 2223/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 35.6386 - val_loss: 36.4837\n",
            "Epoch 2224/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 35.5340 - val_loss: 36.2874\n",
            "Epoch 2225/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 35.5649 - val_loss: 35.9242\n",
            "Epoch 2226/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 35.4942 - val_loss: 36.1677\n",
            "Epoch 2227/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 35.4503 - val_loss: 36.2104\n",
            "Epoch 2228/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 35.4381 - val_loss: 35.9187\n",
            "Epoch 2229/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 35.4614 - val_loss: 35.9100\n",
            "Epoch 2230/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 35.6840 - val_loss: 36.2437\n",
            "Epoch 2231/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 35.5056 - val_loss: 36.0472\n",
            "Epoch 2232/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 35.6253 - val_loss: 36.3646\n",
            "Epoch 2233/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 35.4707 - val_loss: 36.2326\n",
            "Epoch 2234/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 35.3754 - val_loss: 35.9207\n",
            "Epoch 2235/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 35.4810 - val_loss: 35.8928\n",
            "Epoch 2236/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 35.3639 - val_loss: 35.9654\n",
            "Epoch 2237/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 35.2966 - val_loss: 36.0784\n",
            "Epoch 2238/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 35.3257 - val_loss: 36.0813\n",
            "Epoch 2239/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 35.2338 - val_loss: 35.9646\n",
            "Epoch 2240/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 35.2696 - val_loss: 35.7605\n",
            "Epoch 2241/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 35.2296 - val_loss: 35.7663\n",
            "Epoch 2242/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 35.2231 - val_loss: 35.6436\n",
            "Epoch 2243/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 35.2298 - val_loss: 35.7384\n",
            "Epoch 2244/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 35.1866 - val_loss: 35.8174\n",
            "Epoch 2245/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 35.2373 - val_loss: 35.7557\n",
            "Epoch 2246/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 35.3096 - val_loss: 35.6541\n",
            "Epoch 2247/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 35.2358 - val_loss: 35.7581\n",
            "Epoch 2248/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 35.1307 - val_loss: 35.7286\n",
            "Epoch 2249/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 35.0755 - val_loss: 35.5212\n",
            "Epoch 2250/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 35.0889 - val_loss: 35.6129\n",
            "Epoch 2251/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 35.2142 - val_loss: 35.5133\n",
            "Epoch 2252/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 35.1172 - val_loss: 35.8109\n",
            "Epoch 2253/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 35.2024 - val_loss: 35.8070\n",
            "Epoch 2254/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 35.1411 - val_loss: 35.6538\n",
            "Epoch 2255/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 35.0585 - val_loss: 35.8399\n",
            "Epoch 2256/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 34.9700 - val_loss: 35.5249\n",
            "Epoch 2257/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 34.9715 - val_loss: 35.4543\n",
            "Epoch 2258/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 34.9164 - val_loss: 35.4808\n",
            "Epoch 2259/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 34.9699 - val_loss: 35.5909\n",
            "Epoch 2260/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 35.0722 - val_loss: 35.6799\n",
            "Epoch 2261/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 35.1610 - val_loss: 35.3129\n",
            "Epoch 2262/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 35.0082 - val_loss: 35.4625\n",
            "Epoch 2263/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 34.8697 - val_loss: 35.4968\n",
            "Epoch 2264/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 34.8911 - val_loss: 35.3619\n",
            "Epoch 2265/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 34.8054 - val_loss: 35.4500\n",
            "Epoch 2266/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 34.8239 - val_loss: 35.5487\n",
            "Epoch 2267/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 34.8544 - val_loss: 35.0724\n",
            "Epoch 2268/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 34.9852 - val_loss: 35.8090\n",
            "Epoch 2269/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 34.8978 - val_loss: 35.2326\n",
            "Epoch 2270/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 34.8093 - val_loss: 35.3415\n",
            "Epoch 2271/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 34.7348 - val_loss: 35.3638\n",
            "Epoch 2272/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 34.7365 - val_loss: 35.6730\n",
            "Epoch 2273/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 34.7457 - val_loss: 35.2977\n",
            "Epoch 2274/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 34.9776 - val_loss: 35.9716\n",
            "Epoch 2275/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 34.8239 - val_loss: 35.2599\n",
            "Epoch 2276/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 34.7267 - val_loss: 35.2422\n",
            "Epoch 2277/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 34.7393 - val_loss: 35.3094\n",
            "Epoch 2278/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 34.6937 - val_loss: 35.4177\n",
            "Epoch 2279/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 34.6726 - val_loss: 35.2541\n",
            "Epoch 2280/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 34.6019 - val_loss: 35.1848\n",
            "Epoch 2281/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 34.5453 - val_loss: 35.4381\n",
            "Epoch 2282/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 34.5687 - val_loss: 35.1599\n",
            "Epoch 2283/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 34.5838 - val_loss: 35.2407\n",
            "Epoch 2284/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 34.6465 - val_loss: 35.2426\n",
            "Epoch 2285/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 34.5490 - val_loss: 35.1670\n",
            "Epoch 2286/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 34.5893 - val_loss: 35.1648\n",
            "Epoch 2287/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 34.4583 - val_loss: 35.0360\n",
            "Epoch 2288/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 34.3918 - val_loss: 34.9033\n",
            "Epoch 2289/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 34.4899 - val_loss: 34.7174\n",
            "Epoch 2290/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 34.4616 - val_loss: 35.0315\n",
            "Epoch 2291/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 34.5598 - val_loss: 34.8414\n",
            "Epoch 2292/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 34.5085 - val_loss: 34.8383\n",
            "Epoch 2293/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 34.5819 - val_loss: 34.6928\n",
            "Epoch 2294/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 34.5151 - val_loss: 34.9632\n",
            "Epoch 2295/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 34.4156 - val_loss: 34.9949\n",
            "Epoch 2296/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 34.6792 - val_loss: 34.9170\n",
            "Epoch 2297/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 34.3995 - val_loss: 34.6182\n",
            "Epoch 2298/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 34.4432 - val_loss: 34.8800\n",
            "Epoch 2299/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 34.2766 - val_loss: 34.7403\n",
            "Epoch 2300/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 34.2954 - val_loss: 34.8274\n",
            "Epoch 2301/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 34.2136 - val_loss: 34.7910\n",
            "Epoch 2302/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 34.2018 - val_loss: 34.8600\n",
            "Epoch 2303/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 34.1715 - val_loss: 34.6602\n",
            "Epoch 2304/6000\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 34.2039 - val_loss: 34.7221\n",
            "Epoch 2305/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 34.2930 - val_loss: 34.7333\n",
            "Epoch 2306/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 34.1850 - val_loss: 34.9568\n",
            "Epoch 2307/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 34.1388 - val_loss: 34.7451\n",
            "Epoch 2308/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 34.1485 - val_loss: 34.7687\n",
            "Epoch 2309/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 34.2141 - val_loss: 34.5291\n",
            "Epoch 2310/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 34.2285 - val_loss: 34.9291\n",
            "Epoch 2311/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 34.1558 - val_loss: 34.6720\n",
            "Epoch 2312/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 34.0498 - val_loss: 34.8568\n",
            "Epoch 2313/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 34.1421 - val_loss: 34.6710\n",
            "Epoch 2314/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 34.0721 - val_loss: 34.7224\n",
            "Epoch 2315/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 34.0812 - val_loss: 34.4638\n",
            "Epoch 2316/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 34.0586 - val_loss: 34.5224\n",
            "Epoch 2317/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 34.1402 - val_loss: 34.8379\n",
            "Epoch 2318/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 34.1164 - val_loss: 34.7083\n",
            "Epoch 2319/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 33.9707 - val_loss: 34.6519\n",
            "Epoch 2320/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 34.2614 - val_loss: 34.6229\n",
            "Epoch 2321/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 33.9540 - val_loss: 34.3948\n",
            "Epoch 2322/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 34.0376 - val_loss: 34.7421\n",
            "Epoch 2323/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 34.0384 - val_loss: 34.6035\n",
            "Epoch 2324/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 34.0623 - val_loss: 34.5042\n",
            "Epoch 2325/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 33.8811 - val_loss: 34.7604\n",
            "Epoch 2326/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 33.9219 - val_loss: 34.6293\n",
            "Epoch 2327/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 33.8694 - val_loss: 34.3444\n",
            "Epoch 2328/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 33.8082 - val_loss: 34.4721\n",
            "Epoch 2329/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 33.8125 - val_loss: 34.3166\n",
            "Epoch 2330/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 33.9575 - val_loss: 34.5081\n",
            "Epoch 2331/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 33.9028 - val_loss: 34.2771\n",
            "Epoch 2332/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 33.7674 - val_loss: 34.3826\n",
            "Epoch 2333/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 33.9433 - val_loss: 34.4098\n",
            "Epoch 2334/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 33.9234 - val_loss: 34.3111\n",
            "Epoch 2335/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 33.7205 - val_loss: 34.4189\n",
            "Epoch 2336/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 33.7717 - val_loss: 34.3906\n",
            "Epoch 2337/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 33.7721 - val_loss: 34.2532\n",
            "Epoch 2338/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 33.6821 - val_loss: 34.1807\n",
            "Epoch 2339/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 33.6896 - val_loss: 34.2754\n",
            "Epoch 2340/6000\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 33.8487 - val_loss: 34.2736\n",
            "Epoch 2341/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 33.5943 - val_loss: 33.9980\n",
            "Epoch 2342/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 33.5411 - val_loss: 34.0191\n",
            "Epoch 2343/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 33.5681 - val_loss: 33.9721\n",
            "Epoch 2344/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 33.7515 - val_loss: 33.9270\n",
            "Epoch 2345/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 33.5857 - val_loss: 33.9004\n",
            "Epoch 2346/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 33.5961 - val_loss: 34.1831\n",
            "Epoch 2347/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 33.6862 - val_loss: 33.8831\n",
            "Epoch 2348/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 33.5403 - val_loss: 33.9917\n",
            "Epoch 2349/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 33.5090 - val_loss: 33.8954\n",
            "Epoch 2350/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 33.6129 - val_loss: 33.8682\n",
            "Epoch 2351/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 33.5941 - val_loss: 34.1016\n",
            "Epoch 2352/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 33.5628 - val_loss: 34.0772\n",
            "Epoch 2353/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 33.4378 - val_loss: 34.0624\n",
            "Epoch 2354/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 33.4628 - val_loss: 33.9802\n",
            "Epoch 2355/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 33.4335 - val_loss: 33.7699\n",
            "Epoch 2356/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 33.3560 - val_loss: 33.7949\n",
            "Epoch 2357/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 33.3549 - val_loss: 33.6694\n",
            "Epoch 2358/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 33.3495 - val_loss: 33.8073\n",
            "Epoch 2359/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 33.3546 - val_loss: 33.8905\n",
            "Epoch 2360/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 33.3191 - val_loss: 33.7765\n",
            "Epoch 2361/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 33.3798 - val_loss: 33.6406\n",
            "Epoch 2362/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 33.2139 - val_loss: 33.7086\n",
            "Epoch 2363/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 33.2320 - val_loss: 33.6393\n",
            "Epoch 2364/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 33.3064 - val_loss: 33.6553\n",
            "Epoch 2365/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 33.4871 - val_loss: 34.2005\n",
            "Epoch 2366/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 33.4956 - val_loss: 33.7535\n",
            "Epoch 2367/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 33.2890 - val_loss: 33.6935\n",
            "Epoch 2368/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 33.4044 - val_loss: 33.5744\n",
            "Epoch 2369/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 33.2381 - val_loss: 33.8926\n",
            "Epoch 2370/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 33.2090 - val_loss: 34.0622\n",
            "Epoch 2371/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 33.1637 - val_loss: 33.9515\n",
            "Epoch 2372/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 33.2184 - val_loss: 33.8768\n",
            "Epoch 2373/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 33.1085 - val_loss: 33.6354\n",
            "Epoch 2374/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 33.3695 - val_loss: 33.8465\n",
            "Epoch 2375/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 33.0699 - val_loss: 33.8345\n",
            "Epoch 2376/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 33.2147 - val_loss: 33.6925\n",
            "Epoch 2377/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 33.2631 - val_loss: 34.0877\n",
            "Epoch 2378/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 33.1823 - val_loss: 33.7047\n",
            "Epoch 2379/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 33.0280 - val_loss: 33.8713\n",
            "Epoch 2380/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 33.1172 - val_loss: 34.2113\n",
            "Epoch 2381/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 33.0883 - val_loss: 33.8795\n",
            "Epoch 2382/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 33.2649 - val_loss: 33.7713\n",
            "Epoch 2383/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 33.1480 - val_loss: 33.5480\n",
            "Epoch 2384/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 32.9692 - val_loss: 33.3287\n",
            "Epoch 2385/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 32.9822 - val_loss: 33.6416\n",
            "Epoch 2386/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 32.9670 - val_loss: 33.5666\n",
            "Epoch 2387/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 32.8661 - val_loss: 33.5626\n",
            "Epoch 2388/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 33.0638 - val_loss: 33.4833\n",
            "Epoch 2389/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 32.9777 - val_loss: 33.4686\n",
            "Epoch 2390/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 32.9215 - val_loss: 33.9595\n",
            "Epoch 2391/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 32.8433 - val_loss: 33.4460\n",
            "Epoch 2392/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 33.1448 - val_loss: 33.1741\n",
            "Epoch 2393/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 33.0636 - val_loss: 33.7457\n",
            "Epoch 2394/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 32.9093 - val_loss: 33.7256\n",
            "Epoch 2395/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 32.9302 - val_loss: 33.3762\n",
            "Epoch 2396/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 32.7539 - val_loss: 33.3679\n",
            "Epoch 2397/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 32.6845 - val_loss: 33.5315\n",
            "Epoch 2398/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 32.7220 - val_loss: 33.2798\n",
            "Epoch 2399/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 32.7080 - val_loss: 33.4702\n",
            "Epoch 2400/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 32.8268 - val_loss: 33.4642\n",
            "Epoch 2401/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 32.8564 - val_loss: 33.5654\n",
            "Epoch 2402/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 32.7193 - val_loss: 33.5116\n",
            "Epoch 2403/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 32.6293 - val_loss: 33.2464\n",
            "Epoch 2404/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 32.6705 - val_loss: 33.2431\n",
            "Epoch 2405/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 32.5936 - val_loss: 33.3774\n",
            "Epoch 2406/6000\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 32.6302 - val_loss: 33.2925\n",
            "Epoch 2407/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 32.6018 - val_loss: 33.3040\n",
            "Epoch 2408/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 32.4911 - val_loss: 33.2031\n",
            "Epoch 2409/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 32.5434 - val_loss: 33.1287\n",
            "Epoch 2410/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 32.4587 - val_loss: 33.0227\n",
            "Epoch 2411/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 32.5880 - val_loss: 33.0902\n",
            "Epoch 2412/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 32.6500 - val_loss: 33.1451\n",
            "Epoch 2413/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 32.5043 - val_loss: 33.2603\n",
            "Epoch 2414/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 32.5031 - val_loss: 32.9444\n",
            "Epoch 2415/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 32.6076 - val_loss: 33.3421\n",
            "Epoch 2416/6000\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 32.6455 - val_loss: 33.2333\n",
            "Epoch 2417/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 32.6163 - val_loss: 33.1283\n",
            "Epoch 2418/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 32.5461 - val_loss: 33.0272\n",
            "Epoch 2419/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 32.4503 - val_loss: 33.0008\n",
            "Epoch 2420/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 32.4515 - val_loss: 33.1435\n",
            "Epoch 2421/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 32.4222 - val_loss: 33.2371\n",
            "Epoch 2422/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 32.3394 - val_loss: 33.0814\n",
            "Epoch 2423/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 32.3968 - val_loss: 33.0634\n",
            "Epoch 2424/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 32.6585 - val_loss: 32.7629\n",
            "Epoch 2425/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 32.3636 - val_loss: 33.0521\n",
            "Epoch 2426/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 32.6512 - val_loss: 33.1101\n",
            "Epoch 2427/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 32.3206 - val_loss: 33.0529\n",
            "Epoch 2428/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 32.4819 - val_loss: 32.7809\n",
            "Epoch 2429/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 32.2349 - val_loss: 32.7486\n",
            "Epoch 2430/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 32.1793 - val_loss: 32.9072\n",
            "Epoch 2431/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 32.3272 - val_loss: 32.8678\n",
            "Epoch 2432/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 32.3518 - val_loss: 32.7144\n",
            "Epoch 2433/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 32.2944 - val_loss: 32.4881\n",
            "Epoch 2434/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 32.2250 - val_loss: 32.7612\n",
            "Epoch 2435/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 32.2413 - val_loss: 32.7515\n",
            "Epoch 2436/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 32.1344 - val_loss: 32.7606\n",
            "Epoch 2437/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 32.3228 - val_loss: 32.7131\n",
            "Epoch 2438/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 32.1525 - val_loss: 32.7752\n",
            "Epoch 2439/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 32.1118 - val_loss: 32.5233\n",
            "Epoch 2440/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 32.1514 - val_loss: 32.6812\n",
            "Epoch 2441/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 32.1993 - val_loss: 32.5471\n",
            "Epoch 2442/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 32.0908 - val_loss: 32.7553\n",
            "Epoch 2443/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 32.1470 - val_loss: 32.6087\n",
            "Epoch 2444/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 32.2638 - val_loss: 32.6825\n",
            "Epoch 2445/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 32.0114 - val_loss: 32.4895\n",
            "Epoch 2446/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 32.1641 - val_loss: 32.3653\n",
            "Epoch 2447/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 32.1819 - val_loss: 32.5879\n",
            "Epoch 2448/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 32.0494 - val_loss: 32.5685\n",
            "Epoch 2449/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 31.9922 - val_loss: 32.2927\n",
            "Epoch 2450/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 32.0143 - val_loss: 32.4497\n",
            "Epoch 2451/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 32.1542 - val_loss: 32.3929\n",
            "Epoch 2452/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 31.9636 - val_loss: 32.4889\n",
            "Epoch 2453/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 31.9506 - val_loss: 32.3529\n",
            "Epoch 2454/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 31.9887 - val_loss: 32.3733\n",
            "Epoch 2455/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 32.0449 - val_loss: 32.4364\n",
            "Epoch 2456/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 31.9214 - val_loss: 32.8046\n",
            "Epoch 2457/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 31.9192 - val_loss: 32.3550\n",
            "Epoch 2458/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 31.8144 - val_loss: 32.3594\n",
            "Epoch 2459/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 31.7647 - val_loss: 32.2962\n",
            "Epoch 2460/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 31.8157 - val_loss: 32.3142\n",
            "Epoch 2461/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 31.8204 - val_loss: 32.2663\n",
            "Epoch 2462/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 31.7837 - val_loss: 32.3613\n",
            "Epoch 2463/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 31.7495 - val_loss: 32.2769\n",
            "Epoch 2464/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 31.7881 - val_loss: 32.2954\n",
            "Epoch 2465/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 31.6905 - val_loss: 32.2271\n",
            "Epoch 2466/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 31.7344 - val_loss: 32.2939\n",
            "Epoch 2467/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 31.6932 - val_loss: 32.2462\n",
            "Epoch 2468/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 31.7290 - val_loss: 32.1784\n",
            "Epoch 2469/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 31.6536 - val_loss: 32.3407\n",
            "Epoch 2470/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 31.6636 - val_loss: 32.1028\n",
            "Epoch 2471/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 31.5664 - val_loss: 32.0091\n",
            "Epoch 2472/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 31.5772 - val_loss: 31.9285\n",
            "Epoch 2473/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 31.7559 - val_loss: 32.1073\n",
            "Epoch 2474/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 31.6150 - val_loss: 32.4823\n",
            "Epoch 2475/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 31.6149 - val_loss: 32.2364\n",
            "Epoch 2476/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 31.5475 - val_loss: 32.2896\n",
            "Epoch 2477/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 31.7503 - val_loss: 32.4063\n",
            "Epoch 2478/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 31.6299 - val_loss: 32.3133\n",
            "Epoch 2479/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 31.7161 - val_loss: 32.2350\n",
            "Epoch 2480/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 31.6393 - val_loss: 32.2927\n",
            "Epoch 2481/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 31.4994 - val_loss: 32.0366\n",
            "Epoch 2482/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 31.5413 - val_loss: 32.2852\n",
            "Epoch 2483/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 31.6854 - val_loss: 32.1163\n",
            "Epoch 2484/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 31.5427 - val_loss: 32.1627\n",
            "Epoch 2485/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 31.6234 - val_loss: 32.0308\n",
            "Epoch 2486/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 31.4722 - val_loss: 32.0248\n",
            "Epoch 2487/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 31.4626 - val_loss: 32.0537\n",
            "Epoch 2488/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 31.6598 - val_loss: 31.9885\n",
            "Epoch 2489/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 31.5035 - val_loss: 32.1605\n",
            "Epoch 2490/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 31.4131 - val_loss: 31.9552\n",
            "Epoch 2491/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 31.4306 - val_loss: 31.9388\n",
            "Epoch 2492/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 31.6254 - val_loss: 31.8501\n",
            "Epoch 2493/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 31.5674 - val_loss: 31.9303\n",
            "Epoch 2494/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 31.3909 - val_loss: 32.3742\n",
            "Epoch 2495/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 31.3896 - val_loss: 31.9031\n",
            "Epoch 2496/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 31.4563 - val_loss: 32.1208\n",
            "Epoch 2497/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 31.3848 - val_loss: 31.9854\n",
            "Epoch 2498/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 31.2949 - val_loss: 32.0228\n",
            "Epoch 2499/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 31.3409 - val_loss: 31.8471\n",
            "Epoch 2500/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 31.2169 - val_loss: 31.8770\n",
            "Epoch 2501/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 31.3851 - val_loss: 31.8601\n",
            "Epoch 2502/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 31.1928 - val_loss: 31.8164\n",
            "Epoch 2503/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 31.2722 - val_loss: 31.9852\n",
            "Epoch 2504/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 31.2199 - val_loss: 31.9303\n",
            "Epoch 2505/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 31.3145 - val_loss: 31.7861\n",
            "Epoch 2506/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 31.3632 - val_loss: 31.5708\n",
            "Epoch 2507/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 31.2254 - val_loss: 31.6726\n",
            "Epoch 2508/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 31.0692 - val_loss: 31.6634\n",
            "Epoch 2509/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 31.2866 - val_loss: 31.4560\n",
            "Epoch 2510/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 31.2922 - val_loss: 31.9259\n",
            "Epoch 2511/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 31.2364 - val_loss: 31.7092\n",
            "Epoch 2512/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 31.1154 - val_loss: 31.6590\n",
            "Epoch 2513/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 31.0795 - val_loss: 31.6149\n",
            "Epoch 2514/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 31.1734 - val_loss: 31.4593\n",
            "Epoch 2515/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 31.1270 - val_loss: 31.5698\n",
            "Epoch 2516/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 31.0387 - val_loss: 31.5494\n",
            "Epoch 2517/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 30.9772 - val_loss: 31.5196\n",
            "Epoch 2518/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 30.9006 - val_loss: 31.5512\n",
            "Epoch 2519/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 30.9101 - val_loss: 31.4310\n",
            "Epoch 2520/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 30.9948 - val_loss: 31.3880\n",
            "Epoch 2521/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 31.0041 - val_loss: 31.8081\n",
            "Epoch 2522/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 30.9715 - val_loss: 31.6613\n",
            "Epoch 2523/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 31.1765 - val_loss: 31.7483\n",
            "Epoch 2524/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 30.9594 - val_loss: 31.5994\n",
            "Epoch 2525/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 30.9767 - val_loss: 31.4428\n",
            "Epoch 2526/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 30.9429 - val_loss: 31.4152\n",
            "Epoch 2527/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 30.8532 - val_loss: 31.4368\n",
            "Epoch 2528/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 30.8983 - val_loss: 31.4970\n",
            "Epoch 2529/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 30.9222 - val_loss: 31.2743\n",
            "Epoch 2530/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 30.8573 - val_loss: 31.4489\n",
            "Epoch 2531/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 30.8579 - val_loss: 31.4490\n",
            "Epoch 2532/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 30.7824 - val_loss: 31.2977\n",
            "Epoch 2533/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 30.8505 - val_loss: 31.2296\n",
            "Epoch 2534/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 30.7430 - val_loss: 31.4286\n",
            "Epoch 2535/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 31.2661 - val_loss: 31.3242\n",
            "Epoch 2536/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 30.8357 - val_loss: 31.5236\n",
            "Epoch 2537/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 30.8727 - val_loss: 31.4662\n",
            "Epoch 2538/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 30.8871 - val_loss: 31.5060\n",
            "Epoch 2539/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 30.8017 - val_loss: 31.4771\n",
            "Epoch 2540/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 30.7213 - val_loss: 31.2645\n",
            "Epoch 2541/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 30.7727 - val_loss: 31.2530\n",
            "Epoch 2542/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 30.7998 - val_loss: 31.2773\n",
            "Epoch 2543/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 30.6841 - val_loss: 31.2020\n",
            "Epoch 2544/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 30.5907 - val_loss: 31.2101\n",
            "Epoch 2545/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 30.6989 - val_loss: 31.3045\n",
            "Epoch 2546/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 30.7153 - val_loss: 31.3111\n",
            "Epoch 2547/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 30.6151 - val_loss: 31.3091\n",
            "Epoch 2548/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 30.6439 - val_loss: 31.0480\n",
            "Epoch 2549/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 30.5335 - val_loss: 31.1172\n",
            "Epoch 2550/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 30.4768 - val_loss: 31.1554\n",
            "Epoch 2551/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 30.5948 - val_loss: 31.1035\n",
            "Epoch 2552/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 30.5568 - val_loss: 31.0667\n",
            "Epoch 2553/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 30.4617 - val_loss: 31.2893\n",
            "Epoch 2554/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 30.5761 - val_loss: 31.1519\n",
            "Epoch 2555/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 30.5514 - val_loss: 31.1884\n",
            "Epoch 2556/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 30.5942 - val_loss: 30.9299\n",
            "Epoch 2557/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 30.5902 - val_loss: 31.4465\n",
            "Epoch 2558/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 30.5758 - val_loss: 31.2695\n",
            "Epoch 2559/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 30.5184 - val_loss: 30.8783\n",
            "Epoch 2560/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 30.4730 - val_loss: 31.1235\n",
            "Epoch 2561/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 30.4773 - val_loss: 31.0678\n",
            "Epoch 2562/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 30.4142 - val_loss: 30.8666\n",
            "Epoch 2563/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 30.5252 - val_loss: 30.9297\n",
            "Epoch 2564/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 30.3100 - val_loss: 30.9417\n",
            "Epoch 2565/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 30.3540 - val_loss: 30.9059\n",
            "Epoch 2566/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 30.2559 - val_loss: 30.8014\n",
            "Epoch 2567/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 30.2737 - val_loss: 30.8007\n",
            "Epoch 2568/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 30.1935 - val_loss: 30.9278\n",
            "Epoch 2569/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 30.1773 - val_loss: 30.8341\n",
            "Epoch 2570/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 30.1450 - val_loss: 30.7438\n",
            "Epoch 2571/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 30.2952 - val_loss: 30.7501\n",
            "Epoch 2572/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 30.3992 - val_loss: 30.8385\n",
            "Epoch 2573/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 30.2522 - val_loss: 30.9501\n",
            "Epoch 2574/6000\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 30.2200 - val_loss: 30.6289\n",
            "Epoch 2575/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 30.2805 - val_loss: 30.7140\n",
            "Epoch 2576/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 30.2239 - val_loss: 31.0744\n",
            "Epoch 2577/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 30.1450 - val_loss: 30.7959\n",
            "Epoch 2578/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 30.3951 - val_loss: 30.7853\n",
            "Epoch 2579/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 30.1600 - val_loss: 30.9806\n",
            "Epoch 2580/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 30.0443 - val_loss: 30.9876\n",
            "Epoch 2581/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 30.0578 - val_loss: 30.7560\n",
            "Epoch 2582/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 30.2820 - val_loss: 30.8131\n",
            "Epoch 2583/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 30.1320 - val_loss: 30.6649\n",
            "Epoch 2584/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 29.9842 - val_loss: 30.6321\n",
            "Epoch 2585/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 29.9835 - val_loss: 30.7174\n",
            "Epoch 2586/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 30.0053 - val_loss: 30.7377\n",
            "Epoch 2587/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 30.0915 - val_loss: 30.7668\n",
            "Epoch 2588/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 30.0827 - val_loss: 30.8810\n",
            "Epoch 2589/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 29.9399 - val_loss: 30.6129\n",
            "Epoch 2590/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 29.9809 - val_loss: 30.5429\n",
            "Epoch 2591/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 29.9291 - val_loss: 30.6185\n",
            "Epoch 2592/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 30.1012 - val_loss: 30.6776\n",
            "Epoch 2593/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 29.8876 - val_loss: 30.6283\n",
            "Epoch 2594/6000\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 30.0201 - val_loss: 30.7477\n",
            "Epoch 2595/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 30.0001 - val_loss: 30.5465\n",
            "Epoch 2596/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 29.9394 - val_loss: 30.7303\n",
            "Epoch 2597/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 29.9634 - val_loss: 30.6084\n",
            "Epoch 2598/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 29.9524 - val_loss: 30.6049\n",
            "Epoch 2599/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 29.9234 - val_loss: 30.5095\n",
            "Epoch 2600/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 29.8909 - val_loss: 30.4920\n",
            "Epoch 2601/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 30.0705 - val_loss: 30.4963\n",
            "Epoch 2602/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 29.8434 - val_loss: 30.4311\n",
            "Epoch 2603/6000\n",
            "6/6 [==============================] - 0s 40ms/step - loss: 29.7887 - val_loss: 30.4471\n",
            "Epoch 2604/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 29.7235 - val_loss: 30.3064\n",
            "Epoch 2605/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 29.7822 - val_loss: 30.5386\n",
            "Epoch 2606/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 29.7099 - val_loss: 30.4858\n",
            "Epoch 2607/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 29.8284 - val_loss: 30.4941\n",
            "Epoch 2608/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 29.7358 - val_loss: 30.4628\n",
            "Epoch 2609/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 29.6980 - val_loss: 30.3267\n",
            "Epoch 2610/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 29.8271 - val_loss: 30.2356\n",
            "Epoch 2611/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 29.8264 - val_loss: 30.6076\n",
            "Epoch 2612/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 29.8824 - val_loss: 30.6623\n",
            "Epoch 2613/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 29.7684 - val_loss: 30.8054\n",
            "Epoch 2614/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 29.7506 - val_loss: 30.4449\n",
            "Epoch 2615/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 29.7066 - val_loss: 30.2712\n",
            "Epoch 2616/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 29.7175 - val_loss: 30.3048\n",
            "Epoch 2617/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 29.5410 - val_loss: 30.2766\n",
            "Epoch 2618/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 29.6389 - val_loss: 30.1872\n",
            "Epoch 2619/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 29.6727 - val_loss: 30.4028\n",
            "Epoch 2620/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 29.5172 - val_loss: 30.3018\n",
            "Epoch 2621/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 29.5672 - val_loss: 30.3275\n",
            "Epoch 2622/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 29.5599 - val_loss: 30.1423\n",
            "Epoch 2623/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 29.4911 - val_loss: 30.3747\n",
            "Epoch 2624/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 29.5154 - val_loss: 30.2914\n",
            "Epoch 2625/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 29.4803 - val_loss: 30.3246\n",
            "Epoch 2626/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 29.4370 - val_loss: 30.1435\n",
            "Epoch 2627/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 29.7764 - val_loss: 30.1523\n",
            "Epoch 2628/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 29.4728 - val_loss: 30.3254\n",
            "Epoch 2629/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 29.4699 - val_loss: 30.2789\n",
            "Epoch 2630/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 29.4227 - val_loss: 30.0891\n",
            "Epoch 2631/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 29.4060 - val_loss: 29.9113\n",
            "Epoch 2632/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 29.7422 - val_loss: 30.2332\n",
            "Epoch 2633/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 29.4577 - val_loss: 30.2901\n",
            "Epoch 2634/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 29.3400 - val_loss: 30.2102\n",
            "Epoch 2635/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 29.3657 - val_loss: 30.0711\n",
            "Epoch 2636/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 29.3680 - val_loss: 29.9141\n",
            "Epoch 2637/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 29.6079 - val_loss: 29.8621\n",
            "Epoch 2638/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 29.5862 - val_loss: 30.3027\n",
            "Epoch 2639/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 29.4666 - val_loss: 30.1511\n",
            "Epoch 2640/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 29.4409 - val_loss: 29.9793\n",
            "Epoch 2641/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 29.5296 - val_loss: 30.0398\n",
            "Epoch 2642/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 29.3872 - val_loss: 30.1751\n",
            "Epoch 2643/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 29.4207 - val_loss: 30.0312\n",
            "Epoch 2644/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 29.3107 - val_loss: 30.2213\n",
            "Epoch 2645/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 29.4302 - val_loss: 30.2195\n",
            "Epoch 2646/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 29.2234 - val_loss: 29.9687\n",
            "Epoch 2647/6000\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 29.2355 - val_loss: 29.7622\n",
            "Epoch 2648/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 29.2099 - val_loss: 29.7799\n",
            "Epoch 2649/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 29.2089 - val_loss: 29.8163\n",
            "Epoch 2650/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 29.1886 - val_loss: 29.9655\n",
            "Epoch 2651/6000\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 29.1755 - val_loss: 29.8337\n",
            "Epoch 2652/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 29.2138 - val_loss: 29.8299\n",
            "Epoch 2653/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 29.3534 - val_loss: 29.7549\n",
            "Epoch 2654/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 29.1646 - val_loss: 30.1576\n",
            "Epoch 2655/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 29.2233 - val_loss: 30.1683\n",
            "Epoch 2656/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 29.2439 - val_loss: 30.2229\n",
            "Epoch 2657/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 29.1346 - val_loss: 29.8715\n",
            "Epoch 2658/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 29.1461 - val_loss: 29.7975\n",
            "Epoch 2659/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 29.0287 - val_loss: 29.8511\n",
            "Epoch 2660/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 29.1968 - val_loss: 29.9091\n",
            "Epoch 2661/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 29.1348 - val_loss: 29.5432\n",
            "Epoch 2662/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 29.0877 - val_loss: 29.7730\n",
            "Epoch 2663/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 29.0895 - val_loss: 29.6403\n",
            "Epoch 2664/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 29.2225 - val_loss: 29.9490\n",
            "Epoch 2665/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 28.9963 - val_loss: 30.2016\n",
            "Epoch 2666/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 29.0349 - val_loss: 29.7202\n",
            "Epoch 2667/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 29.0837 - val_loss: 29.8191\n",
            "Epoch 2668/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 29.0660 - val_loss: 29.8704\n",
            "Epoch 2669/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 29.0515 - val_loss: 29.9284\n",
            "Epoch 2670/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 28.8943 - val_loss: 29.7882\n",
            "Epoch 2671/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 28.8586 - val_loss: 29.8289\n",
            "Epoch 2672/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 28.8159 - val_loss: 29.8946\n",
            "Epoch 2673/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 29.1588 - val_loss: 29.7483\n",
            "Epoch 2674/6000\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 28.8196 - val_loss: 29.6879\n",
            "Epoch 2675/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 29.0280 - val_loss: 29.5886\n",
            "Epoch 2676/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 28.9209 - val_loss: 29.6830\n",
            "Epoch 2677/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 28.8433 - val_loss: 29.8901\n",
            "Epoch 2678/6000\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 28.9236 - val_loss: 29.6177\n",
            "Epoch 2679/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 28.9365 - val_loss: 29.3759\n",
            "Epoch 2680/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 28.8531 - val_loss: 29.5463\n",
            "Epoch 2681/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 28.8132 - val_loss: 29.6419\n",
            "Epoch 2682/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 28.7985 - val_loss: 29.5467\n",
            "Epoch 2683/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 28.7103 - val_loss: 29.5102\n",
            "Epoch 2684/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 28.8642 - val_loss: 29.3287\n",
            "Epoch 2685/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 28.7335 - val_loss: 29.4673\n",
            "Epoch 2686/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 28.6836 - val_loss: 29.6289\n",
            "Epoch 2687/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 28.8350 - val_loss: 29.4388\n",
            "Epoch 2688/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 28.6378 - val_loss: 29.6831\n",
            "Epoch 2689/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 28.7559 - val_loss: 29.4564\n",
            "Epoch 2690/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 28.6745 - val_loss: 29.4596\n",
            "Epoch 2691/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 28.7092 - val_loss: 29.4850\n",
            "Epoch 2692/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 28.6016 - val_loss: 29.6234\n",
            "Epoch 2693/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 28.7282 - val_loss: 29.4756\n",
            "Epoch 2694/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 28.8230 - val_loss: 29.3685\n",
            "Epoch 2695/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 28.5186 - val_loss: 29.4818\n",
            "Epoch 2696/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 28.7275 - val_loss: 29.4020\n",
            "Epoch 2697/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 28.5515 - val_loss: 29.4075\n",
            "Epoch 2698/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 28.6974 - val_loss: 29.6774\n",
            "Epoch 2699/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 28.6082 - val_loss: 29.5089\n",
            "Epoch 2700/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 28.5991 - val_loss: 29.2340\n",
            "Epoch 2701/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 28.6346 - val_loss: 29.2381\n",
            "Epoch 2702/6000\n",
            "6/6 [==============================] - 0s 39ms/step - loss: 28.5860 - val_loss: 29.3073\n",
            "Epoch 2703/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 28.4950 - val_loss: 29.1093\n",
            "Epoch 2704/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 28.5385 - val_loss: 29.0911\n",
            "Epoch 2705/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 28.6517 - val_loss: 28.9150\n",
            "Epoch 2706/6000\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 28.4591 - val_loss: 29.0925\n",
            "Epoch 2707/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 28.4199 - val_loss: 29.3582\n",
            "Epoch 2708/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 28.4093 - val_loss: 29.3526\n",
            "Epoch 2709/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 28.4856 - val_loss: 29.2189\n",
            "Epoch 2710/6000\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 28.4741 - val_loss: 29.2201\n",
            "Epoch 2711/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 28.3112 - val_loss: 29.2927\n",
            "Epoch 2712/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 28.3467 - val_loss: 29.0739\n",
            "Epoch 2713/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 28.3095 - val_loss: 29.0382\n",
            "Epoch 2714/6000\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 28.3387 - val_loss: 29.1363\n",
            "Epoch 2715/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 28.2115 - val_loss: 29.2108\n",
            "Epoch 2716/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 28.3315 - val_loss: 29.0895\n",
            "Epoch 2717/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 28.3827 - val_loss: 28.8345\n",
            "Epoch 2718/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 28.3294 - val_loss: 29.0250\n",
            "Epoch 2719/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 28.1721 - val_loss: 29.2412\n",
            "Epoch 2720/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 28.2829 - val_loss: 29.1789\n",
            "Epoch 2721/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 28.3157 - val_loss: 29.0361\n",
            "Epoch 2722/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 28.1948 - val_loss: 29.0501\n",
            "Epoch 2723/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 28.2016 - val_loss: 28.9674\n",
            "Epoch 2724/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 28.1463 - val_loss: 29.2464\n",
            "Epoch 2725/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 28.3062 - val_loss: 29.0887\n",
            "Epoch 2726/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 28.1134 - val_loss: 28.9949\n",
            "Epoch 2727/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 28.2541 - val_loss: 28.9391\n",
            "Epoch 2728/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 28.0739 - val_loss: 29.0273\n",
            "Epoch 2729/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 28.3609 - val_loss: 29.1110\n",
            "Epoch 2730/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 28.1251 - val_loss: 29.0966\n",
            "Epoch 2731/6000\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 28.1644 - val_loss: 29.2014\n",
            "Epoch 2732/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 28.2113 - val_loss: 28.9586\n",
            "Epoch 2733/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 28.1526 - val_loss: 28.9084\n",
            "Epoch 2734/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 28.1468 - val_loss: 28.9685\n",
            "Epoch 2735/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 27.9678 - val_loss: 28.8183\n",
            "Epoch 2736/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 28.0623 - val_loss: 28.8297\n",
            "Epoch 2737/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 28.1698 - val_loss: 28.8626\n",
            "Epoch 2738/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 28.0223 - val_loss: 28.8343\n",
            "Epoch 2739/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 28.1367 - val_loss: 28.8013\n",
            "Epoch 2740/6000\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 28.1533 - val_loss: 28.8895\n",
            "Epoch 2741/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 27.9180 - val_loss: 28.7868\n",
            "Epoch 2742/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 27.9625 - val_loss: 28.6584\n",
            "Epoch 2743/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 27.9076 - val_loss: 28.6274\n",
            "Epoch 2744/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 27.8988 - val_loss: 28.6251\n",
            "Epoch 2745/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 27.8755 - val_loss: 28.7297\n",
            "Epoch 2746/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 27.9245 - val_loss: 28.5698\n",
            "Epoch 2747/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 27.9538 - val_loss: 28.8615\n",
            "Epoch 2748/6000\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 27.9128 - val_loss: 28.7091\n",
            "Epoch 2749/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 28.2130 - val_loss: 28.6488\n",
            "Epoch 2750/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 28.0001 - val_loss: 28.9297\n",
            "Epoch 2751/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 28.0929 - val_loss: 28.9844\n",
            "Epoch 2752/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 28.0023 - val_loss: 28.8498\n",
            "Epoch 2753/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 28.0401 - val_loss: 29.0310\n",
            "Epoch 2754/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 28.0392 - val_loss: 28.8329\n",
            "Epoch 2755/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 27.9166 - val_loss: 28.6193\n",
            "Epoch 2756/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 27.8794 - val_loss: 28.7931\n",
            "Epoch 2757/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 27.7997 - val_loss: 28.5238\n",
            "Epoch 2758/6000\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 27.7049 - val_loss: 28.4829\n",
            "Epoch 2759/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 27.7246 - val_loss: 28.4767\n",
            "Epoch 2760/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 27.6692 - val_loss: 28.4771\n",
            "Epoch 2761/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 27.7707 - val_loss: 28.4398\n",
            "Epoch 2762/6000\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 27.7753 - val_loss: 28.6325\n",
            "Epoch 2763/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 27.8395 - val_loss: 28.3569\n",
            "Epoch 2764/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 27.8384 - val_loss: 28.5159\n",
            "Epoch 2765/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 27.5828 - val_loss: 28.4739\n",
            "Epoch 2766/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 27.7822 - val_loss: 28.4452\n",
            "Epoch 2767/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 27.8097 - val_loss: 28.5581\n",
            "Epoch 2768/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 27.6468 - val_loss: 28.3300\n",
            "Epoch 2769/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 27.7946 - val_loss: 28.2702\n",
            "Epoch 2770/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 27.5638 - val_loss: 28.3334\n",
            "Epoch 2771/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 27.5185 - val_loss: 28.3155\n",
            "Epoch 2772/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 27.6377 - val_loss: 28.4178\n",
            "Epoch 2773/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 27.7018 - val_loss: 28.1531\n",
            "Epoch 2774/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 27.6810 - val_loss: 28.5483\n",
            "Epoch 2775/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 27.8115 - val_loss: 28.3910\n",
            "Epoch 2776/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 27.7073 - val_loss: 28.3155\n",
            "Epoch 2777/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 27.6030 - val_loss: 28.3929\n",
            "Epoch 2778/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 27.5477 - val_loss: 28.4840\n",
            "Epoch 2779/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 27.6449 - val_loss: 28.5490\n",
            "Epoch 2780/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 27.6081 - val_loss: 28.4224\n",
            "Epoch 2781/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 27.5744 - val_loss: 28.1667\n",
            "Epoch 2782/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 27.4823 - val_loss: 28.4861\n",
            "Epoch 2783/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 27.4909 - val_loss: 28.3128\n",
            "Epoch 2784/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 27.6524 - val_loss: 28.1875\n",
            "Epoch 2785/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 27.5173 - val_loss: 28.2507\n",
            "Epoch 2786/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 27.3795 - val_loss: 28.3744\n",
            "Epoch 2787/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 27.4043 - val_loss: 28.1788\n",
            "Epoch 2788/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 27.4415 - val_loss: 28.1352\n",
            "Epoch 2789/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 27.3748 - val_loss: 28.3654\n",
            "Epoch 2790/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 27.5128 - val_loss: 28.1509\n",
            "Epoch 2791/6000\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 27.7330 - val_loss: 28.4887\n",
            "Epoch 2792/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 27.3654 - val_loss: 28.3695\n",
            "Epoch 2793/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 27.5482 - val_loss: 28.1260\n",
            "Epoch 2794/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 27.3947 - val_loss: 28.1756\n",
            "Epoch 2795/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 27.3887 - val_loss: 28.4957\n",
            "Epoch 2796/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 27.3046 - val_loss: 28.2811\n",
            "Epoch 2797/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 27.2542 - val_loss: 28.3720\n",
            "Epoch 2798/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 27.2818 - val_loss: 28.1844\n",
            "Epoch 2799/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 27.4237 - val_loss: 28.0106\n",
            "Epoch 2800/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 27.3653 - val_loss: 28.1368\n",
            "Epoch 2801/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 27.1730 - val_loss: 28.3486\n",
            "Epoch 2802/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 27.2091 - val_loss: 28.3223\n",
            "Epoch 2803/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 27.1761 - val_loss: 28.1786\n",
            "Epoch 2804/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 27.1565 - val_loss: 28.0695\n",
            "Epoch 2805/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 27.0564 - val_loss: 28.1858\n",
            "Epoch 2806/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 27.1927 - val_loss: 28.3081\n",
            "Epoch 2807/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 27.1149 - val_loss: 28.0978\n",
            "Epoch 2808/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 27.2996 - val_loss: 28.1669\n",
            "Epoch 2809/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 27.2138 - val_loss: 28.2213\n",
            "Epoch 2810/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 27.1184 - val_loss: 28.1152\n",
            "Epoch 2811/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 27.0985 - val_loss: 28.1656\n",
            "Epoch 2812/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 27.1009 - val_loss: 28.2696\n",
            "Epoch 2813/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 27.1592 - val_loss: 27.9170\n",
            "Epoch 2814/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 27.1125 - val_loss: 27.8326\n",
            "Epoch 2815/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 27.1368 - val_loss: 27.7540\n",
            "Epoch 2816/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 26.9916 - val_loss: 27.8066\n",
            "Epoch 2817/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 26.9570 - val_loss: 27.7751\n",
            "Epoch 2818/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 26.9634 - val_loss: 28.1273\n",
            "Epoch 2819/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 27.0372 - val_loss: 27.9439\n",
            "Epoch 2820/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 27.0521 - val_loss: 27.8358\n",
            "Epoch 2821/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 27.0015 - val_loss: 27.8255\n",
            "Epoch 2822/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 26.8917 - val_loss: 27.7837\n",
            "Epoch 2823/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 26.8882 - val_loss: 27.9208\n",
            "Epoch 2824/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 26.9975 - val_loss: 27.8476\n",
            "Epoch 2825/6000\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 27.0351 - val_loss: 27.7954\n",
            "Epoch 2826/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 26.8636 - val_loss: 27.9485\n",
            "Epoch 2827/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 26.8670 - val_loss: 27.7881\n",
            "Epoch 2828/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 27.1614 - val_loss: 27.6458\n",
            "Epoch 2829/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 26.9179 - val_loss: 27.9271\n",
            "Epoch 2830/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 26.8764 - val_loss: 27.8538\n",
            "Epoch 2831/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 26.9439 - val_loss: 27.7011\n",
            "Epoch 2832/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 26.9356 - val_loss: 27.7073\n",
            "Epoch 2833/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 26.9476 - val_loss: 27.9103\n",
            "Epoch 2834/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 26.9274 - val_loss: 27.6381\n",
            "Epoch 2835/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 26.8814 - val_loss: 27.7934\n",
            "Epoch 2836/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 26.8412 - val_loss: 27.7343\n",
            "Epoch 2837/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 26.8804 - val_loss: 27.8182\n",
            "Epoch 2838/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 26.8749 - val_loss: 27.6833\n",
            "Epoch 2839/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 26.7076 - val_loss: 27.5326\n",
            "Epoch 2840/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 26.6759 - val_loss: 27.6283\n",
            "Epoch 2841/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 26.7342 - val_loss: 27.7603\n",
            "Epoch 2842/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 26.7328 - val_loss: 27.5948\n",
            "Epoch 2843/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 26.7228 - val_loss: 27.5058\n",
            "Epoch 2844/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 26.6940 - val_loss: 27.6824\n",
            "Epoch 2845/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 26.7568 - val_loss: 27.7582\n",
            "Epoch 2846/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 26.6620 - val_loss: 27.9269\n",
            "Epoch 2847/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 26.6319 - val_loss: 27.8531\n",
            "Epoch 2848/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 26.7975 - val_loss: 27.7026\n",
            "Epoch 2849/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 26.5154 - val_loss: 27.5353\n",
            "Epoch 2850/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 26.7143 - val_loss: 27.8596\n",
            "Epoch 2851/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 26.6417 - val_loss: 27.6289\n",
            "Epoch 2852/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 26.7685 - val_loss: 27.5715\n",
            "Epoch 2853/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 26.5822 - val_loss: 27.9091\n",
            "Epoch 2854/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 26.6459 - val_loss: 27.7799\n",
            "Epoch 2855/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 26.7166 - val_loss: 27.8075\n",
            "Epoch 2856/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 26.5898 - val_loss: 27.6817\n",
            "Epoch 2857/6000\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 26.6276 - val_loss: 27.3416\n",
            "Epoch 2858/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 26.5073 - val_loss: 27.4082\n",
            "Epoch 2859/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 26.5970 - val_loss: 27.6170\n",
            "Epoch 2860/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 26.4554 - val_loss: 27.6335\n",
            "Epoch 2861/6000\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 26.5297 - val_loss: 27.2765\n",
            "Epoch 2862/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 26.4039 - val_loss: 27.4758\n",
            "Epoch 2863/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 26.4272 - val_loss: 27.4893\n",
            "Epoch 2864/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 26.4564 - val_loss: 27.4826\n",
            "Epoch 2865/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 26.4239 - val_loss: 27.3860\n",
            "Epoch 2866/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 26.5496 - val_loss: 27.3396\n",
            "Epoch 2867/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 26.4488 - val_loss: 27.2051\n",
            "Epoch 2868/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 26.3601 - val_loss: 27.3035\n",
            "Epoch 2869/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 26.3124 - val_loss: 27.3579\n",
            "Epoch 2870/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 26.4467 - val_loss: 27.2840\n",
            "Epoch 2871/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 26.3080 - val_loss: 27.2998\n",
            "Epoch 2872/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 26.3278 - val_loss: 27.3398\n",
            "Epoch 2873/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 26.2922 - val_loss: 27.3742\n",
            "Epoch 2874/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 26.3847 - val_loss: 27.2797\n",
            "Epoch 2875/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 26.3488 - val_loss: 27.3951\n",
            "Epoch 2876/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 26.2703 - val_loss: 27.2404\n",
            "Epoch 2877/6000\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 26.2229 - val_loss: 27.2345\n",
            "Epoch 2878/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 26.2142 - val_loss: 27.0609\n",
            "Epoch 2879/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 26.1774 - val_loss: 26.9799\n",
            "Epoch 2880/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 26.3792 - val_loss: 27.1244\n",
            "Epoch 2881/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 26.3377 - val_loss: 27.2670\n",
            "Epoch 2882/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 26.1512 - val_loss: 27.2154\n",
            "Epoch 2883/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 26.2872 - val_loss: 27.3755\n",
            "Epoch 2884/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 26.2848 - val_loss: 27.2647\n",
            "Epoch 2885/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 26.3056 - val_loss: 27.0563\n",
            "Epoch 2886/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 26.1520 - val_loss: 27.3646\n",
            "Epoch 2887/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 26.1922 - val_loss: 27.3083\n",
            "Epoch 2888/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 26.1844 - val_loss: 27.0401\n",
            "Epoch 2889/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 26.2383 - val_loss: 27.0741\n",
            "Epoch 2890/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 26.2991 - val_loss: 26.9843\n",
            "Epoch 2891/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 26.3727 - val_loss: 27.2870\n",
            "Epoch 2892/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 26.1177 - val_loss: 27.2732\n",
            "Epoch 2893/6000\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 26.0435 - val_loss: 27.1046\n",
            "Epoch 2894/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 26.2674 - val_loss: 27.0310\n",
            "Epoch 2895/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 26.1464 - val_loss: 27.1060\n",
            "Epoch 2896/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 26.0713 - val_loss: 26.9688\n",
            "Epoch 2897/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 25.9957 - val_loss: 27.0224\n",
            "Epoch 2898/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 26.0407 - val_loss: 26.9477\n",
            "Epoch 2899/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 26.0473 - val_loss: 27.1587\n",
            "Epoch 2900/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 26.0199 - val_loss: 27.1772\n",
            "Epoch 2901/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 26.1131 - val_loss: 27.0090\n",
            "Epoch 2902/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 26.0132 - val_loss: 26.7835\n",
            "Epoch 2903/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 25.9142 - val_loss: 26.7159\n",
            "Epoch 2904/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 26.1784 - val_loss: 26.9974\n",
            "Epoch 2905/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 26.0613 - val_loss: 26.7909\n",
            "Epoch 2906/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 25.9928 - val_loss: 26.9841\n",
            "Epoch 2907/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 26.0344 - val_loss: 27.0664\n",
            "Epoch 2908/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 26.1245 - val_loss: 26.8700\n",
            "Epoch 2909/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 26.1135 - val_loss: 27.0236\n",
            "Epoch 2910/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 26.0577 - val_loss: 26.9823\n",
            "Epoch 2911/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 26.0775 - val_loss: 27.0176\n",
            "Epoch 2912/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 26.0902 - val_loss: 27.1089\n",
            "Epoch 2913/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 25.9724 - val_loss: 26.8027\n",
            "Epoch 2914/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 26.0801 - val_loss: 26.9159\n",
            "Epoch 2915/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 26.2682 - val_loss: 26.8931\n",
            "Epoch 2916/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 26.1630 - val_loss: 27.4795\n",
            "Epoch 2917/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 26.1941 - val_loss: 27.0491\n",
            "Epoch 2918/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 25.9366 - val_loss: 26.6955\n",
            "Epoch 2919/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 25.8031 - val_loss: 26.5543\n",
            "Epoch 2920/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 25.8992 - val_loss: 26.6362\n",
            "Epoch 2921/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 25.9933 - val_loss: 26.5865\n",
            "Epoch 2922/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 25.9604 - val_loss: 26.8990\n",
            "Epoch 2923/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 25.7356 - val_loss: 26.7134\n",
            "Epoch 2924/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 25.7438 - val_loss: 26.8348\n",
            "Epoch 2925/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 25.7686 - val_loss: 26.7231\n",
            "Epoch 2926/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 25.8168 - val_loss: 27.0235\n",
            "Epoch 2927/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 25.7117 - val_loss: 26.7718\n",
            "Epoch 2928/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 25.6876 - val_loss: 26.7734\n",
            "Epoch 2929/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 25.8449 - val_loss: 26.9286\n",
            "Epoch 2930/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 25.8278 - val_loss: 26.7908\n",
            "Epoch 2931/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 25.7901 - val_loss: 26.6269\n",
            "Epoch 2932/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 25.5935 - val_loss: 26.6976\n",
            "Epoch 2933/6000\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 25.5864 - val_loss: 26.8383\n",
            "Epoch 2934/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 25.7965 - val_loss: 26.8940\n",
            "Epoch 2935/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 25.8702 - val_loss: 26.7029\n",
            "Epoch 2936/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 25.7865 - val_loss: 26.8007\n",
            "Epoch 2937/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 25.8875 - val_loss: 26.6356\n",
            "Epoch 2938/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 25.6967 - val_loss: 26.8426\n",
            "Epoch 2939/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 25.8508 - val_loss: 26.5142\n",
            "Epoch 2940/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 25.6224 - val_loss: 26.3719\n",
            "Epoch 2941/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 25.6367 - val_loss: 26.5992\n",
            "Epoch 2942/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 25.6334 - val_loss: 26.7240\n",
            "Epoch 2943/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 25.5941 - val_loss: 26.7548\n",
            "Epoch 2944/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 25.5676 - val_loss: 26.5389\n",
            "Epoch 2945/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 25.5088 - val_loss: 26.8555\n",
            "Epoch 2946/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 25.5751 - val_loss: 26.5693\n",
            "Epoch 2947/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 25.6223 - val_loss: 26.6063\n",
            "Epoch 2948/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 25.4113 - val_loss: 26.6545\n",
            "Epoch 2949/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 25.5159 - val_loss: 26.3165\n",
            "Epoch 2950/6000\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 25.4468 - val_loss: 26.2009\n",
            "Epoch 2951/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 25.4557 - val_loss: 26.2500\n",
            "Epoch 2952/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 25.4608 - val_loss: 26.3700\n",
            "Epoch 2953/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 25.5867 - val_loss: 26.3479\n",
            "Epoch 2954/6000\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 25.4105 - val_loss: 26.2411\n",
            "Epoch 2955/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 25.3309 - val_loss: 26.1862\n",
            "Epoch 2956/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 25.3321 - val_loss: 26.3760\n",
            "Epoch 2957/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 25.4335 - val_loss: 26.3038\n",
            "Epoch 2958/6000\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 25.4484 - val_loss: 26.4815\n",
            "Epoch 2959/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 25.4010 - val_loss: 26.3823\n",
            "Epoch 2960/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 25.4363 - val_loss: 26.2938\n",
            "Epoch 2961/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 25.4001 - val_loss: 26.1827\n",
            "Epoch 2962/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 25.3545 - val_loss: 26.2526\n",
            "Epoch 2963/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 25.2379 - val_loss: 26.1947\n",
            "Epoch 2964/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 25.3220 - val_loss: 26.1262\n",
            "Epoch 2965/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 25.4320 - val_loss: 26.0617\n",
            "Epoch 2966/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 25.3123 - val_loss: 26.3156\n",
            "Epoch 2967/6000\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 25.2521 - val_loss: 26.3018\n",
            "Epoch 2968/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 25.2862 - val_loss: 26.2964\n",
            "Epoch 2969/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 25.6048 - val_loss: 26.4973\n",
            "Epoch 2970/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 25.5600 - val_loss: 26.3061\n",
            "Epoch 2971/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 25.5579 - val_loss: 26.1671\n",
            "Epoch 2972/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 25.4835 - val_loss: 26.5547\n",
            "Epoch 2973/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 25.3558 - val_loss: 26.3908\n",
            "Epoch 2974/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 25.3427 - val_loss: 26.4868\n",
            "Epoch 2975/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 25.2729 - val_loss: 26.4070\n",
            "Epoch 2976/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 25.1829 - val_loss: 26.2556\n",
            "Epoch 2977/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 25.1456 - val_loss: 26.3592\n",
            "Epoch 2978/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 25.1489 - val_loss: 26.0449\n",
            "Epoch 2979/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 25.1805 - val_loss: 26.0564\n",
            "Epoch 2980/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 25.1801 - val_loss: 25.9791\n",
            "Epoch 2981/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 25.1261 - val_loss: 25.9008\n",
            "Epoch 2982/6000\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 25.1160 - val_loss: 26.0401\n",
            "Epoch 2983/6000\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 25.2134 - val_loss: 26.0363\n",
            "Epoch 2984/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 25.0785 - val_loss: 26.1485\n",
            "Epoch 2985/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 25.1337 - val_loss: 26.2644\n",
            "Epoch 2986/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 25.1050 - val_loss: 26.1218\n",
            "Epoch 2987/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 25.2546 - val_loss: 26.3761\n",
            "Epoch 2988/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 25.1061 - val_loss: 26.1541\n",
            "Epoch 2989/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 25.1312 - val_loss: 26.1565\n",
            "Epoch 2990/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 24.9165 - val_loss: 25.8652\n",
            "Epoch 2991/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 25.1130 - val_loss: 25.8282\n",
            "Epoch 2992/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 24.9985 - val_loss: 25.8698\n",
            "Epoch 2993/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 25.0001 - val_loss: 25.8560\n",
            "Epoch 2994/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 25.0338 - val_loss: 26.3998\n",
            "Epoch 2995/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 24.9881 - val_loss: 26.0936\n",
            "Epoch 2996/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 24.9797 - val_loss: 25.9549\n",
            "Epoch 2997/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 24.9125 - val_loss: 26.1040\n",
            "Epoch 2998/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 24.8977 - val_loss: 25.8944\n",
            "Epoch 2999/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 24.9781 - val_loss: 25.8026\n",
            "Epoch 3000/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 25.0454 - val_loss: 26.0870\n",
            "Epoch 3001/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 24.9441 - val_loss: 25.8529\n",
            "Epoch 3002/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 24.9083 - val_loss: 25.7167\n",
            "Epoch 3003/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 24.8217 - val_loss: 25.8351\n",
            "Epoch 3004/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 24.8664 - val_loss: 25.6503\n",
            "Epoch 3005/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 24.7874 - val_loss: 25.9553\n",
            "Epoch 3006/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 24.8034 - val_loss: 25.6975\n",
            "Epoch 3007/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 24.8270 - val_loss: 25.7552\n",
            "Epoch 3008/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 24.9256 - val_loss: 25.6759\n",
            "Epoch 3009/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 24.7192 - val_loss: 25.5683\n",
            "Epoch 3010/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 24.6692 - val_loss: 25.7130\n",
            "Epoch 3011/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 24.8413 - val_loss: 25.9434\n",
            "Epoch 3012/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 24.8752 - val_loss: 25.7213\n",
            "Epoch 3013/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 24.7728 - val_loss: 25.5614\n",
            "Epoch 3014/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 24.7237 - val_loss: 25.6369\n",
            "Epoch 3015/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 24.6274 - val_loss: 25.5784\n",
            "Epoch 3016/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 24.6366 - val_loss: 25.6175\n",
            "Epoch 3017/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 24.6093 - val_loss: 25.8314\n",
            "Epoch 3018/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 24.5274 - val_loss: 25.6033\n",
            "Epoch 3019/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 24.6434 - val_loss: 25.6665\n",
            "Epoch 3020/6000\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 24.5194 - val_loss: 25.4929\n",
            "Epoch 3021/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 24.5929 - val_loss: 25.6696\n",
            "Epoch 3022/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 24.6289 - val_loss: 25.6121\n",
            "Epoch 3023/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 24.5012 - val_loss: 25.5933\n",
            "Epoch 3024/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 24.4787 - val_loss: 25.5657\n",
            "Epoch 3025/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 24.6289 - val_loss: 25.5956\n",
            "Epoch 3026/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 24.6081 - val_loss: 25.5934\n",
            "Epoch 3027/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 24.7116 - val_loss: 25.8417\n",
            "Epoch 3028/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 24.6199 - val_loss: 25.8774\n",
            "Epoch 3029/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 24.6313 - val_loss: 25.6504\n",
            "Epoch 3030/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 24.5251 - val_loss: 25.5364\n",
            "Epoch 3031/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 24.9093 - val_loss: 25.6638\n",
            "Epoch 3032/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 24.5744 - val_loss: 25.9444\n",
            "Epoch 3033/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 24.8676 - val_loss: 25.7939\n",
            "Epoch 3034/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 24.4991 - val_loss: 25.7148\n",
            "Epoch 3035/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 24.5680 - val_loss: 25.5882\n",
            "Epoch 3036/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 24.6005 - val_loss: 25.9911\n",
            "Epoch 3037/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 24.4694 - val_loss: 25.7515\n",
            "Epoch 3038/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 24.4841 - val_loss: 25.5266\n",
            "Epoch 3039/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 24.3459 - val_loss: 25.7900\n",
            "Epoch 3040/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 24.4947 - val_loss: 25.4260\n",
            "Epoch 3041/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 24.3916 - val_loss: 25.6478\n",
            "Epoch 3042/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 24.5903 - val_loss: 25.7097\n",
            "Epoch 3043/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 24.4914 - val_loss: 25.4196\n",
            "Epoch 3044/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 24.5450 - val_loss: 25.8333\n",
            "Epoch 3045/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 24.4091 - val_loss: 25.4851\n",
            "Epoch 3046/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 24.4809 - val_loss: 25.5331\n",
            "Epoch 3047/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 24.4357 - val_loss: 25.6378\n",
            "Epoch 3048/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 24.3970 - val_loss: 25.5925\n",
            "Epoch 3049/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 24.3918 - val_loss: 25.4659\n",
            "Epoch 3050/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 24.4430 - val_loss: 25.6671\n",
            "Epoch 3051/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 24.3325 - val_loss: 25.6984\n",
            "Epoch 3052/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 24.5391 - val_loss: 25.6608\n",
            "Epoch 3053/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 24.3181 - val_loss: 25.3115\n",
            "Epoch 3054/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 24.2364 - val_loss: 25.5304\n",
            "Epoch 3055/6000\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 24.3141 - val_loss: 25.4787\n",
            "Epoch 3056/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 24.2264 - val_loss: 25.2777\n",
            "Epoch 3057/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 24.1413 - val_loss: 25.3608\n",
            "Epoch 3058/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 24.2005 - val_loss: 25.2925\n",
            "Epoch 3059/6000\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 24.1710 - val_loss: 25.2910\n",
            "Epoch 3060/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 24.1101 - val_loss: 25.3488\n",
            "Epoch 3061/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 24.1504 - val_loss: 25.3311\n",
            "Epoch 3062/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 24.4517 - val_loss: 25.3359\n",
            "Epoch 3063/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 24.1584 - val_loss: 25.5065\n",
            "Epoch 3064/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 24.0953 - val_loss: 25.5679\n",
            "Epoch 3065/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 24.1486 - val_loss: 25.4333\n",
            "Epoch 3066/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 24.3366 - val_loss: 25.3050\n",
            "Epoch 3067/6000\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 24.1379 - val_loss: 25.1076\n",
            "Epoch 3068/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 24.0442 - val_loss: 25.1348\n",
            "Epoch 3069/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 24.1697 - val_loss: 25.0925\n",
            "Epoch 3070/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 24.0893 - val_loss: 25.2564\n",
            "Epoch 3071/6000\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 24.0286 - val_loss: 25.0901\n",
            "Epoch 3072/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 24.0485 - val_loss: 25.1522\n",
            "Epoch 3073/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 24.0326 - val_loss: 24.9038\n",
            "Epoch 3074/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 24.1845 - val_loss: 24.8453\n",
            "Epoch 3075/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 24.1047 - val_loss: 24.9562\n",
            "Epoch 3076/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 24.0960 - val_loss: 25.1157\n",
            "Epoch 3077/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 24.4212 - val_loss: 25.2619\n",
            "Epoch 3078/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 24.0878 - val_loss: 25.1290\n",
            "Epoch 3079/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 23.9702 - val_loss: 25.0301\n",
            "Epoch 3080/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 24.1309 - val_loss: 25.0632\n",
            "Epoch 3081/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 23.9248 - val_loss: 25.0935\n",
            "Epoch 3082/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 24.0465 - val_loss: 24.8779\n",
            "Epoch 3083/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 24.3589 - val_loss: 25.3876\n",
            "Epoch 3084/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 24.5853 - val_loss: 25.6633\n",
            "Epoch 3085/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 24.4817 - val_loss: 25.6432\n",
            "Epoch 3086/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 24.2219 - val_loss: 25.9140\n",
            "Epoch 3087/6000\n",
            "6/6 [==============================] - 0s 41ms/step - loss: 24.1564 - val_loss: 25.8055\n",
            "Epoch 3088/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 24.1837 - val_loss: 25.3419\n",
            "Epoch 3089/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 24.2133 - val_loss: 25.1919\n",
            "Epoch 3090/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 24.1528 - val_loss: 25.5286\n",
            "Epoch 3091/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 24.1130 - val_loss: 25.3410\n",
            "Epoch 3092/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 24.0233 - val_loss: 25.3143\n",
            "Epoch 3093/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 24.0604 - val_loss: 25.3890\n",
            "Epoch 3094/6000\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 23.9127 - val_loss: 25.2698\n",
            "Epoch 3095/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 23.9056 - val_loss: 25.4346\n",
            "Epoch 3096/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 23.9024 - val_loss: 25.1932\n",
            "Epoch 3097/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 23.9103 - val_loss: 25.4221\n",
            "Epoch 3098/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 23.7635 - val_loss: 25.0612\n",
            "Epoch 3099/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 24.0438 - val_loss: 25.3398\n",
            "Epoch 3100/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 23.9065 - val_loss: 25.1243\n",
            "Epoch 3101/6000\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 23.8171 - val_loss: 25.0777\n",
            "Epoch 3102/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 23.7451 - val_loss: 25.0493\n",
            "Epoch 3103/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 23.6663 - val_loss: 24.9923\n",
            "Epoch 3104/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 23.7579 - val_loss: 24.9941\n",
            "Epoch 3105/6000\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 23.8517 - val_loss: 24.8368\n",
            "Epoch 3106/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 23.8089 - val_loss: 24.6616\n",
            "Epoch 3107/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 23.7965 - val_loss: 24.8535\n",
            "Epoch 3108/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 23.6364 - val_loss: 24.9798\n",
            "Epoch 3109/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 23.6877 - val_loss: 24.8166\n",
            "Epoch 3110/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 23.6160 - val_loss: 24.7927\n",
            "Epoch 3111/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 23.8039 - val_loss: 24.6624\n",
            "Epoch 3112/6000\n",
            "6/6 [==============================] - 0s 46ms/step - loss: 23.7209 - val_loss: 24.8513\n",
            "Epoch 3113/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 23.7574 - val_loss: 24.8568\n",
            "Epoch 3114/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 23.8352 - val_loss: 25.1742\n",
            "Epoch 3115/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 23.7541 - val_loss: 24.7864\n",
            "Epoch 3116/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 23.5739 - val_loss: 24.8321\n",
            "Epoch 3117/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 23.7278 - val_loss: 24.7214\n",
            "Epoch 3118/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 23.6348 - val_loss: 24.8931\n",
            "Epoch 3119/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 23.6471 - val_loss: 24.8056\n",
            "Epoch 3120/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 23.5754 - val_loss: 24.8287\n",
            "Epoch 3121/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 23.6179 - val_loss: 24.4897\n",
            "Epoch 3122/6000\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 23.6061 - val_loss: 24.4508\n",
            "Epoch 3123/6000\n",
            "6/6 [==============================] - 0s 53ms/step - loss: 23.5013 - val_loss: 24.3971\n",
            "Epoch 3124/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 23.5169 - val_loss: 24.3893\n",
            "Epoch 3125/6000\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 23.4734 - val_loss: 24.5146\n",
            "Epoch 3126/6000\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 23.5185 - val_loss: 24.3826\n",
            "Epoch 3127/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 23.6345 - val_loss: 24.4785\n",
            "Epoch 3128/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 23.4950 - val_loss: 24.7411\n",
            "Epoch 3129/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 23.4004 - val_loss: 24.5220\n",
            "Epoch 3130/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 23.4777 - val_loss: 24.4200\n",
            "Epoch 3131/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 23.4367 - val_loss: 24.4072\n",
            "Epoch 3132/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 23.3926 - val_loss: 24.4051\n",
            "Epoch 3133/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 23.6790 - val_loss: 24.5120\n",
            "Epoch 3134/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 23.5823 - val_loss: 24.4481\n",
            "Epoch 3135/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 23.2608 - val_loss: 24.4285\n",
            "Epoch 3136/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 23.3841 - val_loss: 24.6614\n",
            "Epoch 3137/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 23.3385 - val_loss: 24.6561\n",
            "Epoch 3138/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 23.4176 - val_loss: 24.4452\n",
            "Epoch 3139/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 23.5792 - val_loss: 24.4355\n",
            "Epoch 3140/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 23.3515 - val_loss: 24.4644\n",
            "Epoch 3141/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 23.3985 - val_loss: 24.5662\n",
            "Epoch 3142/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 23.3307 - val_loss: 24.7364\n",
            "Epoch 3143/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 23.3724 - val_loss: 24.4886\n",
            "Epoch 3144/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 23.1499 - val_loss: 24.4866\n",
            "Epoch 3145/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 23.3201 - val_loss: 24.1571\n",
            "Epoch 3146/6000\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 23.3812 - val_loss: 24.4706\n",
            "Epoch 3147/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 23.4167 - val_loss: 24.6447\n",
            "Epoch 3148/6000\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 23.4969 - val_loss: 24.4653\n",
            "Epoch 3149/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 23.1859 - val_loss: 24.2571\n",
            "Epoch 3150/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 23.1325 - val_loss: 24.2610\n",
            "Epoch 3151/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 23.3248 - val_loss: 24.2252\n",
            "Epoch 3152/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 23.5066 - val_loss: 24.8013\n",
            "Epoch 3153/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 23.1465 - val_loss: 24.5195\n",
            "Epoch 3154/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 23.2142 - val_loss: 24.2705\n",
            "Epoch 3155/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 23.2282 - val_loss: 24.1577\n",
            "Epoch 3156/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 23.1414 - val_loss: 24.2461\n",
            "Epoch 3157/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 23.3014 - val_loss: 24.3452\n",
            "Epoch 3158/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 23.2826 - val_loss: 24.2129\n",
            "Epoch 3159/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 23.4087 - val_loss: 24.5228\n",
            "Epoch 3160/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 23.2203 - val_loss: 24.3624\n",
            "Epoch 3161/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 23.1020 - val_loss: 24.3825\n",
            "Epoch 3162/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 23.2713 - val_loss: 24.4301\n",
            "Epoch 3163/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 23.1323 - val_loss: 24.0616\n",
            "Epoch 3164/6000\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 23.1801 - val_loss: 23.9518\n",
            "Epoch 3165/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 22.9874 - val_loss: 24.2300\n",
            "Epoch 3166/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 23.1661 - val_loss: 24.1077\n",
            "Epoch 3167/6000\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 23.2545 - val_loss: 24.0749\n",
            "Epoch 3168/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 23.2765 - val_loss: 24.2984\n",
            "Epoch 3169/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 23.0121 - val_loss: 24.4012\n",
            "Epoch 3170/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 23.1229 - val_loss: 24.3403\n",
            "Epoch 3171/6000\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 23.0973 - val_loss: 24.0213\n",
            "Epoch 3172/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 23.1350 - val_loss: 24.0019\n",
            "Epoch 3173/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 23.4598 - val_loss: 24.4542\n",
            "Epoch 3174/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 23.1754 - val_loss: 24.6280\n",
            "Epoch 3175/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 22.9814 - val_loss: 24.1790\n",
            "Epoch 3176/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 23.2019 - val_loss: 23.9875\n",
            "Epoch 3177/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 22.9518 - val_loss: 24.1405\n",
            "Epoch 3178/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 22.9655 - val_loss: 23.9749\n",
            "Epoch 3179/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 22.8447 - val_loss: 24.1163\n",
            "Epoch 3180/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 22.8391 - val_loss: 24.0829\n",
            "Epoch 3181/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 22.9992 - val_loss: 24.2585\n",
            "Epoch 3182/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 22.9310 - val_loss: 24.0593\n",
            "Epoch 3183/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 22.7715 - val_loss: 24.2248\n",
            "Epoch 3184/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 23.0303 - val_loss: 24.0323\n",
            "Epoch 3185/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 23.0317 - val_loss: 24.1183\n",
            "Epoch 3186/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 22.8522 - val_loss: 23.9715\n",
            "Epoch 3187/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 22.8588 - val_loss: 23.9945\n",
            "Epoch 3188/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 22.8418 - val_loss: 23.9972\n",
            "Epoch 3189/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 22.7610 - val_loss: 24.0388\n",
            "Epoch 3190/6000\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 22.7617 - val_loss: 24.2175\n",
            "Epoch 3191/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 22.7362 - val_loss: 24.1353\n",
            "Epoch 3192/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 23.1873 - val_loss: 23.9906\n",
            "Epoch 3193/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 22.9937 - val_loss: 24.5303\n",
            "Epoch 3194/6000\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 23.0070 - val_loss: 24.2652\n",
            "Epoch 3195/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 22.9414 - val_loss: 24.4234\n",
            "Epoch 3196/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 22.6975 - val_loss: 24.1913\n",
            "Epoch 3197/6000\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 22.9512 - val_loss: 23.9461\n",
            "Epoch 3198/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 22.8662 - val_loss: 24.0112\n",
            "Epoch 3199/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 22.7726 - val_loss: 24.2545\n",
            "Epoch 3200/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 22.7921 - val_loss: 23.9766\n",
            "Epoch 3201/6000\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 23.0730 - val_loss: 24.0402\n",
            "Epoch 3202/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 22.9474 - val_loss: 24.0996\n",
            "Epoch 3203/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 23.0156 - val_loss: 24.1710\n",
            "Epoch 3204/6000\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 22.9019 - val_loss: 24.2263\n",
            "Epoch 3205/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 22.8907 - val_loss: 24.1125\n",
            "Epoch 3206/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 22.6562 - val_loss: 24.1434\n",
            "Epoch 3207/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 22.7117 - val_loss: 24.1535\n",
            "Epoch 3208/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 22.7553 - val_loss: 24.0277\n",
            "Epoch 3209/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 22.6327 - val_loss: 23.9682\n",
            "Epoch 3210/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 22.7174 - val_loss: 23.9295\n",
            "Epoch 3211/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 22.5757 - val_loss: 23.9202\n",
            "Epoch 3212/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 22.6260 - val_loss: 23.7085\n",
            "Epoch 3213/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 22.6683 - val_loss: 23.7745\n",
            "Epoch 3214/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 22.5839 - val_loss: 23.9361\n",
            "Epoch 3215/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 22.5746 - val_loss: 23.6974\n",
            "Epoch 3216/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 22.8112 - val_loss: 23.6137\n",
            "Epoch 3217/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 22.6259 - val_loss: 23.6714\n",
            "Epoch 3218/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 22.5371 - val_loss: 24.1132\n",
            "Epoch 3219/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 22.5555 - val_loss: 24.1487\n",
            "Epoch 3220/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 22.6405 - val_loss: 23.7765\n",
            "Epoch 3221/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 22.7079 - val_loss: 23.8111\n",
            "Epoch 3222/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 22.5045 - val_loss: 23.8914\n",
            "Epoch 3223/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 22.4700 - val_loss: 23.8354\n",
            "Epoch 3224/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 22.3636 - val_loss: 23.6737\n",
            "Epoch 3225/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 22.6102 - val_loss: 23.5661\n",
            "Epoch 3226/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 22.3467 - val_loss: 23.7186\n",
            "Epoch 3227/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 22.5992 - val_loss: 23.6002\n",
            "Epoch 3228/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 22.5149 - val_loss: 23.6837\n",
            "Epoch 3229/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 22.3979 - val_loss: 23.6520\n",
            "Epoch 3230/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 22.3525 - val_loss: 23.6331\n",
            "Epoch 3231/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 22.5432 - val_loss: 23.6219\n",
            "Epoch 3232/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 22.4220 - val_loss: 23.4342\n",
            "Epoch 3233/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 22.3447 - val_loss: 23.3439\n",
            "Epoch 3234/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 22.3409 - val_loss: 23.7065\n",
            "Epoch 3235/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 22.3411 - val_loss: 23.5121\n",
            "Epoch 3236/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 22.5112 - val_loss: 23.4808\n",
            "Epoch 3237/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 22.6593 - val_loss: 23.6668\n",
            "Epoch 3238/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 22.4733 - val_loss: 23.5191\n",
            "Epoch 3239/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 22.3822 - val_loss: 23.5594\n",
            "Epoch 3240/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 22.2788 - val_loss: 23.4957\n",
            "Epoch 3241/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 22.2543 - val_loss: 23.3882\n",
            "Epoch 3242/6000\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 22.3264 - val_loss: 23.6089\n",
            "Epoch 3243/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 22.2882 - val_loss: 23.6816\n",
            "Epoch 3244/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 22.2260 - val_loss: 23.4303\n",
            "Epoch 3245/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 22.3193 - val_loss: 23.4385\n",
            "Epoch 3246/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 22.1877 - val_loss: 23.4254\n",
            "Epoch 3247/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 22.2253 - val_loss: 23.6656\n",
            "Epoch 3248/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 22.2870 - val_loss: 23.5469\n",
            "Epoch 3249/6000\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 22.4426 - val_loss: 23.8845\n",
            "Epoch 3250/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 22.5142 - val_loss: 23.5367\n",
            "Epoch 3251/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 22.2178 - val_loss: 23.5103\n",
            "Epoch 3252/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 22.2588 - val_loss: 23.3653\n",
            "Epoch 3253/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 22.1700 - val_loss: 23.4633\n",
            "Epoch 3254/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 22.2156 - val_loss: 23.5143\n",
            "Epoch 3255/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 22.2778 - val_loss: 23.4746\n",
            "Epoch 3256/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 22.1530 - val_loss: 23.3393\n",
            "Epoch 3257/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 22.2405 - val_loss: 23.1927\n",
            "Epoch 3258/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 22.1037 - val_loss: 23.2715\n",
            "Epoch 3259/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 22.0786 - val_loss: 23.3466\n",
            "Epoch 3260/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 22.0721 - val_loss: 23.6271\n",
            "Epoch 3261/6000\n",
            "6/6 [==============================] - 0s 39ms/step - loss: 22.1611 - val_loss: 23.4092\n",
            "Epoch 3262/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 22.1072 - val_loss: 23.5631\n",
            "Epoch 3263/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 22.1714 - val_loss: 23.4319\n",
            "Epoch 3264/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 22.1217 - val_loss: 23.3363\n",
            "Epoch 3265/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 22.4074 - val_loss: 23.5823\n",
            "Epoch 3266/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 21.9601 - val_loss: 23.3957\n",
            "Epoch 3267/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 22.2123 - val_loss: 23.3358\n",
            "Epoch 3268/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 22.1852 - val_loss: 23.4267\n",
            "Epoch 3269/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 22.0502 - val_loss: 23.3428\n",
            "Epoch 3270/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 21.9416 - val_loss: 23.2431\n",
            "Epoch 3271/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 22.3087 - val_loss: 23.2777\n",
            "Epoch 3272/6000\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 22.0388 - val_loss: 23.2132\n",
            "Epoch 3273/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 22.0496 - val_loss: 22.9974\n",
            "Epoch 3274/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 22.0735 - val_loss: 23.4873\n",
            "Epoch 3275/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 22.0081 - val_loss: 23.2950\n",
            "Epoch 3276/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 22.1986 - val_loss: 23.3795\n",
            "Epoch 3277/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 22.1574 - val_loss: 23.3145\n",
            "Epoch 3278/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 22.0350 - val_loss: 23.2409\n",
            "Epoch 3279/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 21.9633 - val_loss: 23.5432\n",
            "Epoch 3280/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 22.1944 - val_loss: 23.2629\n",
            "Epoch 3281/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 22.0473 - val_loss: 23.3299\n",
            "Epoch 3282/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 22.1311 - val_loss: 23.5224\n",
            "Epoch 3283/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 22.0980 - val_loss: 23.5519\n",
            "Epoch 3284/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 22.1601 - val_loss: 23.3913\n",
            "Epoch 3285/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 22.0797 - val_loss: 23.5021\n",
            "Epoch 3286/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 21.9717 - val_loss: 23.4641\n",
            "Epoch 3287/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 22.1629 - val_loss: 23.3264\n",
            "Epoch 3288/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 21.8587 - val_loss: 23.0641\n",
            "Epoch 3289/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 22.0593 - val_loss: 23.0733\n",
            "Epoch 3290/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 22.0296 - val_loss: 23.3267\n",
            "Epoch 3291/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 21.8623 - val_loss: 23.0690\n",
            "Epoch 3292/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 22.1007 - val_loss: 23.0668\n",
            "Epoch 3293/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 21.8587 - val_loss: 23.1066\n",
            "Epoch 3294/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 21.8585 - val_loss: 22.8697\n",
            "Epoch 3295/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 21.6642 - val_loss: 22.8149\n",
            "Epoch 3296/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 22.0870 - val_loss: 22.9277\n",
            "Epoch 3297/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 21.8808 - val_loss: 22.8804\n",
            "Epoch 3298/6000\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 21.7022 - val_loss: 23.0252\n",
            "Epoch 3299/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 21.7739 - val_loss: 22.9512\n",
            "Epoch 3300/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 21.8920 - val_loss: 23.0555\n",
            "Epoch 3301/6000\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 21.9059 - val_loss: 22.9146\n",
            "Epoch 3302/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 21.6956 - val_loss: 23.0603\n",
            "Epoch 3303/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 21.6748 - val_loss: 23.0981\n",
            "Epoch 3304/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 21.8942 - val_loss: 23.5090\n",
            "Epoch 3305/6000\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 21.6611 - val_loss: 23.2282\n",
            "Epoch 3306/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 21.6791 - val_loss: 22.8955\n",
            "Epoch 3307/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 21.7386 - val_loss: 22.9507\n",
            "Epoch 3308/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 21.6872 - val_loss: 23.0663\n",
            "Epoch 3309/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 21.6099 - val_loss: 23.1436\n",
            "Epoch 3310/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 21.8490 - val_loss: 23.0621\n",
            "Epoch 3311/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 21.5930 - val_loss: 22.9441\n",
            "Epoch 3312/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 21.7119 - val_loss: 23.0220\n",
            "Epoch 3313/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 21.7466 - val_loss: 23.0611\n",
            "Epoch 3314/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 21.8132 - val_loss: 23.2381\n",
            "Epoch 3315/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 21.6291 - val_loss: 23.3631\n",
            "Epoch 3316/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 21.8478 - val_loss: 23.2423\n",
            "Epoch 3317/6000\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 21.6078 - val_loss: 23.3700\n",
            "Epoch 3318/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 21.5080 - val_loss: 23.3570\n",
            "Epoch 3319/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 21.6749 - val_loss: 22.9062\n",
            "Epoch 3320/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 21.6174 - val_loss: 22.8695\n",
            "Epoch 3321/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 21.4634 - val_loss: 22.7944\n",
            "Epoch 3322/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 21.5418 - val_loss: 22.6868\n",
            "Epoch 3323/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 21.4805 - val_loss: 22.6063\n",
            "Epoch 3324/6000\n",
            "6/6 [==============================] - 0s 39ms/step - loss: 21.4635 - val_loss: 23.0011\n",
            "Epoch 3325/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 21.4567 - val_loss: 22.6435\n",
            "Epoch 3326/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 21.4898 - val_loss: 22.7577\n",
            "Epoch 3327/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 21.5513 - val_loss: 22.5201\n",
            "Epoch 3328/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 21.3685 - val_loss: 22.6234\n",
            "Epoch 3329/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 21.3413 - val_loss: 22.3705\n",
            "Epoch 3330/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 21.3501 - val_loss: 22.5483\n",
            "Epoch 3331/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 21.4762 - val_loss: 22.5948\n",
            "Epoch 3332/6000\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 21.8568 - val_loss: 22.9283\n",
            "Epoch 3333/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 21.4015 - val_loss: 22.8728\n",
            "Epoch 3334/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 21.3389 - val_loss: 22.5426\n",
            "Epoch 3335/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 21.4003 - val_loss: 22.7096\n",
            "Epoch 3336/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 21.3583 - val_loss: 22.9114\n",
            "Epoch 3337/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 21.5530 - val_loss: 22.9014\n",
            "Epoch 3338/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 21.2653 - val_loss: 22.7944\n",
            "Epoch 3339/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 21.5063 - val_loss: 22.8898\n",
            "Epoch 3340/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 21.4005 - val_loss: 22.7803\n",
            "Epoch 3341/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 21.3959 - val_loss: 22.5451\n",
            "Epoch 3342/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 21.3262 - val_loss: 22.8104\n",
            "Epoch 3343/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 21.5376 - val_loss: 22.7469\n",
            "Epoch 3344/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 21.5924 - val_loss: 22.9481\n",
            "Epoch 3345/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 21.4919 - val_loss: 22.9618\n",
            "Epoch 3346/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 21.3650 - val_loss: 22.8371\n",
            "Epoch 3347/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 21.4803 - val_loss: 22.9231\n",
            "Epoch 3348/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 21.2744 - val_loss: 22.6366\n",
            "Epoch 3349/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 21.2983 - val_loss: 22.6782\n",
            "Epoch 3350/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 21.2809 - val_loss: 22.8801\n",
            "Epoch 3351/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 21.3428 - val_loss: 22.7476\n",
            "Epoch 3352/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 21.3390 - val_loss: 22.6465\n",
            "Epoch 3353/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 21.4109 - val_loss: 22.7658\n",
            "Epoch 3354/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 21.3961 - val_loss: 22.7153\n",
            "Epoch 3355/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 21.2448 - val_loss: 22.5265\n",
            "Epoch 3356/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 21.1869 - val_loss: 22.7011\n",
            "Epoch 3357/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 21.2978 - val_loss: 22.5563\n",
            "Epoch 3358/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 21.1717 - val_loss: 22.5155\n",
            "Epoch 3359/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 21.1092 - val_loss: 22.4052\n",
            "Epoch 3360/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 21.1195 - val_loss: 22.3968\n",
            "Epoch 3361/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 21.2442 - val_loss: 22.3548\n",
            "Epoch 3362/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 21.2786 - val_loss: 22.4509\n",
            "Epoch 3363/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 21.0412 - val_loss: 22.4533\n",
            "Epoch 3364/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 21.1984 - val_loss: 22.4542\n",
            "Epoch 3365/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 21.3403 - val_loss: 22.5465\n",
            "Epoch 3366/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 21.2646 - val_loss: 22.6146\n",
            "Epoch 3367/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 21.4881 - val_loss: 22.7399\n",
            "Epoch 3368/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 21.0991 - val_loss: 22.5482\n",
            "Epoch 3369/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 21.1648 - val_loss: 22.4117\n",
            "Epoch 3370/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 21.0923 - val_loss: 22.5002\n",
            "Epoch 3371/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 21.0778 - val_loss: 22.4614\n",
            "Epoch 3372/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 21.1171 - val_loss: 22.2230\n",
            "Epoch 3373/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 21.1098 - val_loss: 22.3176\n",
            "Epoch 3374/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 21.0729 - val_loss: 22.3659\n",
            "Epoch 3375/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 21.0570 - val_loss: 22.4820\n",
            "Epoch 3376/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 21.1532 - val_loss: 22.4743\n",
            "Epoch 3377/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 21.0685 - val_loss: 22.5879\n",
            "Epoch 3378/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 21.0160 - val_loss: 22.4331\n",
            "Epoch 3379/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 20.8894 - val_loss: 22.2179\n",
            "Epoch 3380/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 21.1285 - val_loss: 22.1423\n",
            "Epoch 3381/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 20.9272 - val_loss: 22.1989\n",
            "Epoch 3382/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 20.9672 - val_loss: 22.3712\n",
            "Epoch 3383/6000\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 20.9400 - val_loss: 22.1741\n",
            "Epoch 3384/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 20.9675 - val_loss: 22.1945\n",
            "Epoch 3385/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 20.9946 - val_loss: 22.3446\n",
            "Epoch 3386/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 21.0089 - val_loss: 22.2841\n",
            "Epoch 3387/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 20.9250 - val_loss: 22.2618\n",
            "Epoch 3388/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 21.1135 - val_loss: 22.5201\n",
            "Epoch 3389/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 21.0278 - val_loss: 22.6316\n",
            "Epoch 3390/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 20.8721 - val_loss: 22.2649\n",
            "Epoch 3391/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 20.8007 - val_loss: 22.2278\n",
            "Epoch 3392/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 20.7565 - val_loss: 22.0022\n",
            "Epoch 3393/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 20.8425 - val_loss: 22.0092\n",
            "Epoch 3394/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 20.9257 - val_loss: 22.2948\n",
            "Epoch 3395/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 20.8348 - val_loss: 22.1914\n",
            "Epoch 3396/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 20.8554 - val_loss: 22.4071\n",
            "Epoch 3397/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 21.1415 - val_loss: 22.1964\n",
            "Epoch 3398/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 20.9678 - val_loss: 22.0820\n",
            "Epoch 3399/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 20.8475 - val_loss: 21.9508\n",
            "Epoch 3400/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 21.0853 - val_loss: 22.1257\n",
            "Epoch 3401/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 20.9137 - val_loss: 22.0520\n",
            "Epoch 3402/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 20.8582 - val_loss: 22.2107\n",
            "Epoch 3403/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 20.7074 - val_loss: 22.1386\n",
            "Epoch 3404/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 20.6382 - val_loss: 21.9858\n",
            "Epoch 3405/6000\n",
            "6/6 [==============================] - 0s 39ms/step - loss: 20.6400 - val_loss: 22.2617\n",
            "Epoch 3406/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 20.6910 - val_loss: 22.0805\n",
            "Epoch 3407/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 20.9614 - val_loss: 22.1237\n",
            "Epoch 3408/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 20.6267 - val_loss: 22.1605\n",
            "Epoch 3409/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 20.7880 - val_loss: 22.1837\n",
            "Epoch 3410/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 20.8232 - val_loss: 22.1108\n",
            "Epoch 3411/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 20.9764 - val_loss: 22.0524\n",
            "Epoch 3412/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 20.7632 - val_loss: 22.4137\n",
            "Epoch 3413/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 20.8160 - val_loss: 22.1546\n",
            "Epoch 3414/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 20.7191 - val_loss: 21.9090\n",
            "Epoch 3415/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 20.7772 - val_loss: 21.8672\n",
            "Epoch 3416/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 20.7266 - val_loss: 21.8635\n",
            "Epoch 3417/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 20.7473 - val_loss: 22.3512\n",
            "Epoch 3418/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 20.8031 - val_loss: 22.1415\n",
            "Epoch 3419/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 20.6925 - val_loss: 22.0324\n",
            "Epoch 3420/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 20.6602 - val_loss: 22.2896\n",
            "Epoch 3421/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 20.6571 - val_loss: 22.0327\n",
            "Epoch 3422/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 20.4992 - val_loss: 21.9021\n",
            "Epoch 3423/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 20.5932 - val_loss: 21.8441\n",
            "Epoch 3424/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 20.6110 - val_loss: 22.1369\n",
            "Epoch 3425/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 20.4717 - val_loss: 22.1557\n",
            "Epoch 3426/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 20.5723 - val_loss: 22.2475\n",
            "Epoch 3427/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 20.4587 - val_loss: 21.9069\n",
            "Epoch 3428/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 20.6820 - val_loss: 21.7287\n",
            "Epoch 3429/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 20.3888 - val_loss: 21.7142\n",
            "Epoch 3430/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 20.8537 - val_loss: 21.8600\n",
            "Epoch 3431/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 20.6326 - val_loss: 21.9240\n",
            "Epoch 3432/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 20.5114 - val_loss: 22.0267\n",
            "Epoch 3433/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 20.6650 - val_loss: 21.7057\n",
            "Epoch 3434/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 20.4796 - val_loss: 21.7248\n",
            "Epoch 3435/6000\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 20.6995 - val_loss: 21.5171\n",
            "Epoch 3436/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 20.6928 - val_loss: 21.6665\n",
            "Epoch 3437/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 20.6131 - val_loss: 21.5711\n",
            "Epoch 3438/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 20.3699 - val_loss: 21.6324\n",
            "Epoch 3439/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 20.4411 - val_loss: 21.5793\n",
            "Epoch 3440/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 20.4958 - val_loss: 21.7215\n",
            "Epoch 3441/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 20.3946 - val_loss: 21.7186\n",
            "Epoch 3442/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 20.5455 - val_loss: 21.7058\n",
            "Epoch 3443/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 20.5776 - val_loss: 21.9953\n",
            "Epoch 3444/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 20.6451 - val_loss: 21.7453\n",
            "Epoch 3445/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 20.7522 - val_loss: 22.0367\n",
            "Epoch 3446/6000\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 20.5567 - val_loss: 21.8922\n",
            "Epoch 3447/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 20.4297 - val_loss: 21.7186\n",
            "Epoch 3448/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 20.3254 - val_loss: 21.6903\n",
            "Epoch 3449/6000\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 20.3089 - val_loss: 21.8385\n",
            "Epoch 3450/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 20.2903 - val_loss: 21.6952\n",
            "Epoch 3451/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 20.5104 - val_loss: 21.5703\n",
            "Epoch 3452/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 20.2521 - val_loss: 21.7415\n",
            "Epoch 3453/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 20.7534 - val_loss: 21.4600\n",
            "Epoch 3454/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 20.4694 - val_loss: 21.9782\n",
            "Epoch 3455/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 20.4868 - val_loss: 21.9174\n",
            "Epoch 3456/6000\n",
            "6/6 [==============================] - 0s 41ms/step - loss: 20.3260 - val_loss: 21.6404\n",
            "Epoch 3457/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 20.2517 - val_loss: 21.8022\n",
            "Epoch 3458/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 20.2967 - val_loss: 22.0192\n",
            "Epoch 3459/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 20.2563 - val_loss: 21.9142\n",
            "Epoch 3460/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 20.2922 - val_loss: 21.6257\n",
            "Epoch 3461/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 20.3577 - val_loss: 21.8812\n",
            "Epoch 3462/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 20.3297 - val_loss: 21.9905\n",
            "Epoch 3463/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 20.5235 - val_loss: 21.9547\n",
            "Epoch 3464/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 20.0904 - val_loss: 21.7379\n",
            "Epoch 3465/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 20.0894 - val_loss: 21.6000\n",
            "Epoch 3466/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 20.1505 - val_loss: 21.5756\n",
            "Epoch 3467/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 20.4007 - val_loss: 21.4421\n",
            "Epoch 3468/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 20.1912 - val_loss: 21.7150\n",
            "Epoch 3469/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 20.2441 - val_loss: 21.5890\n",
            "Epoch 3470/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 20.2663 - val_loss: 21.4049\n",
            "Epoch 3471/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 20.1365 - val_loss: 21.4055\n",
            "Epoch 3472/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 20.4977 - val_loss: 21.5594\n",
            "Epoch 3473/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 20.2298 - val_loss: 21.6564\n",
            "Epoch 3474/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 20.1463 - val_loss: 21.5923\n",
            "Epoch 3475/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 20.3068 - val_loss: 21.4003\n",
            "Epoch 3476/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 20.2331 - val_loss: 21.4280\n",
            "Epoch 3477/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 20.3257 - val_loss: 21.3089\n",
            "Epoch 3478/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 20.2101 - val_loss: 21.8050\n",
            "Epoch 3479/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 20.2884 - val_loss: 21.6630\n",
            "Epoch 3480/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 20.2351 - val_loss: 21.8449\n",
            "Epoch 3481/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 20.0600 - val_loss: 21.7984\n",
            "Epoch 3482/6000\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 20.1290 - val_loss: 21.7642\n",
            "Epoch 3483/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 20.0426 - val_loss: 21.5269\n",
            "Epoch 3484/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 20.3199 - val_loss: 21.5014\n",
            "Epoch 3485/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 20.0091 - val_loss: 21.7330\n",
            "Epoch 3486/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 20.2257 - val_loss: 21.8846\n",
            "Epoch 3487/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 20.1910 - val_loss: 21.3813\n",
            "Epoch 3488/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 20.1179 - val_loss: 21.5709\n",
            "Epoch 3489/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 20.1127 - val_loss: 21.7361\n",
            "Epoch 3490/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 20.1263 - val_loss: 21.7747\n",
            "Epoch 3491/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 20.1218 - val_loss: 21.7519\n",
            "Epoch 3492/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 20.0321 - val_loss: 21.4141\n",
            "Epoch 3493/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 20.1460 - val_loss: 21.1271\n",
            "Epoch 3494/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 20.1265 - val_loss: 21.4247\n",
            "Epoch 3495/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 20.0176 - val_loss: 21.3879\n",
            "Epoch 3496/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 20.1123 - val_loss: 21.2937\n",
            "Epoch 3497/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 20.3007 - val_loss: 21.9440\n",
            "Epoch 3498/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 20.0341 - val_loss: 21.4738\n",
            "Epoch 3499/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 20.1798 - val_loss: 21.3645\n",
            "Epoch 3500/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 19.9119 - val_loss: 21.2370\n",
            "Epoch 3501/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 19.8854 - val_loss: 21.2930\n",
            "Epoch 3502/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 19.9059 - val_loss: 21.3846\n",
            "Epoch 3503/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 19.9716 - val_loss: 21.2137\n",
            "Epoch 3504/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 20.0704 - val_loss: 21.3754\n",
            "Epoch 3505/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 19.9506 - val_loss: 21.1409\n",
            "Epoch 3506/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 20.0196 - val_loss: 21.3037\n",
            "Epoch 3507/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 19.9398 - val_loss: 21.1482\n",
            "Epoch 3508/6000\n",
            "6/6 [==============================] - 0s 41ms/step - loss: 19.9541 - val_loss: 20.9997\n",
            "Epoch 3509/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 20.1432 - val_loss: 21.2926\n",
            "Epoch 3510/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 19.8956 - val_loss: 21.1597\n",
            "Epoch 3511/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 19.8353 - val_loss: 21.0277\n",
            "Epoch 3512/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 20.0094 - val_loss: 21.0694\n",
            "Epoch 3513/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 19.7621 - val_loss: 21.2550\n",
            "Epoch 3514/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 19.8870 - val_loss: 21.1678\n",
            "Epoch 3515/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 19.9558 - val_loss: 21.2525\n",
            "Epoch 3516/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 19.7747 - val_loss: 21.2126\n",
            "Epoch 3517/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 19.7498 - val_loss: 21.2104\n",
            "Epoch 3518/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 19.7943 - val_loss: 21.4165\n",
            "Epoch 3519/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 19.9173 - val_loss: 21.0257\n",
            "Epoch 3520/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 20.0668 - val_loss: 21.2015\n",
            "Epoch 3521/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 19.9126 - val_loss: 21.0740\n",
            "Epoch 3522/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 19.9519 - val_loss: 20.8694\n",
            "Epoch 3523/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 19.7701 - val_loss: 21.2722\n",
            "Epoch 3524/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 19.6905 - val_loss: 21.0431\n",
            "Epoch 3525/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 19.7521 - val_loss: 21.1281\n",
            "Epoch 3526/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 19.8197 - val_loss: 21.1710\n",
            "Epoch 3527/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 20.0447 - val_loss: 21.2095\n",
            "Epoch 3528/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 19.8572 - val_loss: 21.2626\n",
            "Epoch 3529/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 19.6877 - val_loss: 20.9401\n",
            "Epoch 3530/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 19.9759 - val_loss: 21.3597\n",
            "Epoch 3531/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 19.7463 - val_loss: 20.9693\n",
            "Epoch 3532/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 19.6090 - val_loss: 21.0607\n",
            "Epoch 3533/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 19.6197 - val_loss: 20.8181\n",
            "Epoch 3534/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 19.6600 - val_loss: 20.9248\n",
            "Epoch 3535/6000\n",
            "6/6 [==============================] - 0s 41ms/step - loss: 19.5676 - val_loss: 20.9227\n",
            "Epoch 3536/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 19.6632 - val_loss: 20.9596\n",
            "Epoch 3537/6000\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 19.6657 - val_loss: 20.9785\n",
            "Epoch 3538/6000\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 19.5575 - val_loss: 20.9216\n",
            "Epoch 3539/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 19.5722 - val_loss: 20.9468\n",
            "Epoch 3540/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 19.6737 - val_loss: 20.9679\n",
            "Epoch 3541/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 19.4431 - val_loss: 20.9512\n",
            "Epoch 3542/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 19.4757 - val_loss: 20.9293\n",
            "Epoch 3543/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 19.5466 - val_loss: 21.1470\n",
            "Epoch 3544/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 19.4973 - val_loss: 21.0417\n",
            "Epoch 3545/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 19.5376 - val_loss: 20.9162\n",
            "Epoch 3546/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 19.5758 - val_loss: 21.0490\n",
            "Epoch 3547/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 19.6168 - val_loss: 21.0327\n",
            "Epoch 3548/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 19.5287 - val_loss: 20.9173\n",
            "Epoch 3549/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 19.7729 - val_loss: 20.7356\n",
            "Epoch 3550/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 19.4667 - val_loss: 20.7560\n",
            "Epoch 3551/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 19.4835 - val_loss: 20.6810\n",
            "Epoch 3552/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 19.4703 - val_loss: 20.7691\n",
            "Epoch 3553/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 19.4368 - val_loss: 20.7701\n",
            "Epoch 3554/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 19.5054 - val_loss: 20.8600\n",
            "Epoch 3555/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 19.4555 - val_loss: 20.7870\n",
            "Epoch 3556/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 19.3946 - val_loss: 20.9341\n",
            "Epoch 3557/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 19.6370 - val_loss: 21.0756\n",
            "Epoch 3558/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 19.4284 - val_loss: 20.7822\n",
            "Epoch 3559/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 19.3279 - val_loss: 20.7256\n",
            "Epoch 3560/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 19.3371 - val_loss: 20.8278\n",
            "Epoch 3561/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 19.3354 - val_loss: 20.5915\n",
            "Epoch 3562/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 19.4301 - val_loss: 20.6720\n",
            "Epoch 3563/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 19.3738 - val_loss: 20.7537\n",
            "Epoch 3564/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 19.3468 - val_loss: 20.6625\n",
            "Epoch 3565/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 19.4099 - val_loss: 20.5771\n",
            "Epoch 3566/6000\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 19.3511 - val_loss: 20.7088\n",
            "Epoch 3567/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 19.4010 - val_loss: 20.6090\n",
            "Epoch 3568/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 19.2362 - val_loss: 20.7200\n",
            "Epoch 3569/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 19.4603 - val_loss: 20.7404\n",
            "Epoch 3570/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 19.2922 - val_loss: 20.7085\n",
            "Epoch 3571/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 19.4657 - val_loss: 20.8868\n",
            "Epoch 3572/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 19.4732 - val_loss: 21.0373\n",
            "Epoch 3573/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 19.3985 - val_loss: 21.0071\n",
            "Epoch 3574/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 19.3710 - val_loss: 20.8524\n",
            "Epoch 3575/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 19.1824 - val_loss: 20.7941\n",
            "Epoch 3576/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 19.6652 - val_loss: 20.5511\n",
            "Epoch 3577/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 19.4596 - val_loss: 20.9962\n",
            "Epoch 3578/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 19.4738 - val_loss: 20.8199\n",
            "Epoch 3579/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 19.4259 - val_loss: 21.1123\n",
            "Epoch 3580/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 19.3892 - val_loss: 21.1475\n",
            "Epoch 3581/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 19.3466 - val_loss: 21.3706\n",
            "Epoch 3582/6000\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 19.5595 - val_loss: 21.1391\n",
            "Epoch 3583/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 19.3146 - val_loss: 20.8785\n",
            "Epoch 3584/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 19.2086 - val_loss: 20.7498\n",
            "Epoch 3585/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 19.3351 - val_loss: 20.6376\n",
            "Epoch 3586/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 19.3415 - val_loss: 20.7722\n",
            "Epoch 3587/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 19.2607 - val_loss: 20.7086\n",
            "Epoch 3588/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 19.1468 - val_loss: 20.7299\n",
            "Epoch 3589/6000\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 19.1543 - val_loss: 20.8190\n",
            "Epoch 3590/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 19.2423 - val_loss: 20.7051\n",
            "Epoch 3591/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 19.1159 - val_loss: 20.5091\n",
            "Epoch 3592/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 19.0819 - val_loss: 20.4374\n",
            "Epoch 3593/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 19.3001 - val_loss: 20.6689\n",
            "Epoch 3594/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 19.1140 - val_loss: 20.9891\n",
            "Epoch 3595/6000\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 19.1099 - val_loss: 20.7564\n",
            "Epoch 3596/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 19.0905 - val_loss: 20.6548\n",
            "Epoch 3597/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 19.2545 - val_loss: 21.0343\n",
            "Epoch 3598/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 19.2391 - val_loss: 21.2795\n",
            "Epoch 3599/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 19.2390 - val_loss: 20.8109\n",
            "Epoch 3600/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 19.1170 - val_loss: 20.8723\n",
            "Epoch 3601/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 19.1138 - val_loss: 20.8128\n",
            "Epoch 3602/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 19.1642 - val_loss: 20.6260\n",
            "Epoch 3603/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 19.1889 - val_loss: 20.6979\n",
            "Epoch 3604/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 19.1707 - val_loss: 20.6810\n",
            "Epoch 3605/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 18.9927 - val_loss: 20.4928\n",
            "Epoch 3606/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 19.1011 - val_loss: 20.5674\n",
            "Epoch 3607/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 19.1162 - val_loss: 20.6093\n",
            "Epoch 3608/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 19.1607 - val_loss: 20.7046\n",
            "Epoch 3609/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 19.1716 - val_loss: 21.0294\n",
            "Epoch 3610/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 19.1427 - val_loss: 21.2796\n",
            "Epoch 3611/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 18.9829 - val_loss: 20.7127\n",
            "Epoch 3612/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 18.9535 - val_loss: 20.4730\n",
            "Epoch 3613/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 18.8790 - val_loss: 20.3115\n",
            "Epoch 3614/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 18.8931 - val_loss: 20.3551\n",
            "Epoch 3615/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 18.8681 - val_loss: 20.4122\n",
            "Epoch 3616/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 19.0257 - val_loss: 20.5927\n",
            "Epoch 3617/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 19.0450 - val_loss: 20.6152\n",
            "Epoch 3618/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 19.0412 - val_loss: 20.4969\n",
            "Epoch 3619/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 19.1276 - val_loss: 20.4176\n",
            "Epoch 3620/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 18.9284 - val_loss: 20.2637\n",
            "Epoch 3621/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 18.8913 - val_loss: 20.4245\n",
            "Epoch 3622/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 18.9261 - val_loss: 20.3786\n",
            "Epoch 3623/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 18.8635 - val_loss: 20.2910\n",
            "Epoch 3624/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 18.9558 - val_loss: 20.2282\n",
            "Epoch 3625/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 19.0066 - val_loss: 20.5226\n",
            "Epoch 3626/6000\n",
            "6/6 [==============================] - 0s 39ms/step - loss: 19.0773 - val_loss: 20.4015\n",
            "Epoch 3627/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 19.1560 - val_loss: 20.6372\n",
            "Epoch 3628/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 18.8994 - val_loss: 20.5776\n",
            "Epoch 3629/6000\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 18.8332 - val_loss: 20.5915\n",
            "Epoch 3630/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 18.8978 - val_loss: 20.6148\n",
            "Epoch 3631/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 18.7594 - val_loss: 20.3067\n",
            "Epoch 3632/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 18.9232 - val_loss: 20.2970\n",
            "Epoch 3633/6000\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 18.8038 - val_loss: 20.1830\n",
            "Epoch 3634/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 18.8773 - val_loss: 20.3927\n",
            "Epoch 3635/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 18.8980 - val_loss: 20.5175\n",
            "Epoch 3636/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 18.9751 - val_loss: 20.3878\n",
            "Epoch 3637/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 18.8018 - val_loss: 20.5531\n",
            "Epoch 3638/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 18.8921 - val_loss: 20.4569\n",
            "Epoch 3639/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 18.7176 - val_loss: 20.4636\n",
            "Epoch 3640/6000\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 18.9400 - val_loss: 20.4003\n",
            "Epoch 3641/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 18.8367 - val_loss: 20.2618\n",
            "Epoch 3642/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 18.9422 - val_loss: 20.4416\n",
            "Epoch 3643/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 18.9821 - val_loss: 20.5672\n",
            "Epoch 3644/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 18.7459 - val_loss: 20.4897\n",
            "Epoch 3645/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 18.7803 - val_loss: 20.3247\n",
            "Epoch 3646/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 18.8475 - val_loss: 20.2997\n",
            "Epoch 3647/6000\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 18.8599 - val_loss: 20.0855\n",
            "Epoch 3648/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 18.7991 - val_loss: 20.0174\n",
            "Epoch 3649/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 18.8011 - val_loss: 19.9043\n",
            "Epoch 3650/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 18.9088 - val_loss: 19.8864\n",
            "Epoch 3651/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 18.5721 - val_loss: 20.0865\n",
            "Epoch 3652/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 18.9115 - val_loss: 20.4313\n",
            "Epoch 3653/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 18.7390 - val_loss: 20.1521\n",
            "Epoch 3654/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 18.7051 - val_loss: 20.0425\n",
            "Epoch 3655/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 18.6847 - val_loss: 19.9205\n",
            "Epoch 3656/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 18.6677 - val_loss: 19.9051\n",
            "Epoch 3657/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 18.6478 - val_loss: 20.1628\n",
            "Epoch 3658/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 18.7959 - val_loss: 20.2702\n",
            "Epoch 3659/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 18.7719 - val_loss: 20.2441\n",
            "Epoch 3660/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 18.7722 - val_loss: 20.0173\n",
            "Epoch 3661/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 18.5493 - val_loss: 20.0569\n",
            "Epoch 3662/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 18.6565 - val_loss: 20.0751\n",
            "Epoch 3663/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 18.8062 - val_loss: 20.1327\n",
            "Epoch 3664/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 18.5801 - val_loss: 20.2476\n",
            "Epoch 3665/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 18.7861 - val_loss: 20.1731\n",
            "Epoch 3666/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 18.7399 - val_loss: 20.0745\n",
            "Epoch 3667/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 18.7718 - val_loss: 19.8557\n",
            "Epoch 3668/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 18.6707 - val_loss: 19.9900\n",
            "Epoch 3669/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 18.6143 - val_loss: 20.0580\n",
            "Epoch 3670/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 18.5498 - val_loss: 19.9554\n",
            "Epoch 3671/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 18.5521 - val_loss: 20.1243\n",
            "Epoch 3672/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 18.6467 - val_loss: 20.3945\n",
            "Epoch 3673/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 18.6268 - val_loss: 20.2689\n",
            "Epoch 3674/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 18.4384 - val_loss: 20.3664\n",
            "Epoch 3675/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 18.5923 - val_loss: 20.0104\n",
            "Epoch 3676/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 18.4458 - val_loss: 20.0042\n",
            "Epoch 3677/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 18.3413 - val_loss: 19.9096\n",
            "Epoch 3678/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 18.4447 - val_loss: 19.6954\n",
            "Epoch 3679/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 18.6188 - val_loss: 19.9986\n",
            "Epoch 3680/6000\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 18.4417 - val_loss: 20.1240\n",
            "Epoch 3681/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 18.6225 - val_loss: 19.9790\n",
            "Epoch 3682/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 18.6132 - val_loss: 20.1499\n",
            "Epoch 3683/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 18.7537 - val_loss: 19.8293\n",
            "Epoch 3684/6000\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 18.7424 - val_loss: 20.0231\n",
            "Epoch 3685/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 18.6405 - val_loss: 19.9274\n",
            "Epoch 3686/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 18.6289 - val_loss: 20.2733\n",
            "Epoch 3687/6000\n",
            "6/6 [==============================] - 0s 42ms/step - loss: 18.3623 - val_loss: 20.1894\n",
            "Epoch 3688/6000\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 18.4397 - val_loss: 19.9834\n",
            "Epoch 3689/6000\n",
            "6/6 [==============================] - 0s 78ms/step - loss: 18.3700 - val_loss: 20.1095\n",
            "Epoch 3690/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 18.4104 - val_loss: 19.9958\n",
            "Epoch 3691/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 18.4817 - val_loss: 20.3013\n",
            "Epoch 3692/6000\n",
            "6/6 [==============================] - 0s 40ms/step - loss: 18.2647 - val_loss: 20.1817\n",
            "Epoch 3693/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 18.4255 - val_loss: 20.0060\n",
            "Epoch 3694/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 18.5375 - val_loss: 19.7715\n",
            "Epoch 3695/6000\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 18.5680 - val_loss: 19.9369\n",
            "Epoch 3696/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 18.5522 - val_loss: 19.6669\n",
            "Epoch 3697/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 18.5685 - val_loss: 20.0437\n",
            "Epoch 3698/6000\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 18.4672 - val_loss: 19.8859\n",
            "Epoch 3699/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 18.7836 - val_loss: 20.0427\n",
            "Epoch 3700/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 18.3474 - val_loss: 19.8236\n",
            "Epoch 3701/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 18.4353 - val_loss: 19.9128\n",
            "Epoch 3702/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 18.6312 - val_loss: 20.0142\n",
            "Epoch 3703/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 18.2573 - val_loss: 19.7447\n",
            "Epoch 3704/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 18.3884 - val_loss: 19.7636\n",
            "Epoch 3705/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 18.2498 - val_loss: 20.0354\n",
            "Epoch 3706/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 18.2782 - val_loss: 20.1103\n",
            "Epoch 3707/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 18.2957 - val_loss: 20.0710\n",
            "Epoch 3708/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 18.3390 - val_loss: 20.3214\n",
            "Epoch 3709/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 18.2495 - val_loss: 19.8215\n",
            "Epoch 3710/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 18.3339 - val_loss: 19.7153\n",
            "Epoch 3711/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 18.4153 - val_loss: 20.0414\n",
            "Epoch 3712/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 18.1008 - val_loss: 20.0810\n",
            "Epoch 3713/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 18.2139 - val_loss: 20.0409\n",
            "Epoch 3714/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 18.1558 - val_loss: 20.0054\n",
            "Epoch 3715/6000\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 18.1690 - val_loss: 19.8387\n",
            "Epoch 3716/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 18.2010 - val_loss: 19.8990\n",
            "Epoch 3717/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 18.1723 - val_loss: 19.9130\n",
            "Epoch 3718/6000\n",
            "6/6 [==============================] - 0s 39ms/step - loss: 18.2826 - val_loss: 19.5898\n",
            "Epoch 3719/6000\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 18.1291 - val_loss: 19.7795\n",
            "Epoch 3720/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 18.3818 - val_loss: 19.6083\n",
            "Epoch 3721/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 18.2130 - val_loss: 19.6223\n",
            "Epoch 3722/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 18.3610 - val_loss: 19.8871\n",
            "Epoch 3723/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 18.4138 - val_loss: 19.9940\n",
            "Epoch 3724/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 18.2480 - val_loss: 19.8405\n",
            "Epoch 3725/6000\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 18.1780 - val_loss: 19.6420\n",
            "Epoch 3726/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 18.0437 - val_loss: 19.6425\n",
            "Epoch 3727/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 18.0915 - val_loss: 19.5257\n",
            "Epoch 3728/6000\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 18.4935 - val_loss: 19.5538\n",
            "Epoch 3729/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 18.1390 - val_loss: 19.6319\n",
            "Epoch 3730/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 18.1865 - val_loss: 19.4500\n",
            "Epoch 3731/6000\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 18.1261 - val_loss: 19.3406\n",
            "Epoch 3732/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 18.0828 - val_loss: 19.4133\n",
            "Epoch 3733/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 18.1215 - val_loss: 19.4431\n",
            "Epoch 3734/6000\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 18.1012 - val_loss: 19.6089\n",
            "Epoch 3735/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 18.1403 - val_loss: 19.5498\n",
            "Epoch 3736/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 18.1733 - val_loss: 19.6466\n",
            "Epoch 3737/6000\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 18.3756 - val_loss: 19.5704\n",
            "Epoch 3738/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 17.9737 - val_loss: 19.5303\n",
            "Epoch 3739/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 18.0277 - val_loss: 19.3335\n",
            "Epoch 3740/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 18.3350 - val_loss: 19.7288\n",
            "Epoch 3741/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 18.1881 - val_loss: 19.5424\n",
            "Epoch 3742/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 18.0751 - val_loss: 19.8873\n",
            "Epoch 3743/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 18.3252 - val_loss: 19.7526\n",
            "Epoch 3744/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 18.1349 - val_loss: 19.5376\n",
            "Epoch 3745/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 17.9900 - val_loss: 19.7362\n",
            "Epoch 3746/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 18.2330 - val_loss: 19.7807\n",
            "Epoch 3747/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 18.1917 - val_loss: 19.6570\n",
            "Epoch 3748/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 18.1447 - val_loss: 19.5934\n",
            "Epoch 3749/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 18.0288 - val_loss: 19.9063\n",
            "Epoch 3750/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 17.9616 - val_loss: 20.1471\n",
            "Epoch 3751/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 18.1282 - val_loss: 19.6483\n",
            "Epoch 3752/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 17.9857 - val_loss: 19.6842\n",
            "Epoch 3753/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 17.9475 - val_loss: 19.4914\n",
            "Epoch 3754/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 18.1979 - val_loss: 19.4943\n",
            "Epoch 3755/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 17.9807 - val_loss: 19.1641\n",
            "Epoch 3756/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 17.8624 - val_loss: 19.4063\n",
            "Epoch 3757/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 17.9439 - val_loss: 19.3586\n",
            "Epoch 3758/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 18.0608 - val_loss: 19.4720\n",
            "Epoch 3759/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 17.7794 - val_loss: 19.3224\n",
            "Epoch 3760/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 17.7847 - val_loss: 19.2713\n",
            "Epoch 3761/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 17.9161 - val_loss: 19.3386\n",
            "Epoch 3762/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 17.8352 - val_loss: 19.5347\n",
            "Epoch 3763/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 18.2153 - val_loss: 19.3417\n",
            "Epoch 3764/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 18.0418 - val_loss: 19.8608\n",
            "Epoch 3765/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 18.1601 - val_loss: 19.6931\n",
            "Epoch 3766/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 17.8712 - val_loss: 20.0392\n",
            "Epoch 3767/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 17.9619 - val_loss: 19.8055\n",
            "Epoch 3768/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 18.0715 - val_loss: 19.4292\n",
            "Epoch 3769/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 17.7289 - val_loss: 19.4330\n",
            "Epoch 3770/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 18.0389 - val_loss: 19.3540\n",
            "Epoch 3771/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 18.0697 - val_loss: 19.3325\n",
            "Epoch 3772/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 17.8234 - val_loss: 19.2094\n",
            "Epoch 3773/6000\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 17.8162 - val_loss: 19.2707\n",
            "Epoch 3774/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 18.0201 - val_loss: 19.7730\n",
            "Epoch 3775/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 17.9786 - val_loss: 19.6857\n",
            "Epoch 3776/6000\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 17.7607 - val_loss: 19.5334\n",
            "Epoch 3777/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 18.3551 - val_loss: 19.3330\n",
            "Epoch 3778/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 17.7374 - val_loss: 19.4206\n",
            "Epoch 3779/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 17.7937 - val_loss: 19.3314\n",
            "Epoch 3780/6000\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 17.6466 - val_loss: 19.3446\n",
            "Epoch 3781/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 17.7070 - val_loss: 19.2012\n",
            "Epoch 3782/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 17.6911 - val_loss: 19.3235\n",
            "Epoch 3783/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 17.8494 - val_loss: 19.3780\n",
            "Epoch 3784/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 17.7482 - val_loss: 19.2744\n",
            "Epoch 3785/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 17.7581 - val_loss: 19.1101\n",
            "Epoch 3786/6000\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 17.6807 - val_loss: 19.1224\n",
            "Epoch 3787/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 17.6714 - val_loss: 18.9358\n",
            "Epoch 3788/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 17.6974 - val_loss: 19.0475\n",
            "Epoch 3789/6000\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 17.5968 - val_loss: 18.9617\n",
            "Epoch 3790/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 17.6298 - val_loss: 19.2524\n",
            "Epoch 3791/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 17.8646 - val_loss: 19.2086\n",
            "Epoch 3792/6000\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 17.5339 - val_loss: 19.0330\n",
            "Epoch 3793/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 17.7965 - val_loss: 19.2257\n",
            "Epoch 3794/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 17.6705 - val_loss: 19.2758\n",
            "Epoch 3795/6000\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 17.6417 - val_loss: 19.0562\n",
            "Epoch 3796/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 17.7975 - val_loss: 19.2340\n",
            "Epoch 3797/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 17.5971 - val_loss: 18.9021\n",
            "Epoch 3798/6000\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 17.7912 - val_loss: 19.0289\n",
            "Epoch 3799/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 17.6676 - val_loss: 18.9671\n",
            "Epoch 3800/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 17.6265 - val_loss: 19.0103\n",
            "Epoch 3801/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 17.5333 - val_loss: 18.9511\n",
            "Epoch 3802/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 17.6928 - val_loss: 19.0970\n",
            "Epoch 3803/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 17.6359 - val_loss: 19.3161\n",
            "Epoch 3804/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 17.7097 - val_loss: 19.4110\n",
            "Epoch 3805/6000\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 17.5114 - val_loss: 19.1864\n",
            "Epoch 3806/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 17.6126 - val_loss: 19.2027\n",
            "Epoch 3807/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 17.5471 - val_loss: 19.2095\n",
            "Epoch 3808/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 17.8931 - val_loss: 19.3673\n",
            "Epoch 3809/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 17.5695 - val_loss: 19.2558\n",
            "Epoch 3810/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 17.6266 - val_loss: 19.3697\n",
            "Epoch 3811/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 17.6416 - val_loss: 19.2973\n",
            "Epoch 3812/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 17.6198 - val_loss: 19.5678\n",
            "Epoch 3813/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 17.4963 - val_loss: 19.4232\n",
            "Epoch 3814/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 17.4341 - val_loss: 19.1054\n",
            "Epoch 3815/6000\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 17.7053 - val_loss: 19.1548\n",
            "Epoch 3816/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 17.5632 - val_loss: 19.1011\n",
            "Epoch 3817/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 17.8153 - val_loss: 19.0697\n",
            "Epoch 3818/6000\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 17.5339 - val_loss: 19.2762\n",
            "Epoch 3819/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 17.5992 - val_loss: 19.2271\n",
            "Epoch 3820/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 17.5822 - val_loss: 19.1489\n",
            "Epoch 3821/6000\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 17.5954 - val_loss: 19.0286\n",
            "Epoch 3822/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 17.5058 - val_loss: 19.2316\n",
            "Epoch 3823/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 17.8696 - val_loss: 19.3130\n",
            "Epoch 3824/6000\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 17.6522 - val_loss: 19.2082\n",
            "Epoch 3825/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 17.4785 - val_loss: 19.4681\n",
            "Epoch 3826/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 17.6239 - val_loss: 19.2113\n",
            "Epoch 3827/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 17.6141 - val_loss: 18.9796\n",
            "Epoch 3828/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 17.5057 - val_loss: 19.2499\n",
            "Epoch 3829/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 17.5484 - val_loss: 19.0276\n",
            "Epoch 3830/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 17.5500 - val_loss: 19.1680\n",
            "Epoch 3831/6000\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 17.4967 - val_loss: 19.1224\n",
            "Epoch 3832/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 17.5004 - val_loss: 19.1915\n",
            "Epoch 3833/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 17.2508 - val_loss: 18.9018\n",
            "Epoch 3834/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 17.3507 - val_loss: 18.7603\n",
            "Epoch 3835/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 17.2973 - val_loss: 18.6963\n",
            "Epoch 3836/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 17.4282 - val_loss: 18.7828\n",
            "Epoch 3837/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 17.3250 - val_loss: 18.7271\n",
            "Epoch 3838/6000\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 17.4199 - val_loss: 18.6993\n",
            "Epoch 3839/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 17.3749 - val_loss: 18.7390\n",
            "Epoch 3840/6000\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 17.4344 - val_loss: 18.8733\n",
            "Epoch 3841/6000\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 17.6107 - val_loss: 18.9085\n",
            "Epoch 3842/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 17.3513 - val_loss: 18.7208\n",
            "Epoch 3843/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 17.6746 - val_loss: 18.9436\n",
            "Epoch 3844/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 17.3177 - val_loss: 18.7738\n",
            "Epoch 3845/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 17.4974 - val_loss: 18.8536\n",
            "Epoch 3846/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 17.3228 - val_loss: 18.9644\n",
            "Epoch 3847/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 17.4308 - val_loss: 18.9914\n",
            "Epoch 3848/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 17.3944 - val_loss: 19.0160\n",
            "Epoch 3849/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 17.2433 - val_loss: 19.0989\n",
            "Epoch 3850/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 17.2102 - val_loss: 18.7743\n",
            "Epoch 3851/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 17.4454 - val_loss: 18.8261\n",
            "Epoch 3852/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 17.4282 - val_loss: 18.9007\n",
            "Epoch 3853/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 17.3236 - val_loss: 18.9023\n",
            "Epoch 3854/6000\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 17.2319 - val_loss: 18.8109\n",
            "Epoch 3855/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 17.1974 - val_loss: 18.8546\n",
            "Epoch 3856/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 17.1477 - val_loss: 18.8207\n",
            "Epoch 3857/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 17.1926 - val_loss: 18.9863\n",
            "Epoch 3858/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 17.3067 - val_loss: 18.9164\n",
            "Epoch 3859/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 17.2854 - val_loss: 18.7372\n",
            "Epoch 3860/6000\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 17.1970 - val_loss: 18.7561\n",
            "Epoch 3861/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 17.3754 - val_loss: 18.7727\n",
            "Epoch 3862/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 17.1686 - val_loss: 18.9215\n",
            "Epoch 3863/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 17.0594 - val_loss: 18.9848\n",
            "Epoch 3864/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 17.2917 - val_loss: 18.8591\n",
            "Epoch 3865/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 17.1347 - val_loss: 18.8555\n",
            "Epoch 3866/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 17.1686 - val_loss: 18.6100\n",
            "Epoch 3867/6000\n",
            "6/6 [==============================] - 0s 45ms/step - loss: 17.1537 - val_loss: 18.6193\n",
            "Epoch 3868/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 17.2951 - val_loss: 18.4834\n",
            "Epoch 3869/6000\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 17.1677 - val_loss: 18.6933\n",
            "Epoch 3870/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 17.2035 - val_loss: 18.7375\n",
            "Epoch 3871/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 17.4136 - val_loss: 18.8936\n",
            "Epoch 3872/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 17.0394 - val_loss: 18.7127\n",
            "Epoch 3873/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 17.1617 - val_loss: 18.6332\n",
            "Epoch 3874/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 17.1797 - val_loss: 18.5943\n",
            "Epoch 3875/6000\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 17.2178 - val_loss: 18.6526\n",
            "Epoch 3876/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 17.2169 - val_loss: 18.7606\n",
            "Epoch 3877/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 17.1110 - val_loss: 18.7431\n",
            "Epoch 3878/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 17.1222 - val_loss: 18.5909\n",
            "Epoch 3879/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 17.1400 - val_loss: 18.4701\n",
            "Epoch 3880/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 17.1511 - val_loss: 18.4080\n",
            "Epoch 3881/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 17.0005 - val_loss: 18.5776\n",
            "Epoch 3882/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 16.9631 - val_loss: 18.4981\n",
            "Epoch 3883/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 17.0781 - val_loss: 18.5414\n",
            "Epoch 3884/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 17.1698 - val_loss: 18.3299\n",
            "Epoch 3885/6000\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 16.9519 - val_loss: 18.4614\n",
            "Epoch 3886/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 17.2083 - val_loss: 18.6215\n",
            "Epoch 3887/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 16.9420 - val_loss: 18.5581\n",
            "Epoch 3888/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 17.2648 - val_loss: 18.4637\n",
            "Epoch 3889/6000\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 16.9321 - val_loss: 18.5089\n",
            "Epoch 3890/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 17.1510 - val_loss: 18.4696\n",
            "Epoch 3891/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 17.0961 - val_loss: 18.2415\n",
            "Epoch 3892/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 17.0982 - val_loss: 18.2167\n",
            "Epoch 3893/6000\n",
            "6/6 [==============================] - 0s 40ms/step - loss: 17.2031 - val_loss: 18.3289\n",
            "Epoch 3894/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 17.1035 - val_loss: 18.2352\n",
            "Epoch 3895/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 17.0053 - val_loss: 18.3400\n",
            "Epoch 3896/6000\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 17.1452 - val_loss: 18.3512\n",
            "Epoch 3897/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 16.9458 - val_loss: 18.4132\n",
            "Epoch 3898/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 17.0560 - val_loss: 18.2720\n",
            "Epoch 3899/6000\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 16.9069 - val_loss: 18.3994\n",
            "Epoch 3900/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 17.0880 - val_loss: 18.4371\n",
            "Epoch 3901/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 17.1503 - val_loss: 18.7187\n",
            "Epoch 3902/6000\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 16.8926 - val_loss: 18.5795\n",
            "Epoch 3903/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 16.8442 - val_loss: 18.2831\n",
            "Epoch 3904/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 17.0766 - val_loss: 18.2490\n",
            "Epoch 3905/6000\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 17.0345 - val_loss: 18.3485\n",
            "Epoch 3906/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 16.8468 - val_loss: 18.3049\n",
            "Epoch 3907/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 16.9068 - val_loss: 18.5233\n",
            "Epoch 3908/6000\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 16.9185 - val_loss: 18.3564\n",
            "Epoch 3909/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 16.8781 - val_loss: 18.4334\n",
            "Epoch 3910/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 16.8330 - val_loss: 18.3599\n",
            "Epoch 3911/6000\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 16.7763 - val_loss: 18.4715\n",
            "Epoch 3912/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 17.1450 - val_loss: 18.4389\n",
            "Epoch 3913/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 16.8139 - val_loss: 18.3474\n",
            "Epoch 3914/6000\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 16.7643 - val_loss: 18.2961\n",
            "Epoch 3915/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 16.7546 - val_loss: 18.3684\n",
            "Epoch 3916/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 16.8498 - val_loss: 18.5271\n",
            "Epoch 3917/6000\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 16.9694 - val_loss: 18.5834\n",
            "Epoch 3918/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 16.8040 - val_loss: 18.4783\n",
            "Epoch 3919/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 17.0383 - val_loss: 18.3356\n",
            "Epoch 3920/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 16.7432 - val_loss: 18.4369\n",
            "Epoch 3921/6000\n",
            "6/6 [==============================] - 0s 39ms/step - loss: 16.8111 - val_loss: 18.3086\n",
            "Epoch 3922/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 17.0648 - val_loss: 18.4674\n",
            "Epoch 3923/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 16.9286 - val_loss: 18.8221\n",
            "Epoch 3924/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 16.7733 - val_loss: 19.0300\n",
            "Epoch 3925/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 16.8963 - val_loss: 18.9372\n",
            "Epoch 3926/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 16.7887 - val_loss: 18.9727\n",
            "Epoch 3927/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 16.6173 - val_loss: 18.5027\n",
            "Epoch 3928/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 16.8608 - val_loss: 18.2934\n",
            "Epoch 3929/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 16.7447 - val_loss: 18.2369\n",
            "Epoch 3930/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 16.6175 - val_loss: 18.0996\n",
            "Epoch 3931/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 16.7478 - val_loss: 18.3700\n",
            "Epoch 3932/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 16.7743 - val_loss: 18.4339\n",
            "Epoch 3933/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 16.9104 - val_loss: 18.5239\n",
            "Epoch 3934/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 16.8226 - val_loss: 18.7232\n",
            "Epoch 3935/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 16.6720 - val_loss: 18.4879\n",
            "Epoch 3936/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 16.5913 - val_loss: 18.4839\n",
            "Epoch 3937/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 16.9750 - val_loss: 18.3744\n",
            "Epoch 3938/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 16.7993 - val_loss: 18.3601\n",
            "Epoch 3939/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 16.8876 - val_loss: 18.1513\n",
            "Epoch 3940/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 16.8974 - val_loss: 18.1403\n",
            "Epoch 3941/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 16.7245 - val_loss: 18.1842\n",
            "Epoch 3942/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 16.7813 - val_loss: 18.3581\n",
            "Epoch 3943/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 16.7384 - val_loss: 18.2729\n",
            "Epoch 3944/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 16.9499 - val_loss: 18.2788\n",
            "Epoch 3945/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 16.7468 - val_loss: 18.1755\n",
            "Epoch 3946/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 16.9762 - val_loss: 18.0740\n",
            "Epoch 3947/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 16.8054 - val_loss: 18.2120\n",
            "Epoch 3948/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 16.6277 - val_loss: 18.3821\n",
            "Epoch 3949/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 16.8497 - val_loss: 18.4442\n",
            "Epoch 3950/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 16.5800 - val_loss: 18.3165\n",
            "Epoch 3951/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 16.6541 - val_loss: 18.0177\n",
            "Epoch 3952/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 16.6055 - val_loss: 18.1416\n",
            "Epoch 3953/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 16.5217 - val_loss: 17.8812\n",
            "Epoch 3954/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 16.5143 - val_loss: 17.8737\n",
            "Epoch 3955/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 16.8542 - val_loss: 17.8515\n",
            "Epoch 3956/6000\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 16.7288 - val_loss: 17.8727\n",
            "Epoch 3957/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 16.4838 - val_loss: 17.9546\n",
            "Epoch 3958/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 16.6989 - val_loss: 18.0852\n",
            "Epoch 3959/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 16.5289 - val_loss: 18.0545\n",
            "Epoch 3960/6000\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 16.5539 - val_loss: 18.0294\n",
            "Epoch 3961/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 16.6283 - val_loss: 17.8542\n",
            "Epoch 3962/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 16.5825 - val_loss: 18.0159\n",
            "Epoch 3963/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 16.8196 - val_loss: 17.8495\n",
            "Epoch 3964/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 16.6761 - val_loss: 17.8718\n",
            "Epoch 3965/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 16.5618 - val_loss: 17.7941\n",
            "Epoch 3966/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 16.5532 - val_loss: 17.8839\n",
            "Epoch 3967/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 16.5851 - val_loss: 18.0409\n",
            "Epoch 3968/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 16.5949 - val_loss: 18.1185\n",
            "Epoch 3969/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 16.4460 - val_loss: 18.1571\n",
            "Epoch 3970/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 16.5258 - val_loss: 18.1105\n",
            "Epoch 3971/6000\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 16.5406 - val_loss: 17.8776\n",
            "Epoch 3972/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 16.4202 - val_loss: 17.9062\n",
            "Epoch 3973/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 16.5557 - val_loss: 17.7999\n",
            "Epoch 3974/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 16.4847 - val_loss: 17.8603\n",
            "Epoch 3975/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 16.3575 - val_loss: 17.7956\n",
            "Epoch 3976/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 16.4087 - val_loss: 17.7721\n",
            "Epoch 3977/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 16.4786 - val_loss: 17.8813\n",
            "Epoch 3978/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 16.4199 - val_loss: 17.9158\n",
            "Epoch 3979/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 16.4165 - val_loss: 17.8940\n",
            "Epoch 3980/6000\n",
            "6/6 [==============================] - 0s 40ms/step - loss: 16.5002 - val_loss: 17.8892\n",
            "Epoch 3981/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 16.6039 - val_loss: 17.9490\n",
            "Epoch 3982/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 16.4332 - val_loss: 18.0530\n",
            "Epoch 3983/6000\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 16.4909 - val_loss: 17.9920\n",
            "Epoch 3984/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 16.4974 - val_loss: 17.9892\n",
            "Epoch 3985/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 16.7080 - val_loss: 18.0268\n",
            "Epoch 3986/6000\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 16.5498 - val_loss: 18.2523\n",
            "Epoch 3987/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 16.4782 - val_loss: 18.2042\n",
            "Epoch 3988/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 16.3925 - val_loss: 18.2539\n",
            "Epoch 3989/6000\n",
            "6/6 [==============================] - 0s 56ms/step - loss: 16.3973 - val_loss: 18.1182\n",
            "Epoch 3990/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 16.4127 - val_loss: 18.1618\n",
            "Epoch 3991/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 16.3511 - val_loss: 18.1617\n",
            "Epoch 3992/6000\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 16.3770 - val_loss: 18.1738\n",
            "Epoch 3993/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 16.5660 - val_loss: 18.1065\n",
            "Epoch 3994/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 16.4063 - val_loss: 18.1522\n",
            "Epoch 3995/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 16.3419 - val_loss: 18.2094\n",
            "Epoch 3996/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 16.3099 - val_loss: 18.2166\n",
            "Epoch 3997/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 16.3801 - val_loss: 18.1143\n",
            "Epoch 3998/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 16.1758 - val_loss: 18.0280\n",
            "Epoch 3999/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 16.4191 - val_loss: 17.9239\n",
            "Epoch 4000/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 16.3578 - val_loss: 17.9927\n",
            "Epoch 4001/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 16.2268 - val_loss: 17.7846\n",
            "Epoch 4002/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 16.3793 - val_loss: 17.7412\n",
            "Epoch 4003/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 16.4375 - val_loss: 17.7474\n",
            "Epoch 4004/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 16.2725 - val_loss: 17.8116\n",
            "Epoch 4005/6000\n",
            "6/6 [==============================] - 0s 39ms/step - loss: 16.4069 - val_loss: 17.6093\n",
            "Epoch 4006/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 16.4816 - val_loss: 17.8969\n",
            "Epoch 4007/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 16.5858 - val_loss: 17.8227\n",
            "Epoch 4008/6000\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 16.3424 - val_loss: 18.1236\n",
            "Epoch 4009/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 16.3362 - val_loss: 17.9821\n",
            "Epoch 4010/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 16.1769 - val_loss: 17.8032\n",
            "Epoch 4011/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 16.3222 - val_loss: 17.8658\n",
            "Epoch 4012/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 16.3437 - val_loss: 17.6526\n",
            "Epoch 4013/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 16.1567 - val_loss: 17.9660\n",
            "Epoch 4014/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 16.4456 - val_loss: 17.8952\n",
            "Epoch 4015/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 16.2295 - val_loss: 18.1825\n",
            "Epoch 4016/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 16.4310 - val_loss: 17.7678\n",
            "Epoch 4017/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 16.3022 - val_loss: 17.8914\n",
            "Epoch 4018/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 16.5784 - val_loss: 18.0491\n",
            "Epoch 4019/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 16.4176 - val_loss: 18.0637\n",
            "Epoch 4020/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 16.6119 - val_loss: 18.0410\n",
            "Epoch 4021/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 16.4123 - val_loss: 18.0306\n",
            "Epoch 4022/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 16.3963 - val_loss: 18.0302\n",
            "Epoch 4023/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 16.4779 - val_loss: 17.9652\n",
            "Epoch 4024/6000\n",
            "6/6 [==============================] - 0s 39ms/step - loss: 16.5505 - val_loss: 17.9386\n",
            "Epoch 4025/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 16.2810 - val_loss: 17.7610\n",
            "Epoch 4026/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 16.3403 - val_loss: 17.7384\n",
            "Epoch 4027/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 16.4356 - val_loss: 17.5859\n",
            "Epoch 4028/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 16.2772 - val_loss: 17.6588\n",
            "Epoch 4029/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 16.3388 - val_loss: 17.9153\n",
            "Epoch 4030/6000\n",
            "6/6 [==============================] - 0s 40ms/step - loss: 16.3008 - val_loss: 18.0095\n",
            "Epoch 4031/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 16.4226 - val_loss: 17.7177\n",
            "Epoch 4032/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 16.1520 - val_loss: 17.8007\n",
            "Epoch 4033/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 16.3521 - val_loss: 17.7253\n",
            "Epoch 4034/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 16.2417 - val_loss: 17.9629\n",
            "Epoch 4035/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 16.1612 - val_loss: 17.6599\n",
            "Epoch 4036/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 16.1879 - val_loss: 17.8237\n",
            "Epoch 4037/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 16.1210 - val_loss: 17.9364\n",
            "Epoch 4038/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 16.0039 - val_loss: 18.0944\n",
            "Epoch 4039/6000\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 16.0673 - val_loss: 17.9063\n",
            "Epoch 4040/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 16.0908 - val_loss: 17.8481\n",
            "Epoch 4041/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 16.1924 - val_loss: 17.8444\n",
            "Epoch 4042/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 16.0827 - val_loss: 17.7797\n",
            "Epoch 4043/6000\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 16.1092 - val_loss: 17.7682\n",
            "Epoch 4044/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 16.1244 - val_loss: 17.5571\n",
            "Epoch 4045/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 16.1470 - val_loss: 17.6215\n",
            "Epoch 4046/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 15.9549 - val_loss: 17.6917\n",
            "Epoch 4047/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 16.2284 - val_loss: 17.7445\n",
            "Epoch 4048/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 16.1404 - val_loss: 17.6508\n",
            "Epoch 4049/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 16.3182 - val_loss: 17.7368\n",
            "Epoch 4050/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 15.9533 - val_loss: 17.6048\n",
            "Epoch 4051/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 15.9092 - val_loss: 17.5028\n",
            "Epoch 4052/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 15.9462 - val_loss: 17.5189\n",
            "Epoch 4053/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 16.0885 - val_loss: 17.6256\n",
            "Epoch 4054/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 16.2106 - val_loss: 17.5271\n",
            "Epoch 4055/6000\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 16.0468 - val_loss: 17.7576\n",
            "Epoch 4056/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 16.0888 - val_loss: 17.7292\n",
            "Epoch 4057/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 16.1785 - val_loss: 18.0590\n",
            "Epoch 4058/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 16.4733 - val_loss: 17.8046\n",
            "Epoch 4059/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 16.2041 - val_loss: 18.0574\n",
            "Epoch 4060/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 16.1391 - val_loss: 17.8913\n",
            "Epoch 4061/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 16.1230 - val_loss: 17.8628\n",
            "Epoch 4062/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 16.1124 - val_loss: 17.9909\n",
            "Epoch 4063/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 15.9462 - val_loss: 17.8812\n",
            "Epoch 4064/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 16.0132 - val_loss: 18.1968\n",
            "Epoch 4065/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 16.0715 - val_loss: 17.6536\n",
            "Epoch 4066/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 15.9011 - val_loss: 17.6414\n",
            "Epoch 4067/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 15.9622 - val_loss: 17.4976\n",
            "Epoch 4068/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 15.9271 - val_loss: 17.6021\n",
            "Epoch 4069/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 15.9130 - val_loss: 17.4087\n",
            "Epoch 4070/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 16.0865 - val_loss: 17.3385\n",
            "Epoch 4071/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 15.8450 - val_loss: 17.1734\n",
            "Epoch 4072/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 15.8699 - val_loss: 17.4436\n",
            "Epoch 4073/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 15.7751 - val_loss: 17.4397\n",
            "Epoch 4074/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 15.8635 - val_loss: 17.7324\n",
            "Epoch 4075/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 16.0199 - val_loss: 17.6189\n",
            "Epoch 4076/6000\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 15.7899 - val_loss: 17.4948\n",
            "Epoch 4077/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 15.9423 - val_loss: 17.2467\n",
            "Epoch 4078/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 15.7827 - val_loss: 17.2180\n",
            "Epoch 4079/6000\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 15.8346 - val_loss: 17.5823\n",
            "Epoch 4080/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 15.7928 - val_loss: 17.4648\n",
            "Epoch 4081/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 15.8891 - val_loss: 17.5652\n",
            "Epoch 4082/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 15.8324 - val_loss: 17.6373\n",
            "Epoch 4083/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 15.8090 - val_loss: 17.9343\n",
            "Epoch 4084/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 15.8214 - val_loss: 17.5556\n",
            "Epoch 4085/6000\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 15.7234 - val_loss: 17.6012\n",
            "Epoch 4086/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 15.8181 - val_loss: 17.4553\n",
            "Epoch 4087/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 15.8892 - val_loss: 17.3574\n",
            "Epoch 4088/6000\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 15.6870 - val_loss: 17.2692\n",
            "Epoch 4089/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 16.0145 - val_loss: 17.1239\n",
            "Epoch 4090/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 15.7560 - val_loss: 17.2208\n",
            "Epoch 4091/6000\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 15.7593 - val_loss: 17.2786\n",
            "Epoch 4092/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 15.7126 - val_loss: 17.2873\n",
            "Epoch 4093/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 15.6943 - val_loss: 17.0697\n",
            "Epoch 4094/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 15.6210 - val_loss: 17.1095\n",
            "Epoch 4095/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 15.7441 - val_loss: 17.0119\n",
            "Epoch 4096/6000\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 15.7768 - val_loss: 17.2153\n",
            "Epoch 4097/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 15.8584 - val_loss: 17.3267\n",
            "Epoch 4098/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 15.6554 - val_loss: 17.4888\n",
            "Epoch 4099/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 15.6692 - val_loss: 17.3533\n",
            "Epoch 4100/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 15.6636 - val_loss: 17.4693\n",
            "Epoch 4101/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 15.8865 - val_loss: 17.3312\n",
            "Epoch 4102/6000\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 15.9292 - val_loss: 17.3103\n",
            "Epoch 4103/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 15.8527 - val_loss: 17.1079\n",
            "Epoch 4104/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 15.7226 - val_loss: 17.3888\n",
            "Epoch 4105/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 15.8049 - val_loss: 17.3618\n",
            "Epoch 4106/6000\n",
            "6/6 [==============================] - 0s 46ms/step - loss: 15.6785 - val_loss: 17.4586\n",
            "Epoch 4107/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 15.6266 - val_loss: 17.4700\n",
            "Epoch 4108/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 15.9388 - val_loss: 17.4810\n",
            "Epoch 4109/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 15.9709 - val_loss: 17.3756\n",
            "Epoch 4110/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 15.9762 - val_loss: 17.4780\n",
            "Epoch 4111/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 15.6465 - val_loss: 17.7071\n",
            "Epoch 4112/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 15.8538 - val_loss: 17.6394\n",
            "Epoch 4113/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 15.7383 - val_loss: 17.4041\n",
            "Epoch 4114/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 15.9598 - val_loss: 17.3971\n",
            "Epoch 4115/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 15.6857 - val_loss: 17.1878\n",
            "Epoch 4116/6000\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 16.3207 - val_loss: 17.0792\n",
            "Epoch 4117/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 15.7270 - val_loss: 17.2430\n",
            "Epoch 4118/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 15.5908 - val_loss: 17.3557\n",
            "Epoch 4119/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 15.5227 - val_loss: 17.5675\n",
            "Epoch 4120/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 15.6935 - val_loss: 17.6986\n",
            "Epoch 4121/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 15.5953 - val_loss: 17.6807\n",
            "Epoch 4122/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 15.6297 - val_loss: 17.5110\n",
            "Epoch 4123/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 15.5747 - val_loss: 17.2627\n",
            "Epoch 4124/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 15.7496 - val_loss: 17.1027\n",
            "Epoch 4125/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 15.5045 - val_loss: 17.0465\n",
            "Epoch 4126/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 15.9179 - val_loss: 17.1877\n",
            "Epoch 4127/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 15.4983 - val_loss: 17.2057\n",
            "Epoch 4128/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 15.4521 - val_loss: 17.1815\n",
            "Epoch 4129/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 15.4459 - val_loss: 17.1764\n",
            "Epoch 4130/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 15.6100 - val_loss: 17.2475\n",
            "Epoch 4131/6000\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 15.6815 - val_loss: 17.2341\n",
            "Epoch 4132/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 15.5207 - val_loss: 17.4442\n",
            "Epoch 4133/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 15.4480 - val_loss: 17.3511\n",
            "Epoch 4134/6000\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 15.4345 - val_loss: 17.1473\n",
            "Epoch 4135/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 15.5495 - val_loss: 17.1732\n",
            "Epoch 4136/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 15.9614 - val_loss: 17.1336\n",
            "Epoch 4137/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 15.6007 - val_loss: 17.3378\n",
            "Epoch 4138/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 15.4568 - val_loss: 17.2495\n",
            "Epoch 4139/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 15.4657 - val_loss: 17.2392\n",
            "Epoch 4140/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 15.5029 - val_loss: 17.2624\n",
            "Epoch 4141/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 15.6069 - val_loss: 17.0423\n",
            "Epoch 4142/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 15.5659 - val_loss: 16.8934\n",
            "Epoch 4143/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 15.6265 - val_loss: 16.9872\n",
            "Epoch 4144/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 15.5392 - val_loss: 17.0023\n",
            "Epoch 4145/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 15.6597 - val_loss: 17.1115\n",
            "Epoch 4146/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 15.6038 - val_loss: 16.9553\n",
            "Epoch 4147/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 15.6754 - val_loss: 17.0078\n",
            "Epoch 4148/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 15.3614 - val_loss: 17.2232\n",
            "Epoch 4149/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 15.3362 - val_loss: 17.3055\n",
            "Epoch 4150/6000\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 15.3614 - val_loss: 17.0346\n",
            "Epoch 4151/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 15.4168 - val_loss: 17.1480\n",
            "Epoch 4152/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 15.3736 - val_loss: 17.3664\n",
            "Epoch 4153/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 15.5102 - val_loss: 17.4696\n",
            "Epoch 4154/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 15.7101 - val_loss: 17.4209\n",
            "Epoch 4155/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 15.4678 - val_loss: 17.0078\n",
            "Epoch 4156/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 15.4887 - val_loss: 16.9379\n",
            "Epoch 4157/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 15.4261 - val_loss: 17.0918\n",
            "Epoch 4158/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 15.4845 - val_loss: 17.1916\n",
            "Epoch 4159/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 15.4538 - val_loss: 17.1571\n",
            "Epoch 4160/6000\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 15.3896 - val_loss: 17.2497\n",
            "Epoch 4161/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 15.2243 - val_loss: 17.0333\n",
            "Epoch 4162/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 15.3696 - val_loss: 17.0570\n",
            "Epoch 4163/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 15.4010 - val_loss: 16.9067\n",
            "Epoch 4164/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 15.3520 - val_loss: 16.7982\n",
            "Epoch 4165/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 15.3076 - val_loss: 16.9230\n",
            "Epoch 4166/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 15.3594 - val_loss: 16.9908\n",
            "Epoch 4167/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 15.3641 - val_loss: 17.0958\n",
            "Epoch 4168/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 15.1880 - val_loss: 17.0181\n",
            "Epoch 4169/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 15.5071 - val_loss: 17.1029\n",
            "Epoch 4170/6000\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 15.3106 - val_loss: 17.1473\n",
            "Epoch 4171/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 15.3325 - val_loss: 17.1194\n",
            "Epoch 4172/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 15.2458 - val_loss: 17.3015\n",
            "Epoch 4173/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 15.2918 - val_loss: 17.0515\n",
            "Epoch 4174/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 15.2947 - val_loss: 17.2734\n",
            "Epoch 4175/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 15.4797 - val_loss: 16.9764\n",
            "Epoch 4176/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 15.3086 - val_loss: 17.1253\n",
            "Epoch 4177/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 15.2621 - val_loss: 16.9036\n",
            "Epoch 4178/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 15.4287 - val_loss: 16.9345\n",
            "Epoch 4179/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 15.3032 - val_loss: 16.9200\n",
            "Epoch 4180/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 15.2018 - val_loss: 16.9162\n",
            "Epoch 4181/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 15.2269 - val_loss: 16.7862\n",
            "Epoch 4182/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 15.1334 - val_loss: 16.6705\n",
            "Epoch 4183/6000\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 15.1722 - val_loss: 16.6040\n",
            "Epoch 4184/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 15.0800 - val_loss: 16.6518\n",
            "Epoch 4185/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 15.1255 - val_loss: 16.6532\n",
            "Epoch 4186/6000\n",
            "6/6 [==============================] - 0s 40ms/step - loss: 15.1529 - val_loss: 16.7463\n",
            "Epoch 4187/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 15.0877 - val_loss: 16.6887\n",
            "Epoch 4188/6000\n",
            "6/6 [==============================] - 0s 52ms/step - loss: 15.0874 - val_loss: 16.6670\n",
            "Epoch 4189/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 15.2377 - val_loss: 16.6216\n",
            "Epoch 4190/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 15.2900 - val_loss: 16.6756\n",
            "Epoch 4191/6000\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 15.0667 - val_loss: 16.6688\n",
            "Epoch 4192/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 15.1953 - val_loss: 16.6405\n",
            "Epoch 4193/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 15.2840 - val_loss: 16.5883\n",
            "Epoch 4194/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 15.1413 - val_loss: 16.8804\n",
            "Epoch 4195/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 15.0813 - val_loss: 16.8987\n",
            "Epoch 4196/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 15.0763 - val_loss: 16.8496\n",
            "Epoch 4197/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 15.1950 - val_loss: 16.6601\n",
            "Epoch 4198/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 15.1253 - val_loss: 16.9042\n",
            "Epoch 4199/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 15.1780 - val_loss: 16.8133\n",
            "Epoch 4200/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 15.0798 - val_loss: 16.6537\n",
            "Epoch 4201/6000\n",
            "6/6 [==============================] - 0s 40ms/step - loss: 15.4658 - val_loss: 16.6518\n",
            "Epoch 4202/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 15.1709 - val_loss: 16.7970\n",
            "Epoch 4203/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 15.1677 - val_loss: 16.7319\n",
            "Epoch 4204/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 15.3902 - val_loss: 16.8274\n",
            "Epoch 4205/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 15.0658 - val_loss: 16.7598\n",
            "Epoch 4206/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 15.0829 - val_loss: 16.8037\n",
            "Epoch 4207/6000\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 15.3479 - val_loss: 17.0209\n",
            "Epoch 4208/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 15.1277 - val_loss: 16.7806\n",
            "Epoch 4209/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 15.3516 - val_loss: 17.0228\n",
            "Epoch 4210/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 15.1928 - val_loss: 16.6412\n",
            "Epoch 4211/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 15.2092 - val_loss: 16.4570\n",
            "Epoch 4212/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 15.3184 - val_loss: 16.6480\n",
            "Epoch 4213/6000\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 15.2430 - val_loss: 16.8465\n",
            "Epoch 4214/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 15.0242 - val_loss: 16.8163\n",
            "Epoch 4215/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 15.0520 - val_loss: 16.9993\n",
            "Epoch 4216/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 15.1657 - val_loss: 16.8078\n",
            "Epoch 4217/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 15.1164 - val_loss: 16.7350\n",
            "Epoch 4218/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 15.0453 - val_loss: 16.6460\n",
            "Epoch 4219/6000\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 14.9876 - val_loss: 16.5895\n",
            "Epoch 4220/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 14.8883 - val_loss: 16.4258\n",
            "Epoch 4221/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 14.9512 - val_loss: 16.4506\n",
            "Epoch 4222/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 14.9791 - val_loss: 16.3516\n",
            "Epoch 4223/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 15.4325 - val_loss: 16.5399\n",
            "Epoch 4224/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 15.1356 - val_loss: 16.3964\n",
            "Epoch 4225/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 15.3052 - val_loss: 16.7851\n",
            "Epoch 4226/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 15.2696 - val_loss: 16.6327\n",
            "Epoch 4227/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 15.1220 - val_loss: 16.6447\n",
            "Epoch 4228/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 15.2499 - val_loss: 16.8037\n",
            "Epoch 4229/6000\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 15.2148 - val_loss: 16.9183\n",
            "Epoch 4230/6000\n",
            "6/6 [==============================] - 0s 40ms/step - loss: 15.2920 - val_loss: 16.5394\n",
            "Epoch 4231/6000\n",
            "6/6 [==============================] - 0s 39ms/step - loss: 15.2622 - val_loss: 16.3763\n",
            "Epoch 4232/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 15.1097 - val_loss: 16.4474\n",
            "Epoch 4233/6000\n",
            "6/6 [==============================] - 0s 91ms/step - loss: 14.9014 - val_loss: 16.5308\n",
            "Epoch 4234/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 15.0726 - val_loss: 16.6032\n",
            "Epoch 4235/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 14.9655 - val_loss: 16.4190\n",
            "Epoch 4236/6000\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 15.1117 - val_loss: 16.4132\n",
            "Epoch 4237/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 14.9559 - val_loss: 16.5215\n",
            "Epoch 4238/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 15.0632 - val_loss: 16.7370\n",
            "Epoch 4239/6000\n",
            "6/6 [==============================] - 0s 39ms/step - loss: 14.9445 - val_loss: 16.6998\n",
            "Epoch 4240/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 14.8564 - val_loss: 16.8911\n",
            "Epoch 4241/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 15.0702 - val_loss: 16.7924\n",
            "Epoch 4242/6000\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 15.0986 - val_loss: 16.8229\n",
            "Epoch 4243/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 14.8349 - val_loss: 16.6966\n",
            "Epoch 4244/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 14.8086 - val_loss: 16.6237\n",
            "Epoch 4245/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 14.9325 - val_loss: 16.6615\n",
            "Epoch 4246/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 14.8019 - val_loss: 16.6886\n",
            "Epoch 4247/6000\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 15.0919 - val_loss: 16.3030\n",
            "Epoch 4248/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 14.8711 - val_loss: 16.6884\n",
            "Epoch 4249/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 14.9749 - val_loss: 16.6053\n",
            "Epoch 4250/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 14.7533 - val_loss: 16.4987\n",
            "Epoch 4251/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 14.8481 - val_loss: 16.3878\n",
            "Epoch 4252/6000\n",
            "6/6 [==============================] - 0s 46ms/step - loss: 14.7828 - val_loss: 16.3683\n",
            "Epoch 4253/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 14.8070 - val_loss: 16.3695\n",
            "Epoch 4254/6000\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 14.7691 - val_loss: 16.3588\n",
            "Epoch 4255/6000\n",
            "6/6 [==============================] - 0s 47ms/step - loss: 14.8399 - val_loss: 16.3345\n",
            "Epoch 4256/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 14.7912 - val_loss: 16.3428\n",
            "Epoch 4257/6000\n",
            "6/6 [==============================] - 0s 41ms/step - loss: 14.7930 - val_loss: 16.2310\n",
            "Epoch 4258/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 14.8720 - val_loss: 16.2354\n",
            "Epoch 4259/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 14.7944 - val_loss: 16.3694\n",
            "Epoch 4260/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 15.0095 - val_loss: 16.4200\n",
            "Epoch 4261/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 15.3334 - val_loss: 16.4172\n",
            "Epoch 4262/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 14.8317 - val_loss: 16.4553\n",
            "Epoch 4263/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 14.6412 - val_loss: 16.3656\n",
            "Epoch 4264/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 14.9907 - val_loss: 16.4487\n",
            "Epoch 4265/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 14.8661 - val_loss: 16.3485\n",
            "Epoch 4266/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 14.8322 - val_loss: 16.6311\n",
            "Epoch 4267/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 14.8586 - val_loss: 16.5059\n",
            "Epoch 4268/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 15.0026 - val_loss: 16.3133\n",
            "Epoch 4269/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 14.9993 - val_loss: 16.3289\n",
            "Epoch 4270/6000\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 14.6406 - val_loss: 16.3931\n",
            "Epoch 4271/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 14.6950 - val_loss: 16.2089\n",
            "Epoch 4272/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 14.8762 - val_loss: 16.4278\n",
            "Epoch 4273/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 14.7182 - val_loss: 16.3430\n",
            "Epoch 4274/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 14.7399 - val_loss: 16.3953\n",
            "Epoch 4275/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 14.7895 - val_loss: 16.3580\n",
            "Epoch 4276/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 14.8169 - val_loss: 16.3756\n",
            "Epoch 4277/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 14.9316 - val_loss: 16.5002\n",
            "Epoch 4278/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 14.6183 - val_loss: 16.5218\n",
            "Epoch 4279/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 14.6480 - val_loss: 16.3476\n",
            "Epoch 4280/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 14.6607 - val_loss: 16.3226\n",
            "Epoch 4281/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 14.6036 - val_loss: 16.2511\n",
            "Epoch 4282/6000\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 14.8085 - val_loss: 16.3372\n",
            "Epoch 4283/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 14.6676 - val_loss: 16.4206\n",
            "Epoch 4284/6000\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 14.5778 - val_loss: 16.2099\n",
            "Epoch 4285/6000\n",
            "6/6 [==============================] - 0s 45ms/step - loss: 14.8116 - val_loss: 16.3645\n",
            "Epoch 4286/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 14.7571 - val_loss: 16.4122\n",
            "Epoch 4287/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 14.5189 - val_loss: 16.2195\n",
            "Epoch 4288/6000\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 14.5620 - val_loss: 16.0672\n",
            "Epoch 4289/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 14.9760 - val_loss: 16.2759\n",
            "Epoch 4290/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 14.5128 - val_loss: 16.3426\n",
            "Epoch 4291/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 14.9320 - val_loss: 16.5335\n",
            "Epoch 4292/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 15.1560 - val_loss: 16.8167\n",
            "Epoch 4293/6000\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 15.3813 - val_loss: 16.9570\n",
            "Epoch 4294/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 15.4561 - val_loss: 16.8121\n",
            "Epoch 4295/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 15.2211 - val_loss: 16.8804\n",
            "Epoch 4296/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 14.9580 - val_loss: 17.1401\n",
            "Epoch 4297/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 14.8582 - val_loss: 17.1985\n",
            "Epoch 4298/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 14.6630 - val_loss: 16.7343\n",
            "Epoch 4299/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 14.9562 - val_loss: 16.6748\n",
            "Epoch 4300/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 14.7107 - val_loss: 16.7184\n",
            "Epoch 4301/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 14.9634 - val_loss: 16.8761\n",
            "Epoch 4302/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 14.7462 - val_loss: 16.6723\n",
            "Epoch 4303/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 14.7061 - val_loss: 16.4885\n",
            "Epoch 4304/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 14.7080 - val_loss: 16.3382\n",
            "Epoch 4305/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 14.7195 - val_loss: 16.5396\n",
            "Epoch 4306/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 14.7927 - val_loss: 16.3434\n",
            "Epoch 4307/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 14.6205 - val_loss: 16.2656\n",
            "Epoch 4308/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 14.5459 - val_loss: 16.3455\n",
            "Epoch 4309/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 14.4728 - val_loss: 16.3221\n",
            "Epoch 4310/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 14.5167 - val_loss: 16.2895\n",
            "Epoch 4311/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 14.5514 - val_loss: 16.5549\n",
            "Epoch 4312/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 14.5297 - val_loss: 16.3132\n",
            "Epoch 4313/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 14.4362 - val_loss: 16.3740\n",
            "Epoch 4314/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 14.4126 - val_loss: 16.2168\n",
            "Epoch 4315/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 14.5722 - val_loss: 16.2153\n",
            "Epoch 4316/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 14.6633 - val_loss: 16.2869\n",
            "Epoch 4317/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 14.3914 - val_loss: 16.2352\n",
            "Epoch 4318/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 14.6247 - val_loss: 16.1994\n",
            "Epoch 4319/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 14.7056 - val_loss: 16.1714\n",
            "Epoch 4320/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 14.5233 - val_loss: 16.3714\n",
            "Epoch 4321/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 14.5396 - val_loss: 16.3782\n",
            "Epoch 4322/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 14.5619 - val_loss: 16.1058\n",
            "Epoch 4323/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 14.6675 - val_loss: 16.0642\n",
            "Epoch 4324/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 14.4694 - val_loss: 16.1401\n",
            "Epoch 4325/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 14.4262 - val_loss: 16.1400\n",
            "Epoch 4326/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 14.5953 - val_loss: 16.3106\n",
            "Epoch 4327/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 14.4628 - val_loss: 16.2498\n",
            "Epoch 4328/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 14.3183 - val_loss: 16.3668\n",
            "Epoch 4329/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 14.4620 - val_loss: 16.2960\n",
            "Epoch 4330/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 14.6495 - val_loss: 16.0626\n",
            "Epoch 4331/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 14.3332 - val_loss: 16.1737\n",
            "Epoch 4332/6000\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 14.3174 - val_loss: 15.9073\n",
            "Epoch 4333/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 14.3147 - val_loss: 16.0862\n",
            "Epoch 4334/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 14.4077 - val_loss: 15.8607\n",
            "Epoch 4335/6000\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 14.2737 - val_loss: 15.9901\n",
            "Epoch 4336/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 14.3551 - val_loss: 15.8617\n",
            "Epoch 4337/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 14.4101 - val_loss: 15.9938\n",
            "Epoch 4338/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 14.2744 - val_loss: 16.1211\n",
            "Epoch 4339/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 14.6472 - val_loss: 16.1375\n",
            "Epoch 4340/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 14.7479 - val_loss: 16.0764\n",
            "Epoch 4341/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 14.4654 - val_loss: 15.9512\n",
            "Epoch 4342/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 14.6339 - val_loss: 16.0414\n",
            "Epoch 4343/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 14.6140 - val_loss: 16.0649\n",
            "Epoch 4344/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 14.4301 - val_loss: 16.1976\n",
            "Epoch 4345/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 14.4772 - val_loss: 16.0290\n",
            "Epoch 4346/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 14.4433 - val_loss: 15.9512\n",
            "Epoch 4347/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 14.4787 - val_loss: 16.0393\n",
            "Epoch 4348/6000\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 14.4431 - val_loss: 16.1360\n",
            "Epoch 4349/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 14.4359 - val_loss: 15.9953\n",
            "Epoch 4350/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 14.1734 - val_loss: 15.9822\n",
            "Epoch 4351/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 14.4988 - val_loss: 16.1803\n",
            "Epoch 4352/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 14.6535 - val_loss: 16.0283\n",
            "Epoch 4353/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 14.4494 - val_loss: 15.9747\n",
            "Epoch 4354/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 14.2170 - val_loss: 15.9882\n",
            "Epoch 4355/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 14.2213 - val_loss: 15.8629\n",
            "Epoch 4356/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 14.2776 - val_loss: 16.0258\n",
            "Epoch 4357/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 14.2513 - val_loss: 16.0289\n",
            "Epoch 4358/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 14.4845 - val_loss: 15.9204\n",
            "Epoch 4359/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 14.3020 - val_loss: 15.9544\n",
            "Epoch 4360/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 14.2688 - val_loss: 16.0029\n",
            "Epoch 4361/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 14.2178 - val_loss: 15.9702\n",
            "Epoch 4362/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 14.4202 - val_loss: 16.0722\n",
            "Epoch 4363/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 14.4049 - val_loss: 15.8591\n",
            "Epoch 4364/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 14.3024 - val_loss: 15.7434\n",
            "Epoch 4365/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 14.3096 - val_loss: 15.9618\n",
            "Epoch 4366/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 14.2194 - val_loss: 15.8173\n",
            "Epoch 4367/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 14.3757 - val_loss: 15.8917\n",
            "Epoch 4368/6000\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 14.5730 - val_loss: 16.0786\n",
            "Epoch 4369/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 14.1588 - val_loss: 16.1118\n",
            "Epoch 4370/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 14.0247 - val_loss: 15.7940\n",
            "Epoch 4371/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 14.2172 - val_loss: 15.7809\n",
            "Epoch 4372/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 14.2434 - val_loss: 15.7699\n",
            "Epoch 4373/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 14.3004 - val_loss: 15.8670\n",
            "Epoch 4374/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 14.2673 - val_loss: 15.6354\n",
            "Epoch 4375/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 14.0826 - val_loss: 15.7678\n",
            "Epoch 4376/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 14.1895 - val_loss: 15.7100\n",
            "Epoch 4377/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 14.1990 - val_loss: 15.7966\n",
            "Epoch 4378/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 14.0242 - val_loss: 15.6731\n",
            "Epoch 4379/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 14.0284 - val_loss: 15.7275\n",
            "Epoch 4380/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 14.3495 - val_loss: 15.7579\n",
            "Epoch 4381/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 14.2317 - val_loss: 15.7976\n",
            "Epoch 4382/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 14.1097 - val_loss: 15.8814\n",
            "Epoch 4383/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 14.2058 - val_loss: 15.9237\n",
            "Epoch 4384/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 14.4582 - val_loss: 15.9109\n",
            "Epoch 4385/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 14.1390 - val_loss: 15.9658\n",
            "Epoch 4386/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 14.1277 - val_loss: 15.9056\n",
            "Epoch 4387/6000\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 14.0523 - val_loss: 15.8167\n",
            "Epoch 4388/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 14.0495 - val_loss: 15.7697\n",
            "Epoch 4389/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 14.2094 - val_loss: 15.7179\n",
            "Epoch 4390/6000\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 14.5343 - val_loss: 15.8293\n",
            "Epoch 4391/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 14.2820 - val_loss: 15.9190\n",
            "Epoch 4392/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 14.1565 - val_loss: 16.0548\n",
            "Epoch 4393/6000\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 14.3937 - val_loss: 16.1012\n",
            "Epoch 4394/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 14.2278 - val_loss: 16.3015\n",
            "Epoch 4395/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 14.1131 - val_loss: 16.0725\n",
            "Epoch 4396/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 14.3028 - val_loss: 15.9727\n",
            "Epoch 4397/6000\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 14.2571 - val_loss: 15.8996\n",
            "Epoch 4398/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 14.3433 - val_loss: 15.8789\n",
            "Epoch 4399/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 14.0085 - val_loss: 15.9713\n",
            "Epoch 4400/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 14.0488 - val_loss: 16.0510\n",
            "Epoch 4401/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 14.2928 - val_loss: 16.2228\n",
            "Epoch 4402/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 13.9673 - val_loss: 15.9248\n",
            "Epoch 4403/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 14.0549 - val_loss: 15.9838\n",
            "Epoch 4404/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 14.0166 - val_loss: 15.8421\n",
            "Epoch 4405/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 14.1876 - val_loss: 15.7397\n",
            "Epoch 4406/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 13.9810 - val_loss: 15.8847\n",
            "Epoch 4407/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 13.9046 - val_loss: 15.8190\n",
            "Epoch 4408/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 14.0240 - val_loss: 16.0442\n",
            "Epoch 4409/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 14.6286 - val_loss: 16.1642\n",
            "Epoch 4410/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 14.3672 - val_loss: 16.2704\n",
            "Epoch 4411/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 14.4860 - val_loss: 16.1521\n",
            "Epoch 4412/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 14.4339 - val_loss: 16.3359\n",
            "Epoch 4413/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 14.3622 - val_loss: 16.2231\n",
            "Epoch 4414/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 14.3373 - val_loss: 16.2609\n",
            "Epoch 4415/6000\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 14.4131 - val_loss: 16.2644\n",
            "Epoch 4416/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 14.2074 - val_loss: 16.2908\n",
            "Epoch 4417/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 14.0339 - val_loss: 16.2634\n",
            "Epoch 4418/6000\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 14.1432 - val_loss: 16.4932\n",
            "Epoch 4419/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 14.0697 - val_loss: 16.0929\n",
            "Epoch 4420/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 14.0593 - val_loss: 16.2297\n",
            "Epoch 4421/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 14.0034 - val_loss: 16.2311\n",
            "Epoch 4422/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 14.3092 - val_loss: 16.3880\n",
            "Epoch 4423/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 13.8885 - val_loss: 16.1764\n",
            "Epoch 4424/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 14.2372 - val_loss: 16.2951\n",
            "Epoch 4425/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 14.2013 - val_loss: 15.8912\n",
            "Epoch 4426/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 14.0636 - val_loss: 16.0094\n",
            "Epoch 4427/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 13.9376 - val_loss: 15.6743\n",
            "Epoch 4428/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 14.0337 - val_loss: 15.7941\n",
            "Epoch 4429/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 14.0047 - val_loss: 15.7196\n",
            "Epoch 4430/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 14.0944 - val_loss: 15.5521\n",
            "Epoch 4431/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 14.0658 - val_loss: 15.7106\n",
            "Epoch 4432/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 14.1242 - val_loss: 15.5345\n",
            "Epoch 4433/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 13.8666 - val_loss: 15.5303\n",
            "Epoch 4434/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 13.8809 - val_loss: 15.4204\n",
            "Epoch 4435/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 13.8850 - val_loss: 15.4156\n",
            "Epoch 4436/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 14.0908 - val_loss: 15.3057\n",
            "Epoch 4437/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 13.9234 - val_loss: 15.4060\n",
            "Epoch 4438/6000\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 13.9384 - val_loss: 15.4289\n",
            "Epoch 4439/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 13.9198 - val_loss: 15.3983\n",
            "Epoch 4440/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 13.9860 - val_loss: 15.4450\n",
            "Epoch 4441/6000\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 13.8170 - val_loss: 15.3557\n",
            "Epoch 4442/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 13.7821 - val_loss: 15.4267\n",
            "Epoch 4443/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 13.6941 - val_loss: 15.3529\n",
            "Epoch 4444/6000\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 13.7551 - val_loss: 15.3965\n",
            "Epoch 4445/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 13.9126 - val_loss: 15.4412\n",
            "Epoch 4446/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 13.8729 - val_loss: 15.4267\n",
            "Epoch 4447/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 13.7444 - val_loss: 15.4635\n",
            "Epoch 4448/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 13.9470 - val_loss: 15.4514\n",
            "Epoch 4449/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 13.8791 - val_loss: 15.3423\n",
            "Epoch 4450/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 14.0766 - val_loss: 15.5294\n",
            "Epoch 4451/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 13.7687 - val_loss: 15.3587\n",
            "Epoch 4452/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 13.7103 - val_loss: 15.4399\n",
            "Epoch 4453/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 14.0482 - val_loss: 15.3335\n",
            "Epoch 4454/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 13.9528 - val_loss: 15.4837\n",
            "Epoch 4455/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 13.7587 - val_loss: 15.4307\n",
            "Epoch 4456/6000\n",
            "6/6 [==============================] - 0s 39ms/step - loss: 13.9244 - val_loss: 15.5034\n",
            "Epoch 4457/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 13.8756 - val_loss: 15.3902\n",
            "Epoch 4458/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 13.7879 - val_loss: 15.4444\n",
            "Epoch 4459/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 13.9079 - val_loss: 15.4482\n",
            "Epoch 4460/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 13.8563 - val_loss: 15.4344\n",
            "Epoch 4461/6000\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 13.7797 - val_loss: 15.4706\n",
            "Epoch 4462/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 13.7418 - val_loss: 15.4926\n",
            "Epoch 4463/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 13.8195 - val_loss: 15.4860\n",
            "Epoch 4464/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 13.8460 - val_loss: 15.5391\n",
            "Epoch 4465/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 13.8562 - val_loss: 15.5925\n",
            "Epoch 4466/6000\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 13.7244 - val_loss: 15.5014\n",
            "Epoch 4467/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 13.7158 - val_loss: 15.3483\n",
            "Epoch 4468/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 13.7299 - val_loss: 15.2095\n",
            "Epoch 4469/6000\n",
            "6/6 [==============================] - 0s 40ms/step - loss: 13.6857 - val_loss: 15.2941\n",
            "Epoch 4470/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 13.6885 - val_loss: 15.1530\n",
            "Epoch 4471/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 13.6967 - val_loss: 15.4343\n",
            "Epoch 4472/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 13.7883 - val_loss: 15.2909\n",
            "Epoch 4473/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 13.7939 - val_loss: 15.3554\n",
            "Epoch 4474/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 13.9442 - val_loss: 15.4010\n",
            "Epoch 4475/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 13.9433 - val_loss: 15.4877\n",
            "Epoch 4476/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 13.9025 - val_loss: 15.5198\n",
            "Epoch 4477/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 13.8350 - val_loss: 15.3217\n",
            "Epoch 4478/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 14.0184 - val_loss: 15.3903\n",
            "Epoch 4479/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 13.8369 - val_loss: 15.2840\n",
            "Epoch 4480/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 13.6798 - val_loss: 15.6368\n",
            "Epoch 4481/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 13.7187 - val_loss: 15.5465\n",
            "Epoch 4482/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 13.7281 - val_loss: 15.6028\n",
            "Epoch 4483/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 13.8315 - val_loss: 15.5403\n",
            "Epoch 4484/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 13.6247 - val_loss: 15.6091\n",
            "Epoch 4485/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 13.8422 - val_loss: 15.4987\n",
            "Epoch 4486/6000\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 13.6756 - val_loss: 15.3391\n",
            "Epoch 4487/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 13.6017 - val_loss: 15.4695\n",
            "Epoch 4488/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 13.8410 - val_loss: 15.3500\n",
            "Epoch 4489/6000\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 13.8194 - val_loss: 15.3270\n",
            "Epoch 4490/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 13.8655 - val_loss: 15.3889\n",
            "Epoch 4491/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 13.7061 - val_loss: 15.4058\n",
            "Epoch 4492/6000\n",
            "6/6 [==============================] - 0s 39ms/step - loss: 13.9457 - val_loss: 15.4376\n",
            "Epoch 4493/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 13.6720 - val_loss: 15.3029\n",
            "Epoch 4494/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 13.5206 - val_loss: 15.2634\n",
            "Epoch 4495/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 13.5131 - val_loss: 15.1688\n",
            "Epoch 4496/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 13.5538 - val_loss: 15.2606\n",
            "Epoch 4497/6000\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 13.6433 - val_loss: 15.0949\n",
            "Epoch 4498/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 13.6654 - val_loss: 15.1805\n",
            "Epoch 4499/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 13.8753 - val_loss: 15.2550\n",
            "Epoch 4500/6000\n",
            "6/6 [==============================] - 0s 39ms/step - loss: 13.6131 - val_loss: 15.1219\n",
            "Epoch 4501/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 13.5419 - val_loss: 15.2030\n",
            "Epoch 4502/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 13.6830 - val_loss: 15.2664\n",
            "Epoch 4503/6000\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 13.5151 - val_loss: 15.1590\n",
            "Epoch 4504/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 13.4575 - val_loss: 15.1758\n",
            "Epoch 4505/6000\n",
            "6/6 [==============================] - 0s 39ms/step - loss: 13.6656 - val_loss: 15.1658\n",
            "Epoch 4506/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 13.5806 - val_loss: 15.2617\n",
            "Epoch 4507/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 13.5223 - val_loss: 15.1947\n",
            "Epoch 4508/6000\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 13.5744 - val_loss: 15.3763\n",
            "Epoch 4509/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 13.5726 - val_loss: 15.2027\n",
            "Epoch 4510/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 13.6778 - val_loss: 15.3077\n",
            "Epoch 4511/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 13.6950 - val_loss: 15.2214\n",
            "Epoch 4512/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 13.5315 - val_loss: 15.4146\n",
            "Epoch 4513/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 13.4792 - val_loss: 15.2399\n",
            "Epoch 4514/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 13.7188 - val_loss: 15.2944\n",
            "Epoch 4515/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 13.4975 - val_loss: 15.1131\n",
            "Epoch 4516/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 13.5032 - val_loss: 15.2374\n",
            "Epoch 4517/6000\n",
            "6/6 [==============================] - 0s 40ms/step - loss: 13.7235 - val_loss: 15.1160\n",
            "Epoch 4518/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 13.6809 - val_loss: 15.3642\n",
            "Epoch 4519/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 13.5139 - val_loss: 15.1646\n",
            "Epoch 4520/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 13.6144 - val_loss: 15.1494\n",
            "Epoch 4521/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 13.4374 - val_loss: 15.1223\n",
            "Epoch 4522/6000\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 13.4255 - val_loss: 15.1953\n",
            "Epoch 4523/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 13.6498 - val_loss: 15.1326\n",
            "Epoch 4524/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 13.8285 - val_loss: 15.5703\n",
            "Epoch 4525/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 14.6435 - val_loss: 16.2552\n",
            "Epoch 4526/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 14.8631 - val_loss: 16.8912\n",
            "Epoch 4527/6000\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 14.7346 - val_loss: 16.5011\n",
            "Epoch 4528/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 14.6654 - val_loss: 16.5416\n",
            "Epoch 4529/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 14.2764 - val_loss: 16.1606\n",
            "Epoch 4530/6000\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 14.1096 - val_loss: 16.3671\n",
            "Epoch 4531/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 13.9661 - val_loss: 16.3600\n",
            "Epoch 4532/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 13.9104 - val_loss: 16.2105\n",
            "Epoch 4533/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 13.9451 - val_loss: 16.1152\n",
            "Epoch 4534/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 13.7815 - val_loss: 15.8173\n",
            "Epoch 4535/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 13.8144 - val_loss: 15.7740\n",
            "Epoch 4536/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 13.7070 - val_loss: 15.7348\n",
            "Epoch 4537/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 13.6654 - val_loss: 15.8639\n",
            "Epoch 4538/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 13.6024 - val_loss: 15.7015\n",
            "Epoch 4539/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 13.6031 - val_loss: 15.2824\n",
            "Epoch 4540/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 13.6136 - val_loss: 15.2815\n",
            "Epoch 4541/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 13.5304 - val_loss: 15.2834\n",
            "Epoch 4542/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 13.5652 - val_loss: 15.3467\n",
            "Epoch 4543/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 13.6521 - val_loss: 15.1335\n",
            "Epoch 4544/6000\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 13.5009 - val_loss: 15.4320\n",
            "Epoch 4545/6000\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 13.3977 - val_loss: 15.2588\n",
            "Epoch 4546/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 13.5226 - val_loss: 15.4237\n",
            "Epoch 4547/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 13.5934 - val_loss: 15.2143\n",
            "Epoch 4548/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 13.5730 - val_loss: 15.3742\n",
            "Epoch 4549/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 13.4074 - val_loss: 15.2555\n",
            "Epoch 4550/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 13.4317 - val_loss: 15.1986\n",
            "Epoch 4551/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 13.6874 - val_loss: 15.1427\n",
            "Epoch 4552/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 13.7289 - val_loss: 15.3095\n",
            "Epoch 4553/6000\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 13.4919 - val_loss: 15.1089\n",
            "Epoch 4554/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 13.9087 - val_loss: 15.1551\n",
            "Epoch 4555/6000\n",
            "6/6 [==============================] - 0s 41ms/step - loss: 13.4643 - val_loss: 15.0392\n",
            "Epoch 4556/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 13.4825 - val_loss: 15.0313\n",
            "Epoch 4557/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 13.4452 - val_loss: 15.0384\n",
            "Epoch 4558/6000\n",
            "6/6 [==============================] - 0s 41ms/step - loss: 13.2870 - val_loss: 15.0006\n",
            "Epoch 4559/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 13.3560 - val_loss: 14.9311\n",
            "Epoch 4560/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 13.3183 - val_loss: 14.9894\n",
            "Epoch 4561/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 13.3644 - val_loss: 14.9829\n",
            "Epoch 4562/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 13.3291 - val_loss: 15.0927\n",
            "Epoch 4563/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 13.3872 - val_loss: 15.0140\n",
            "Epoch 4564/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 13.2492 - val_loss: 15.0820\n",
            "Epoch 4565/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 13.5097 - val_loss: 15.2359\n",
            "Epoch 4566/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 13.5861 - val_loss: 14.9863\n",
            "Epoch 4567/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 13.5394 - val_loss: 15.0690\n",
            "Epoch 4568/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 13.6813 - val_loss: 15.1781\n",
            "Epoch 4569/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 13.3185 - val_loss: 15.2825\n",
            "Epoch 4570/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 13.2554 - val_loss: 15.2594\n",
            "Epoch 4571/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 13.1497 - val_loss: 15.2371\n",
            "Epoch 4572/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 13.2947 - val_loss: 15.1050\n",
            "Epoch 4573/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 13.3020 - val_loss: 15.0460\n",
            "Epoch 4574/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 13.3682 - val_loss: 15.1507\n",
            "Epoch 4575/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 13.6427 - val_loss: 15.0705\n",
            "Epoch 4576/6000\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 13.2638 - val_loss: 14.9473\n",
            "Epoch 4577/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 13.4107 - val_loss: 14.9140\n",
            "Epoch 4578/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 13.5284 - val_loss: 14.9810\n",
            "Epoch 4579/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 13.1583 - val_loss: 14.8149\n",
            "Epoch 4580/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 13.1299 - val_loss: 14.7384\n",
            "Epoch 4581/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 13.1997 - val_loss: 14.8083\n",
            "Epoch 4582/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 13.2586 - val_loss: 14.8355\n",
            "Epoch 4583/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 13.5685 - val_loss: 14.7340\n",
            "Epoch 4584/6000\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 13.2122 - val_loss: 14.6887\n",
            "Epoch 4585/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 13.2733 - val_loss: 14.7718\n",
            "Epoch 4586/6000\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 13.3008 - val_loss: 14.6556\n",
            "Epoch 4587/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 13.1768 - val_loss: 14.7267\n",
            "Epoch 4588/6000\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 13.4014 - val_loss: 14.8228\n",
            "Epoch 4589/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 13.2713 - val_loss: 14.8685\n",
            "Epoch 4590/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 13.1454 - val_loss: 14.9974\n",
            "Epoch 4591/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 13.3229 - val_loss: 14.7754\n",
            "Epoch 4592/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 13.2447 - val_loss: 14.8421\n",
            "Epoch 4593/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 13.2133 - val_loss: 14.8157\n",
            "Epoch 4594/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 13.1798 - val_loss: 14.7071\n",
            "Epoch 4595/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 13.2000 - val_loss: 14.7247\n",
            "Epoch 4596/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 13.2358 - val_loss: 14.6614\n",
            "Epoch 4597/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 13.2140 - val_loss: 14.7378\n",
            "Epoch 4598/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 13.1908 - val_loss: 14.8418\n",
            "Epoch 4599/6000\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 13.2940 - val_loss: 14.6906\n",
            "Epoch 4600/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 13.0650 - val_loss: 14.7515\n",
            "Epoch 4601/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 13.1034 - val_loss: 14.7531\n",
            "Epoch 4602/6000\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 12.9663 - val_loss: 14.8595\n",
            "Epoch 4603/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 12.9876 - val_loss: 14.8076\n",
            "Epoch 4604/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 13.2398 - val_loss: 14.8010\n",
            "Epoch 4605/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 13.2189 - val_loss: 14.6727\n",
            "Epoch 4606/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 12.9602 - val_loss: 14.7670\n",
            "Epoch 4607/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 13.2582 - val_loss: 14.7096\n",
            "Epoch 4608/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 13.0849 - val_loss: 14.6484\n",
            "Epoch 4609/6000\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 13.1903 - val_loss: 14.6072\n",
            "Epoch 4610/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 13.0783 - val_loss: 14.6816\n",
            "Epoch 4611/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 13.2877 - val_loss: 14.6059\n",
            "Epoch 4612/6000\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 13.3096 - val_loss: 14.5733\n",
            "Epoch 4613/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 13.0990 - val_loss: 14.5874\n",
            "Epoch 4614/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 13.0710 - val_loss: 14.5560\n",
            "Epoch 4615/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 12.9910 - val_loss: 14.6850\n",
            "Epoch 4616/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 13.0504 - val_loss: 14.4256\n",
            "Epoch 4617/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 13.2626 - val_loss: 14.5433\n",
            "Epoch 4618/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 13.0888 - val_loss: 14.6966\n",
            "Epoch 4619/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 13.2831 - val_loss: 14.5194\n",
            "Epoch 4620/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 13.2750 - val_loss: 14.6723\n",
            "Epoch 4621/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 13.0196 - val_loss: 14.5989\n",
            "Epoch 4622/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 13.0764 - val_loss: 14.5899\n",
            "Epoch 4623/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 12.9769 - val_loss: 14.5495\n",
            "Epoch 4624/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 13.0899 - val_loss: 14.4750\n",
            "Epoch 4625/6000\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 13.0163 - val_loss: 14.6316\n",
            "Epoch 4626/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 13.0733 - val_loss: 14.5675\n",
            "Epoch 4627/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 12.9299 - val_loss: 14.5001\n",
            "Epoch 4628/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 13.4647 - val_loss: 14.5189\n",
            "Epoch 4629/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 13.0515 - val_loss: 14.6553\n",
            "Epoch 4630/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 13.1893 - val_loss: 14.5891\n",
            "Epoch 4631/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 12.8723 - val_loss: 14.7461\n",
            "Epoch 4632/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 12.9800 - val_loss: 14.6281\n",
            "Epoch 4633/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 13.0856 - val_loss: 14.7586\n",
            "Epoch 4634/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 12.9576 - val_loss: 14.5801\n",
            "Epoch 4635/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 13.4164 - val_loss: 14.7498\n",
            "Epoch 4636/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 13.0217 - val_loss: 14.8667\n",
            "Epoch 4637/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 13.0790 - val_loss: 14.8079\n",
            "Epoch 4638/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 12.8677 - val_loss: 14.6108\n",
            "Epoch 4639/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 13.1216 - val_loss: 14.6597\n",
            "Epoch 4640/6000\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 12.8805 - val_loss: 14.5561\n",
            "Epoch 4641/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 13.0053 - val_loss: 14.5579\n",
            "Epoch 4642/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 12.8296 - val_loss: 14.5133\n",
            "Epoch 4643/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 12.9194 - val_loss: 14.5707\n",
            "Epoch 4644/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 12.9956 - val_loss: 14.5753\n",
            "Epoch 4645/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 13.0426 - val_loss: 14.4719\n",
            "Epoch 4646/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 12.8299 - val_loss: 14.5886\n",
            "Epoch 4647/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 12.7595 - val_loss: 14.4880\n",
            "Epoch 4648/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 12.8641 - val_loss: 14.6328\n",
            "Epoch 4649/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 12.7824 - val_loss: 14.6665\n",
            "Epoch 4650/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 12.8356 - val_loss: 14.5978\n",
            "Epoch 4651/6000\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 12.7839 - val_loss: 14.5001\n",
            "Epoch 4652/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 13.2298 - val_loss: 14.6764\n",
            "Epoch 4653/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 12.8336 - val_loss: 14.6787\n",
            "Epoch 4654/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 12.9860 - val_loss: 14.5778\n",
            "Epoch 4655/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 13.0094 - val_loss: 14.6632\n",
            "Epoch 4656/6000\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 12.9698 - val_loss: 14.5198\n",
            "Epoch 4657/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 13.0383 - val_loss: 14.6311\n",
            "Epoch 4658/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 13.0672 - val_loss: 14.5253\n",
            "Epoch 4659/6000\n",
            "6/6 [==============================] - 0s 41ms/step - loss: 12.7587 - val_loss: 14.5239\n",
            "Epoch 4660/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 12.8449 - val_loss: 14.3393\n",
            "Epoch 4661/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 12.6784 - val_loss: 14.4935\n",
            "Epoch 4662/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 12.9341 - val_loss: 14.3038\n",
            "Epoch 4663/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 13.0091 - val_loss: 14.3694\n",
            "Epoch 4664/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 12.8095 - val_loss: 14.4332\n",
            "Epoch 4665/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 12.8597 - val_loss: 14.3492\n",
            "Epoch 4666/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 12.9405 - val_loss: 14.3800\n",
            "Epoch 4667/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 12.7814 - val_loss: 14.2950\n",
            "Epoch 4668/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 12.7747 - val_loss: 14.3279\n",
            "Epoch 4669/6000\n",
            "6/6 [==============================] - 0s 39ms/step - loss: 12.8372 - val_loss: 14.3632\n",
            "Epoch 4670/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 12.8424 - val_loss: 14.4594\n",
            "Epoch 4671/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 13.0095 - val_loss: 14.4208\n",
            "Epoch 4672/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 12.7516 - val_loss: 14.5134\n",
            "Epoch 4673/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 12.6646 - val_loss: 14.3636\n",
            "Epoch 4674/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 12.7134 - val_loss: 14.5214\n",
            "Epoch 4675/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 12.8820 - val_loss: 14.3266\n",
            "Epoch 4676/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 13.0425 - val_loss: 14.4332\n",
            "Epoch 4677/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 13.2420 - val_loss: 14.5558\n",
            "Epoch 4678/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 13.1302 - val_loss: 14.3691\n",
            "Epoch 4679/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 12.7853 - val_loss: 14.4534\n",
            "Epoch 4680/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 12.7816 - val_loss: 14.4266\n",
            "Epoch 4681/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 12.6801 - val_loss: 14.4290\n",
            "Epoch 4682/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 12.7496 - val_loss: 14.4169\n",
            "Epoch 4683/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 12.7800 - val_loss: 14.3113\n",
            "Epoch 4684/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 12.6336 - val_loss: 14.2804\n",
            "Epoch 4685/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 12.8236 - val_loss: 14.2528\n",
            "Epoch 4686/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 12.8353 - val_loss: 14.3229\n",
            "Epoch 4687/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 12.6305 - val_loss: 14.4298\n",
            "Epoch 4688/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 12.8327 - val_loss: 14.3628\n",
            "Epoch 4689/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 12.8332 - val_loss: 14.2337\n",
            "Epoch 4690/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 12.7260 - val_loss: 14.3478\n",
            "Epoch 4691/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 12.7759 - val_loss: 14.2327\n",
            "Epoch 4692/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 12.9066 - val_loss: 14.4436\n",
            "Epoch 4693/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 12.8619 - val_loss: 14.2135\n",
            "Epoch 4694/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 13.0373 - val_loss: 14.3146\n",
            "Epoch 4695/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 12.9513 - val_loss: 14.3183\n",
            "Epoch 4696/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 12.8114 - val_loss: 14.2234\n",
            "Epoch 4697/6000\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 12.5608 - val_loss: 14.3017\n",
            "Epoch 4698/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 12.6327 - val_loss: 14.2383\n",
            "Epoch 4699/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 12.7384 - val_loss: 14.4369\n",
            "Epoch 4700/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 12.8872 - val_loss: 14.4191\n",
            "Epoch 4701/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 12.6939 - val_loss: 14.5052\n",
            "Epoch 4702/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 12.6781 - val_loss: 14.3593\n",
            "Epoch 4703/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 12.8274 - val_loss: 14.3294\n",
            "Epoch 4704/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 13.0397 - val_loss: 14.3848\n",
            "Epoch 4705/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 12.6051 - val_loss: 14.2418\n",
            "Epoch 4706/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 12.9269 - val_loss: 14.2460\n",
            "Epoch 4707/6000\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 13.0414 - val_loss: 14.2804\n",
            "Epoch 4708/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 12.7473 - val_loss: 14.3040\n",
            "Epoch 4709/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 12.8401 - val_loss: 14.3610\n",
            "Epoch 4710/6000\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 12.7287 - val_loss: 14.1799\n",
            "Epoch 4711/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 12.9395 - val_loss: 14.2009\n",
            "Epoch 4712/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 12.6412 - val_loss: 14.1728\n",
            "Epoch 4713/6000\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 12.5397 - val_loss: 14.1871\n",
            "Epoch 4714/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 12.5777 - val_loss: 14.2314\n",
            "Epoch 4715/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 12.6585 - val_loss: 14.4341\n",
            "Epoch 4716/6000\n",
            "6/6 [==============================] - 0s 40ms/step - loss: 12.7239 - val_loss: 14.1180\n",
            "Epoch 4717/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 12.7923 - val_loss: 14.4343\n",
            "Epoch 4718/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 12.8642 - val_loss: 14.2500\n",
            "Epoch 4719/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 12.5753 - val_loss: 14.3628\n",
            "Epoch 4720/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 12.9039 - val_loss: 14.4315\n",
            "Epoch 4721/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 12.5976 - val_loss: 14.3708\n",
            "Epoch 4722/6000\n",
            "6/6 [==============================] - 0s 40ms/step - loss: 12.8566 - val_loss: 14.4236\n",
            "Epoch 4723/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 12.8108 - val_loss: 14.2975\n",
            "Epoch 4724/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 12.7282 - val_loss: 14.2678\n",
            "Epoch 4725/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 12.4327 - val_loss: 14.2623\n",
            "Epoch 4726/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 12.7207 - val_loss: 14.4323\n",
            "Epoch 4727/6000\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 12.6911 - val_loss: 14.2130\n",
            "Epoch 4728/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 12.5724 - val_loss: 14.2109\n",
            "Epoch 4729/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 12.6448 - val_loss: 14.2256\n",
            "Epoch 4730/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 12.5121 - val_loss: 14.1985\n",
            "Epoch 4731/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 12.4382 - val_loss: 14.2932\n",
            "Epoch 4732/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 12.5120 - val_loss: 14.2826\n",
            "Epoch 4733/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 12.6923 - val_loss: 14.3528\n",
            "Epoch 4734/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 12.6788 - val_loss: 14.3359\n",
            "Epoch 4735/6000\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 12.5236 - val_loss: 14.1741\n",
            "Epoch 4736/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 12.6481 - val_loss: 14.2188\n",
            "Epoch 4737/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 12.5435 - val_loss: 14.1920\n",
            "Epoch 4738/6000\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 12.7032 - val_loss: 14.2202\n",
            "Epoch 4739/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 12.6166 - val_loss: 14.2726\n",
            "Epoch 4740/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 12.5435 - val_loss: 14.1946\n",
            "Epoch 4741/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 12.4572 - val_loss: 14.0727\n",
            "Epoch 4742/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 12.3492 - val_loss: 14.1257\n",
            "Epoch 4743/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 12.5726 - val_loss: 14.0204\n",
            "Epoch 4744/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 12.5897 - val_loss: 14.0020\n",
            "Epoch 4745/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 12.4605 - val_loss: 13.9889\n",
            "Epoch 4746/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 12.8139 - val_loss: 14.1323\n",
            "Epoch 4747/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 12.4529 - val_loss: 14.0182\n",
            "Epoch 4748/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 12.5713 - val_loss: 14.1404\n",
            "Epoch 4749/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 12.6728 - val_loss: 14.0851\n",
            "Epoch 4750/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 12.4848 - val_loss: 14.1111\n",
            "Epoch 4751/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 12.4391 - val_loss: 14.0628\n",
            "Epoch 4752/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 12.4738 - val_loss: 14.0740\n",
            "Epoch 4753/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 12.3573 - val_loss: 14.0961\n",
            "Epoch 4754/6000\n",
            "6/6 [==============================] - 0s 41ms/step - loss: 12.4019 - val_loss: 14.1554\n",
            "Epoch 4755/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 12.7409 - val_loss: 14.1564\n",
            "Epoch 4756/6000\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 12.4240 - val_loss: 14.1666\n",
            "Epoch 4757/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 12.4914 - val_loss: 14.1732\n",
            "Epoch 4758/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 12.6768 - val_loss: 14.2228\n",
            "Epoch 4759/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 12.4527 - val_loss: 14.1563\n",
            "Epoch 4760/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 12.4543 - val_loss: 14.1258\n",
            "Epoch 4761/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 12.5411 - val_loss: 14.3447\n",
            "Epoch 4762/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 12.4496 - val_loss: 14.0587\n",
            "Epoch 4763/6000\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 12.5187 - val_loss: 14.2511\n",
            "Epoch 4764/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 12.4320 - val_loss: 14.2732\n",
            "Epoch 4765/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 12.4409 - val_loss: 14.3008\n",
            "Epoch 4766/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 12.4305 - val_loss: 14.0677\n",
            "Epoch 4767/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 12.9538 - val_loss: 14.3352\n",
            "Epoch 4768/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 12.4541 - val_loss: 14.1873\n",
            "Epoch 4769/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 12.4759 - val_loss: 14.3146\n",
            "Epoch 4770/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 12.4764 - val_loss: 14.1831\n",
            "Epoch 4771/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 12.3523 - val_loss: 14.2830\n",
            "Epoch 4772/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 12.4119 - val_loss: 14.1911\n",
            "Epoch 4773/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 12.1830 - val_loss: 14.2325\n",
            "Epoch 4774/6000\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 12.5399 - val_loss: 13.9915\n",
            "Epoch 4775/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 12.3178 - val_loss: 14.0259\n",
            "Epoch 4776/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 12.2379 - val_loss: 14.0386\n",
            "Epoch 4777/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 12.4248 - val_loss: 14.0419\n",
            "Epoch 4778/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 12.4535 - val_loss: 14.0086\n",
            "Epoch 4779/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 12.2898 - val_loss: 14.0134\n",
            "Epoch 4780/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 12.1793 - val_loss: 13.9429\n",
            "Epoch 4781/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 12.2657 - val_loss: 13.9705\n",
            "Epoch 4782/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 12.4488 - val_loss: 13.9120\n",
            "Epoch 4783/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 12.2418 - val_loss: 13.9228\n",
            "Epoch 4784/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 12.2511 - val_loss: 13.9322\n",
            "Epoch 4785/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 12.2994 - val_loss: 13.9573\n",
            "Epoch 4786/6000\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 12.6626 - val_loss: 14.0163\n",
            "Epoch 4787/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 12.2979 - val_loss: 13.9368\n",
            "Epoch 4788/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 12.2729 - val_loss: 13.9058\n",
            "Epoch 4789/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 12.3582 - val_loss: 13.8327\n",
            "Epoch 4790/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 12.5721 - val_loss: 14.0916\n",
            "Epoch 4791/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 12.3459 - val_loss: 13.9203\n",
            "Epoch 4792/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 12.2426 - val_loss: 13.8783\n",
            "Epoch 4793/6000\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 12.4628 - val_loss: 13.9451\n",
            "Epoch 4794/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 12.1005 - val_loss: 13.9638\n",
            "Epoch 4795/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 12.3191 - val_loss: 13.9460\n",
            "Epoch 4796/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 12.2089 - val_loss: 13.9896\n",
            "Epoch 4797/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 12.2656 - val_loss: 14.1134\n",
            "Epoch 4798/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 12.1296 - val_loss: 13.8677\n",
            "Epoch 4799/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 12.3444 - val_loss: 13.9633\n",
            "Epoch 4800/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 12.3638 - val_loss: 13.8940\n",
            "Epoch 4801/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 12.4029 - val_loss: 14.0252\n",
            "Epoch 4802/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 12.4018 - val_loss: 13.8647\n",
            "Epoch 4803/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 12.1995 - val_loss: 13.9893\n",
            "Epoch 4804/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 12.2469 - val_loss: 14.0143\n",
            "Epoch 4805/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 12.3599 - val_loss: 14.0146\n",
            "Epoch 4806/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 12.6031 - val_loss: 14.0219\n",
            "Epoch 4807/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 12.2948 - val_loss: 13.9469\n",
            "Epoch 4808/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 12.2703 - val_loss: 13.9408\n",
            "Epoch 4809/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 12.0571 - val_loss: 13.8483\n",
            "Epoch 4810/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 12.0658 - val_loss: 13.8985\n",
            "Epoch 4811/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 12.3189 - val_loss: 13.8570\n",
            "Epoch 4812/6000\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 12.2764 - val_loss: 13.8814\n",
            "Epoch 4813/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 12.2195 - val_loss: 13.8243\n",
            "Epoch 4814/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 12.3871 - val_loss: 13.7575\n",
            "Epoch 4815/6000\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 12.2754 - val_loss: 13.8388\n",
            "Epoch 4816/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 12.2508 - val_loss: 13.8486\n",
            "Epoch 4817/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 12.3727 - val_loss: 13.8563\n",
            "Epoch 4818/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 12.2171 - val_loss: 13.8416\n",
            "Epoch 4819/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 12.1406 - val_loss: 13.7796\n",
            "Epoch 4820/6000\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 12.3375 - val_loss: 13.9803\n",
            "Epoch 4821/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 12.1419 - val_loss: 13.7260\n",
            "Epoch 4822/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 12.4601 - val_loss: 13.9116\n",
            "Epoch 4823/6000\n",
            "6/6 [==============================] - 0s 39ms/step - loss: 12.0856 - val_loss: 13.8188\n",
            "Epoch 4824/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 12.2820 - val_loss: 14.0844\n",
            "Epoch 4825/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 12.2419 - val_loss: 13.9286\n",
            "Epoch 4826/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 12.2209 - val_loss: 13.8268\n",
            "Epoch 4827/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 12.2402 - val_loss: 13.9632\n",
            "Epoch 4828/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 12.1904 - val_loss: 13.9474\n",
            "Epoch 4829/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 12.3099 - val_loss: 14.0201\n",
            "Epoch 4830/6000\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 12.2811 - val_loss: 13.9410\n",
            "Epoch 4831/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 12.3237 - val_loss: 13.9512\n",
            "Epoch 4832/6000\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 12.4927 - val_loss: 13.9299\n",
            "Epoch 4833/6000\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 12.0770 - val_loss: 13.8085\n",
            "Epoch 4834/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 12.3079 - val_loss: 13.9742\n",
            "Epoch 4835/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 12.1711 - val_loss: 13.8873\n",
            "Epoch 4836/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 12.0621 - val_loss: 14.0212\n",
            "Epoch 4837/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 12.1772 - val_loss: 14.0053\n",
            "Epoch 4838/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 12.3081 - val_loss: 13.9633\n",
            "Epoch 4839/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 12.1905 - val_loss: 13.8254\n",
            "Epoch 4840/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 12.0980 - val_loss: 13.8516\n",
            "Epoch 4841/6000\n",
            "6/6 [==============================] - 0s 39ms/step - loss: 12.0543 - val_loss: 13.8664\n",
            "Epoch 4842/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 12.3721 - val_loss: 14.0477\n",
            "Epoch 4843/6000\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 12.4235 - val_loss: 13.7687\n",
            "Epoch 4844/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 12.4204 - val_loss: 13.9401\n",
            "Epoch 4845/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 12.0611 - val_loss: 13.9963\n",
            "Epoch 4846/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 12.1607 - val_loss: 13.9396\n",
            "Epoch 4847/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 11.9929 - val_loss: 13.8680\n",
            "Epoch 4848/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 12.1693 - val_loss: 13.8782\n",
            "Epoch 4849/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 11.9636 - val_loss: 13.9715\n",
            "Epoch 4850/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 12.1425 - val_loss: 13.9527\n",
            "Epoch 4851/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 11.9819 - val_loss: 14.0787\n",
            "Epoch 4852/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 11.9219 - val_loss: 13.8492\n",
            "Epoch 4853/6000\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 12.0517 - val_loss: 14.0500\n",
            "Epoch 4854/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 12.1581 - val_loss: 13.8520\n",
            "Epoch 4855/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 12.0618 - val_loss: 13.7836\n",
            "Epoch 4856/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 12.0876 - val_loss: 13.7825\n",
            "Epoch 4857/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 11.8955 - val_loss: 13.8011\n",
            "Epoch 4858/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 12.1433 - val_loss: 13.8709\n",
            "Epoch 4859/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 12.1556 - val_loss: 13.7505\n",
            "Epoch 4860/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 11.9950 - val_loss: 13.5938\n",
            "Epoch 4861/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 12.0549 - val_loss: 13.6681\n",
            "Epoch 4862/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 12.1284 - val_loss: 13.7802\n",
            "Epoch 4863/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 12.0934 - val_loss: 13.6528\n",
            "Epoch 4864/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 12.3716 - val_loss: 13.9263\n",
            "Epoch 4865/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 12.1688 - val_loss: 13.7053\n",
            "Epoch 4866/6000\n",
            "6/6 [==============================] - 0s 39ms/step - loss: 12.0814 - val_loss: 13.8004\n",
            "Epoch 4867/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 12.1706 - val_loss: 13.7189\n",
            "Epoch 4868/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 11.9972 - val_loss: 13.8104\n",
            "Epoch 4869/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 11.9611 - val_loss: 13.6492\n",
            "Epoch 4870/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 11.9386 - val_loss: 13.7160\n",
            "Epoch 4871/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 11.8946 - val_loss: 13.7024\n",
            "Epoch 4872/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 12.1907 - val_loss: 13.6769\n",
            "Epoch 4873/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 12.0017 - val_loss: 13.8377\n",
            "Epoch 4874/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 11.9865 - val_loss: 13.7545\n",
            "Epoch 4875/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 12.1563 - val_loss: 13.7152\n",
            "Epoch 4876/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 12.3259 - val_loss: 13.8210\n",
            "Epoch 4877/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 11.9601 - val_loss: 13.7642\n",
            "Epoch 4878/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 11.9666 - val_loss: 13.9325\n",
            "Epoch 4879/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 12.0411 - val_loss: 13.8600\n",
            "Epoch 4880/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 11.8599 - val_loss: 13.8637\n",
            "Epoch 4881/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 12.0647 - val_loss: 13.7849\n",
            "Epoch 4882/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 11.9376 - val_loss: 13.9138\n",
            "Epoch 4883/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 11.9631 - val_loss: 13.6925\n",
            "Epoch 4884/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 12.1720 - val_loss: 13.7569\n",
            "Epoch 4885/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 12.2380 - val_loss: 13.7163\n",
            "Epoch 4886/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 11.8216 - val_loss: 13.6523\n",
            "Epoch 4887/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 12.1067 - val_loss: 13.8299\n",
            "Epoch 4888/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 12.0904 - val_loss: 13.9376\n",
            "Epoch 4889/6000\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 11.8304 - val_loss: 13.7623\n",
            "Epoch 4890/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 11.9642 - val_loss: 13.9182\n",
            "Epoch 4891/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 11.8502 - val_loss: 13.7429\n",
            "Epoch 4892/6000\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 11.9580 - val_loss: 13.7799\n",
            "Epoch 4893/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 11.9168 - val_loss: 13.9289\n",
            "Epoch 4894/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 11.9064 - val_loss: 13.6817\n",
            "Epoch 4895/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 11.8518 - val_loss: 13.6631\n",
            "Epoch 4896/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 11.7795 - val_loss: 13.7034\n",
            "Epoch 4897/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 11.8421 - val_loss: 13.6086\n",
            "Epoch 4898/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 11.9275 - val_loss: 13.6803\n",
            "Epoch 4899/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 11.8632 - val_loss: 13.6514\n",
            "Epoch 4900/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 11.8993 - val_loss: 13.5031\n",
            "Epoch 4901/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 11.9149 - val_loss: 13.6904\n",
            "Epoch 4902/6000\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 11.9022 - val_loss: 13.5136\n",
            "Epoch 4903/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 11.9990 - val_loss: 13.6967\n",
            "Epoch 4904/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 11.9550 - val_loss: 13.7232\n",
            "Epoch 4905/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 12.1332 - val_loss: 13.5170\n",
            "Epoch 4906/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 11.6595 - val_loss: 13.5102\n",
            "Epoch 4907/6000\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 11.7758 - val_loss: 13.6895\n",
            "Epoch 4908/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 11.7442 - val_loss: 13.6413\n",
            "Epoch 4909/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 11.9116 - val_loss: 13.5985\n",
            "Epoch 4910/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 11.7764 - val_loss: 13.6087\n",
            "Epoch 4911/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 11.7817 - val_loss: 13.6242\n",
            "Epoch 4912/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 11.9395 - val_loss: 13.5918\n",
            "Epoch 4913/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 11.7599 - val_loss: 13.5956\n",
            "Epoch 4914/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 11.7644 - val_loss: 13.5874\n",
            "Epoch 4915/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 11.9282 - val_loss: 13.6118\n",
            "Epoch 4916/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 11.8282 - val_loss: 13.8104\n",
            "Epoch 4917/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 11.9485 - val_loss: 13.5711\n",
            "Epoch 4918/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 11.7875 - val_loss: 13.7231\n",
            "Epoch 4919/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 11.9959 - val_loss: 13.8125\n",
            "Epoch 4920/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 11.9225 - val_loss: 13.7469\n",
            "Epoch 4921/6000\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 11.8019 - val_loss: 13.7059\n",
            "Epoch 4922/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 11.9918 - val_loss: 13.9795\n",
            "Epoch 4923/6000\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 11.9936 - val_loss: 13.7848\n",
            "Epoch 4924/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 12.0654 - val_loss: 13.9841\n",
            "Epoch 4925/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 11.9311 - val_loss: 13.8142\n",
            "Epoch 4926/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 11.7448 - val_loss: 13.8868\n",
            "Epoch 4927/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 11.9058 - val_loss: 13.8399\n",
            "Epoch 4928/6000\n",
            "6/6 [==============================] - 0s 39ms/step - loss: 11.8443 - val_loss: 13.8095\n",
            "Epoch 4929/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 11.7894 - val_loss: 13.7724\n",
            "Epoch 4930/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 11.7947 - val_loss: 13.6630\n",
            "Epoch 4931/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 11.7604 - val_loss: 13.6785\n",
            "Epoch 4932/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 11.6241 - val_loss: 13.6845\n",
            "Epoch 4933/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 11.6675 - val_loss: 13.7190\n",
            "Epoch 4934/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 11.8170 - val_loss: 13.5979\n",
            "Epoch 4935/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 11.7347 - val_loss: 13.6568\n",
            "Epoch 4936/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 11.8225 - val_loss: 13.6938\n",
            "Epoch 4937/6000\n",
            "6/6 [==============================] - 0s 42ms/step - loss: 11.7176 - val_loss: 13.8279\n",
            "Epoch 4938/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 11.7172 - val_loss: 13.6494\n",
            "Epoch 4939/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 11.9083 - val_loss: 13.7933\n",
            "Epoch 4940/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 11.6266 - val_loss: 13.7020\n",
            "Epoch 4941/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 11.6621 - val_loss: 13.8370\n",
            "Epoch 4942/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 11.7606 - val_loss: 13.8814\n",
            "Epoch 4943/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 11.9925 - val_loss: 13.9962\n",
            "Epoch 4944/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 11.7806 - val_loss: 13.8793\n",
            "Epoch 4945/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 12.0192 - val_loss: 13.8903\n",
            "Epoch 4946/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 12.0493 - val_loss: 14.0812\n",
            "Epoch 4947/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 11.8433 - val_loss: 13.7652\n",
            "Epoch 4948/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 11.9530 - val_loss: 13.9751\n",
            "Epoch 4949/6000\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 11.7322 - val_loss: 13.8763\n",
            "Epoch 4950/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 11.6891 - val_loss: 13.7524\n",
            "Epoch 4951/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 11.9796 - val_loss: 13.9759\n",
            "Epoch 4952/6000\n",
            "6/6 [==============================] - 0s 41ms/step - loss: 11.7215 - val_loss: 13.8702\n",
            "Epoch 4953/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 11.7112 - val_loss: 13.9756\n",
            "Epoch 4954/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 11.9338 - val_loss: 13.8707\n",
            "Epoch 4955/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 11.7477 - val_loss: 13.8583\n",
            "Epoch 4956/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 11.6572 - val_loss: 13.6781\n",
            "Epoch 4957/6000\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 11.6914 - val_loss: 13.7794\n",
            "Epoch 4958/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 11.8866 - val_loss: 13.7522\n",
            "Epoch 4959/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 11.7147 - val_loss: 13.6789\n",
            "Epoch 4960/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 11.6021 - val_loss: 13.5546\n",
            "Epoch 4961/6000\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 11.6744 - val_loss: 13.6394\n",
            "Epoch 4962/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 11.6262 - val_loss: 13.6148\n",
            "Epoch 4963/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 11.4792 - val_loss: 13.5279\n",
            "Epoch 4964/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 11.5505 - val_loss: 13.4561\n",
            "Epoch 4965/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 11.5727 - val_loss: 13.3534\n",
            "Epoch 4966/6000\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 11.6530 - val_loss: 13.3978\n",
            "Epoch 4967/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 12.0123 - val_loss: 13.2955\n",
            "Epoch 4968/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 11.5389 - val_loss: 13.4122\n",
            "Epoch 4969/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 11.7320 - val_loss: 13.2708\n",
            "Epoch 4970/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 11.5464 - val_loss: 13.2261\n",
            "Epoch 4971/6000\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 12.0058 - val_loss: 13.3626\n",
            "Epoch 4972/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 11.5863 - val_loss: 13.2475\n",
            "Epoch 4973/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 11.6003 - val_loss: 13.2543\n",
            "Epoch 4974/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 11.6931 - val_loss: 13.3035\n",
            "Epoch 4975/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 11.6565 - val_loss: 13.2236\n",
            "Epoch 4976/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 11.5585 - val_loss: 13.3084\n",
            "Epoch 4977/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 11.7484 - val_loss: 13.4365\n",
            "Epoch 4978/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 11.6177 - val_loss: 13.2698\n",
            "Epoch 4979/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 11.6717 - val_loss: 13.2749\n",
            "Epoch 4980/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 11.4514 - val_loss: 13.5098\n",
            "Epoch 4981/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 11.6391 - val_loss: 13.3294\n",
            "Epoch 4982/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 11.6958 - val_loss: 13.4068\n",
            "Epoch 4983/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 11.9716 - val_loss: 13.3420\n",
            "Epoch 4984/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 11.7597 - val_loss: 13.4012\n",
            "Epoch 4985/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 11.7213 - val_loss: 13.1961\n",
            "Epoch 4986/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 11.8505 - val_loss: 13.3972\n",
            "Epoch 4987/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 11.6146 - val_loss: 13.2378\n",
            "Epoch 4988/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 11.4996 - val_loss: 13.2353\n",
            "Epoch 4989/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 11.8024 - val_loss: 13.2331\n",
            "Epoch 4990/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 11.6702 - val_loss: 13.2932\n",
            "Epoch 4991/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 11.6580 - val_loss: 13.1971\n",
            "Epoch 4992/6000\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 11.7796 - val_loss: 13.2138\n",
            "Epoch 4993/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 11.5769 - val_loss: 13.1553\n",
            "Epoch 4994/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 11.4751 - val_loss: 13.2232\n",
            "Epoch 4995/6000\n",
            "6/6 [==============================] - 0s 41ms/step - loss: 11.4454 - val_loss: 13.2102\n",
            "Epoch 4996/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 11.5382 - val_loss: 13.2472\n",
            "Epoch 4997/6000\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 11.7525 - val_loss: 13.2890\n",
            "Epoch 4998/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 11.7413 - val_loss: 13.4992\n",
            "Epoch 4999/6000\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 11.9060 - val_loss: 13.2814\n",
            "Epoch 5000/6000\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 11.6294 - val_loss: 13.5291\n",
            "Epoch 5001/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 11.6933 - val_loss: 13.4634\n",
            "Epoch 5002/6000\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 11.6132 - val_loss: 13.4519\n",
            "Epoch 5003/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 11.6105 - val_loss: 13.6119\n",
            "Epoch 5004/6000\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 11.7489 - val_loss: 13.5613\n",
            "Epoch 5005/6000\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 11.5972 - val_loss: 13.3872\n",
            "Epoch 5006/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 11.6133 - val_loss: 13.5500\n",
            "Epoch 5007/6000\n",
            "6/6 [==============================] - 0s 40ms/step - loss: 11.5548 - val_loss: 13.2383\n",
            "Epoch 5008/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 11.6686 - val_loss: 13.3192\n",
            "Epoch 5009/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 11.4047 - val_loss: 13.2869\n",
            "Epoch 5010/6000\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 11.5005 - val_loss: 13.3138\n",
            "Epoch 5011/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 11.5766 - val_loss: 13.2755\n",
            "Epoch 5012/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 11.6749 - val_loss: 13.3693\n",
            "Epoch 5013/6000\n",
            "6/6 [==============================] - 0s 39ms/step - loss: 11.4699 - val_loss: 13.2451\n",
            "Epoch 5014/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 11.5890 - val_loss: 13.3438\n",
            "Epoch 5015/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 11.3210 - val_loss: 13.1792\n",
            "Epoch 5016/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 11.3989 - val_loss: 13.2902\n",
            "Epoch 5017/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 11.2959 - val_loss: 13.1514\n",
            "Epoch 5018/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 11.4170 - val_loss: 13.2038\n",
            "Epoch 5019/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 11.5434 - val_loss: 13.1390\n",
            "Epoch 5020/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 11.6111 - val_loss: 13.1318\n",
            "Epoch 5021/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 11.5022 - val_loss: 13.2623\n",
            "Epoch 5022/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 11.4796 - val_loss: 13.2929\n",
            "Epoch 5023/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 11.5752 - val_loss: 13.2428\n",
            "Epoch 5024/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 11.6408 - val_loss: 13.2435\n",
            "Epoch 5025/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 11.5839 - val_loss: 13.2646\n",
            "Epoch 5026/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 11.4866 - val_loss: 13.2760\n",
            "Epoch 5027/6000\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 11.6369 - val_loss: 13.1874\n",
            "Epoch 5028/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 11.5932 - val_loss: 13.3645\n",
            "Epoch 5029/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 11.4756 - val_loss: 13.2468\n",
            "Epoch 5030/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 11.3159 - val_loss: 13.3753\n",
            "Epoch 5031/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 11.3616 - val_loss: 13.3788\n",
            "Epoch 5032/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 11.5064 - val_loss: 13.3778\n",
            "Epoch 5033/6000\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 11.5072 - val_loss: 13.2885\n",
            "Epoch 5034/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 11.5129 - val_loss: 13.4044\n",
            "Epoch 5035/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 11.4630 - val_loss: 13.2123\n",
            "Epoch 5036/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 11.4997 - val_loss: 13.3315\n",
            "Epoch 5037/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 11.5519 - val_loss: 13.4299\n",
            "Epoch 5038/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 11.5550 - val_loss: 13.4112\n",
            "Epoch 5039/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 11.7152 - val_loss: 13.5610\n",
            "Epoch 5040/6000\n",
            "6/6 [==============================] - 0s 39ms/step - loss: 11.5437 - val_loss: 13.3875\n",
            "Epoch 5041/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 11.5904 - val_loss: 13.4167\n",
            "Epoch 5042/6000\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 11.5361 - val_loss: 13.4492\n",
            "Epoch 5043/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 11.2767 - val_loss: 13.4536\n",
            "Epoch 5044/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 11.7556 - val_loss: 13.7429\n",
            "Epoch 5045/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 11.6040 - val_loss: 13.5287\n",
            "Epoch 5046/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 11.3011 - val_loss: 13.3328\n",
            "Epoch 5047/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 11.1737 - val_loss: 13.2996\n",
            "Epoch 5048/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 11.4512 - val_loss: 13.3564\n",
            "Epoch 5049/6000\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 11.3924 - val_loss: 13.4442\n",
            "Epoch 5050/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 11.1836 - val_loss: 13.2661\n",
            "Epoch 5051/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 11.3103 - val_loss: 13.2129\n",
            "Epoch 5052/6000\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 11.3204 - val_loss: 13.1540\n",
            "Epoch 5053/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 11.1691 - val_loss: 13.0854\n",
            "Epoch 5054/6000\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 11.2759 - val_loss: 13.1473\n",
            "Epoch 5055/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 11.2578 - val_loss: 13.0084\n",
            "Epoch 5056/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 11.3295 - val_loss: 13.0185\n",
            "Epoch 5057/6000\n",
            "6/6 [==============================] - 0s 41ms/step - loss: 11.4764 - val_loss: 13.0157\n",
            "Epoch 5058/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 11.2920 - val_loss: 12.9857\n",
            "Epoch 5059/6000\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 11.4592 - val_loss: 13.0634\n",
            "Epoch 5060/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 11.5692 - val_loss: 13.0540\n",
            "Epoch 5061/6000\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 11.2657 - val_loss: 12.9842\n",
            "Epoch 5062/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 11.4706 - val_loss: 13.1369\n",
            "Epoch 5063/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 11.3329 - val_loss: 12.9874\n",
            "Epoch 5064/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 11.4565 - val_loss: 13.0711\n",
            "Epoch 5065/6000\n",
            "6/6 [==============================] - 0s 40ms/step - loss: 11.2724 - val_loss: 12.9681\n",
            "Epoch 5066/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 11.2454 - val_loss: 12.9830\n",
            "Epoch 5067/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 11.2423 - val_loss: 12.9317\n",
            "Epoch 5068/6000\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 11.2962 - val_loss: 12.9858\n",
            "Epoch 5069/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 11.3674 - val_loss: 12.9193\n",
            "Epoch 5070/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 11.6424 - val_loss: 13.1243\n",
            "Epoch 5071/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 11.4668 - val_loss: 12.8603\n",
            "Epoch 5072/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 11.4711 - val_loss: 12.9739\n",
            "Epoch 5073/6000\n",
            "6/6 [==============================] - 0s 39ms/step - loss: 11.3161 - val_loss: 12.9810\n",
            "Epoch 5074/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 11.4565 - val_loss: 12.9210\n",
            "Epoch 5075/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 11.5088 - val_loss: 12.9615\n",
            "Epoch 5076/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 11.4149 - val_loss: 13.0211\n",
            "Epoch 5077/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 11.2938 - val_loss: 13.0243\n",
            "Epoch 5078/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 11.2042 - val_loss: 13.1266\n",
            "Epoch 5079/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 11.1907 - val_loss: 13.0112\n",
            "Epoch 5080/6000\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 11.1322 - val_loss: 12.9405\n",
            "Epoch 5081/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 11.5297 - val_loss: 12.9825\n",
            "Epoch 5082/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 11.2986 - val_loss: 12.9223\n",
            "Epoch 5083/6000\n",
            "6/6 [==============================] - 0s 42ms/step - loss: 11.4524 - val_loss: 13.0165\n",
            "Epoch 5084/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 11.2820 - val_loss: 12.9440\n",
            "Epoch 5085/6000\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 11.1335 - val_loss: 13.0143\n",
            "Epoch 5086/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 11.2392 - val_loss: 13.0100\n",
            "Epoch 5087/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 11.2091 - val_loss: 12.9398\n",
            "Epoch 5088/6000\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 11.2290 - val_loss: 13.1321\n",
            "Epoch 5089/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 11.2063 - val_loss: 12.8547\n",
            "Epoch 5090/6000\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 11.2491 - val_loss: 13.0099\n",
            "Epoch 5091/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 11.4314 - val_loss: 13.0450\n",
            "Epoch 5092/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 11.1862 - val_loss: 13.0035\n",
            "Epoch 5093/6000\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 11.1429 - val_loss: 12.9474\n",
            "Epoch 5094/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 11.0474 - val_loss: 12.8996\n",
            "Epoch 5095/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 11.0023 - val_loss: 12.9641\n",
            "Epoch 5096/6000\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 10.9837 - val_loss: 12.8452\n",
            "Epoch 5097/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 11.1748 - val_loss: 12.8810\n",
            "Epoch 5098/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 11.4277 - val_loss: 12.8826\n",
            "Epoch 5099/6000\n",
            "6/6 [==============================] - 0s 41ms/step - loss: 11.2623 - val_loss: 12.8513\n",
            "Epoch 5100/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 11.0795 - val_loss: 12.9450\n",
            "Epoch 5101/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 11.2366 - val_loss: 12.8523\n",
            "Epoch 5102/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 11.1262 - val_loss: 12.9346\n",
            "Epoch 5103/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 11.0420 - val_loss: 12.8091\n",
            "Epoch 5104/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 11.4138 - val_loss: 12.8618\n",
            "Epoch 5105/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 11.0453 - val_loss: 12.8031\n",
            "Epoch 5106/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 11.3249 - val_loss: 12.8612\n",
            "Epoch 5107/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 11.4293 - val_loss: 12.8908\n",
            "Epoch 5108/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 11.1983 - val_loss: 12.8222\n",
            "Epoch 5109/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 11.0115 - val_loss: 12.7860\n",
            "Epoch 5110/6000\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 11.2211 - val_loss: 12.9436\n",
            "Epoch 5111/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 11.2954 - val_loss: 12.7853\n",
            "Epoch 5112/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 11.1291 - val_loss: 12.8326\n",
            "Epoch 5113/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 11.1443 - val_loss: 12.9216\n",
            "Epoch 5114/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 11.0967 - val_loss: 12.9165\n",
            "Epoch 5115/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 11.2321 - val_loss: 12.8493\n",
            "Epoch 5116/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 10.9905 - val_loss: 12.8649\n",
            "Epoch 5117/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 11.2080 - val_loss: 12.9254\n",
            "Epoch 5118/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 11.0945 - val_loss: 12.9624\n",
            "Epoch 5119/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 11.2559 - val_loss: 12.8624\n",
            "Epoch 5120/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 11.0097 - val_loss: 12.7773\n",
            "Epoch 5121/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 11.2555 - val_loss: 12.8827\n",
            "Epoch 5122/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 11.0964 - val_loss: 12.7798\n",
            "Epoch 5123/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 11.2354 - val_loss: 12.8634\n",
            "Epoch 5124/6000\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 11.0348 - val_loss: 12.8810\n",
            "Epoch 5125/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 11.3244 - val_loss: 12.8721\n",
            "Epoch 5126/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 11.1884 - val_loss: 12.8441\n",
            "Epoch 5127/6000\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 11.0654 - val_loss: 12.9749\n",
            "Epoch 5128/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 11.1248 - val_loss: 12.9485\n",
            "Epoch 5129/6000\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 11.8711 - val_loss: 13.7064\n",
            "Epoch 5130/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 12.2668 - val_loss: 13.6633\n",
            "Epoch 5131/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 11.9548 - val_loss: 13.6055\n",
            "Epoch 5132/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 11.7372 - val_loss: 13.4747\n",
            "Epoch 5133/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 11.6947 - val_loss: 13.2994\n",
            "Epoch 5134/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 11.4860 - val_loss: 13.4207\n",
            "Epoch 5135/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 11.6171 - val_loss: 13.4799\n",
            "Epoch 5136/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 11.3724 - val_loss: 13.1952\n",
            "Epoch 5137/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 11.5181 - val_loss: 13.2570\n",
            "Epoch 5138/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 11.1896 - val_loss: 13.1772\n",
            "Epoch 5139/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 11.3813 - val_loss: 13.1574\n",
            "Epoch 5140/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 11.2782 - val_loss: 13.0515\n",
            "Epoch 5141/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 11.1381 - val_loss: 12.9396\n",
            "Epoch 5142/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 11.1240 - val_loss: 13.1945\n",
            "Epoch 5143/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 11.2895 - val_loss: 12.9550\n",
            "Epoch 5144/6000\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 11.2636 - val_loss: 13.2727\n",
            "Epoch 5145/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 11.0214 - val_loss: 13.2051\n",
            "Epoch 5146/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 11.1679 - val_loss: 13.0903\n",
            "Epoch 5147/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 11.1654 - val_loss: 13.1158\n",
            "Epoch 5148/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 10.9692 - val_loss: 12.8224\n",
            "Epoch 5149/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 11.1417 - val_loss: 13.0630\n",
            "Epoch 5150/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 11.0107 - val_loss: 12.8748\n",
            "Epoch 5151/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 10.9741 - val_loss: 13.0946\n",
            "Epoch 5152/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 10.9604 - val_loss: 12.8164\n",
            "Epoch 5153/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 10.9930 - val_loss: 12.9041\n",
            "Epoch 5154/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 10.8612 - val_loss: 12.8150\n",
            "Epoch 5155/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 10.9017 - val_loss: 12.8368\n",
            "Epoch 5156/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 11.0783 - val_loss: 12.8621\n",
            "Epoch 5157/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 11.1413 - val_loss: 12.8105\n",
            "Epoch 5158/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 11.1256 - val_loss: 12.7721\n",
            "Epoch 5159/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 11.1621 - val_loss: 12.8854\n",
            "Epoch 5160/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 11.4221 - val_loss: 12.8750\n",
            "Epoch 5161/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 11.1655 - val_loss: 12.9286\n",
            "Epoch 5162/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 10.9896 - val_loss: 13.0093\n",
            "Epoch 5163/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 11.0346 - val_loss: 13.0813\n",
            "Epoch 5164/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 10.9285 - val_loss: 13.0297\n",
            "Epoch 5165/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 11.0089 - val_loss: 13.0194\n",
            "Epoch 5166/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 11.1066 - val_loss: 13.0199\n",
            "Epoch 5167/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 11.1084 - val_loss: 13.0463\n",
            "Epoch 5168/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 11.2112 - val_loss: 12.8935\n",
            "Epoch 5169/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 11.0696 - val_loss: 13.0132\n",
            "Epoch 5170/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 11.0871 - val_loss: 12.9868\n",
            "Epoch 5171/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 10.8486 - val_loss: 12.9566\n",
            "Epoch 5172/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 11.1135 - val_loss: 13.2420\n",
            "Epoch 5173/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 11.0454 - val_loss: 12.8265\n",
            "Epoch 5174/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 11.0081 - val_loss: 13.0537\n",
            "Epoch 5175/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 10.7746 - val_loss: 12.8706\n",
            "Epoch 5176/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 11.2224 - val_loss: 12.8198\n",
            "Epoch 5177/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 10.8998 - val_loss: 12.7237\n",
            "Epoch 5178/6000\n",
            "6/6 [==============================] - 0s 40ms/step - loss: 11.0024 - val_loss: 12.8706\n",
            "Epoch 5179/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 10.9237 - val_loss: 12.6684\n",
            "Epoch 5180/6000\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 10.8694 - val_loss: 12.7881\n",
            "Epoch 5181/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 10.8741 - val_loss: 12.6460\n",
            "Epoch 5182/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 11.0458 - val_loss: 12.8022\n",
            "Epoch 5183/6000\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 11.0489 - val_loss: 12.9890\n",
            "Epoch 5184/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 11.0876 - val_loss: 12.8905\n",
            "Epoch 5185/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 11.1147 - val_loss: 13.1850\n",
            "Epoch 5186/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 10.9262 - val_loss: 13.1261\n",
            "Epoch 5187/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 11.0418 - val_loss: 12.9630\n",
            "Epoch 5188/6000\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 10.9066 - val_loss: 12.8012\n",
            "Epoch 5189/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 11.0420 - val_loss: 12.8919\n",
            "Epoch 5190/6000\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 10.7657 - val_loss: 12.9694\n",
            "Epoch 5191/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 10.9787 - val_loss: 12.7715\n",
            "Epoch 5192/6000\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 10.9698 - val_loss: 12.8232\n",
            "Epoch 5193/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 10.8914 - val_loss: 12.7059\n",
            "Epoch 5194/6000\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 11.0058 - val_loss: 12.8468\n",
            "Epoch 5195/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 10.9846 - val_loss: 12.9964\n",
            "Epoch 5196/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 10.7867 - val_loss: 12.9729\n",
            "Epoch 5197/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 10.7793 - val_loss: 13.0158\n",
            "Epoch 5198/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 11.1845 - val_loss: 13.0024\n",
            "Epoch 5199/6000\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 10.9697 - val_loss: 12.9381\n",
            "Epoch 5200/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 10.8520 - val_loss: 12.9883\n",
            "Epoch 5201/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 10.8446 - val_loss: 12.8174\n",
            "Epoch 5202/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 10.8255 - val_loss: 12.8183\n",
            "Epoch 5203/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 10.9930 - val_loss: 12.7102\n",
            "Epoch 5204/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 10.9460 - val_loss: 12.6480\n",
            "Epoch 5205/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 10.9180 - val_loss: 12.8747\n",
            "Epoch 5206/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 10.8221 - val_loss: 12.7723\n",
            "Epoch 5207/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 11.0218 - val_loss: 12.8026\n",
            "Epoch 5208/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 10.9086 - val_loss: 12.7286\n",
            "Epoch 5209/6000\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 10.8637 - val_loss: 12.7791\n",
            "Epoch 5210/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 10.8275 - val_loss: 12.7207\n",
            "Epoch 5211/6000\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 10.8381 - val_loss: 12.8099\n",
            "Epoch 5212/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 10.6998 - val_loss: 12.6956\n",
            "Epoch 5213/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 10.7550 - val_loss: 12.6682\n",
            "Epoch 5214/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 10.6769 - val_loss: 12.6578\n",
            "Epoch 5215/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 10.7916 - val_loss: 12.5902\n",
            "Epoch 5216/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 10.7991 - val_loss: 12.5985\n",
            "Epoch 5217/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 10.7275 - val_loss: 12.4893\n",
            "Epoch 5218/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 10.8193 - val_loss: 12.5365\n",
            "Epoch 5219/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 10.9990 - val_loss: 12.5412\n",
            "Epoch 5220/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 10.7527 - val_loss: 12.5924\n",
            "Epoch 5221/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 10.7626 - val_loss: 12.6135\n",
            "Epoch 5222/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 10.7284 - val_loss: 12.5171\n",
            "Epoch 5223/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 10.7989 - val_loss: 12.5372\n",
            "Epoch 5224/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 10.8089 - val_loss: 12.6192\n",
            "Epoch 5225/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 10.6708 - val_loss: 12.5126\n",
            "Epoch 5226/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 10.7665 - val_loss: 12.6045\n",
            "Epoch 5227/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 10.8656 - val_loss: 12.5064\n",
            "Epoch 5228/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 10.7457 - val_loss: 12.6169\n",
            "Epoch 5229/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 10.7409 - val_loss: 12.4919\n",
            "Epoch 5230/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 10.7603 - val_loss: 12.5013\n",
            "Epoch 5231/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 10.7993 - val_loss: 12.5706\n",
            "Epoch 5232/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 10.6056 - val_loss: 12.5899\n",
            "Epoch 5233/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 10.8425 - val_loss: 12.5533\n",
            "Epoch 5234/6000\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 10.6912 - val_loss: 12.5230\n",
            "Epoch 5235/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 10.8241 - val_loss: 12.4767\n",
            "Epoch 5236/6000\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 10.7344 - val_loss: 12.5047\n",
            "Epoch 5237/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 10.7273 - val_loss: 12.4805\n",
            "Epoch 5238/6000\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 10.7892 - val_loss: 12.5536\n",
            "Epoch 5239/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 10.8554 - val_loss: 12.5948\n",
            "Epoch 5240/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 10.6955 - val_loss: 12.5869\n",
            "Epoch 5241/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 10.7066 - val_loss: 12.6602\n",
            "Epoch 5242/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 10.7167 - val_loss: 12.5031\n",
            "Epoch 5243/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 11.0033 - val_loss: 12.5289\n",
            "Epoch 5244/6000\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 10.8053 - val_loss: 12.5566\n",
            "Epoch 5245/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 10.7484 - val_loss: 12.4530\n",
            "Epoch 5246/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 10.7238 - val_loss: 12.5563\n",
            "Epoch 5247/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 11.1572 - val_loss: 12.5152\n",
            "Epoch 5248/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 10.6382 - val_loss: 12.6121\n",
            "Epoch 5249/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 10.7065 - val_loss: 12.5646\n",
            "Epoch 5250/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 10.7744 - val_loss: 12.5480\n",
            "Epoch 5251/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 10.9864 - val_loss: 12.5790\n",
            "Epoch 5252/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 10.8619 - val_loss: 12.4612\n",
            "Epoch 5253/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 10.5556 - val_loss: 12.4637\n",
            "Epoch 5254/6000\n",
            "6/6 [==============================] - 0s 40ms/step - loss: 10.6709 - val_loss: 12.3784\n",
            "Epoch 5255/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 10.6653 - val_loss: 12.4387\n",
            "Epoch 5256/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 10.6018 - val_loss: 12.3853\n",
            "Epoch 5257/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 10.7504 - val_loss: 12.3704\n",
            "Epoch 5258/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 10.6337 - val_loss: 12.3096\n",
            "Epoch 5259/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 10.5165 - val_loss: 12.3901\n",
            "Epoch 5260/6000\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 10.8333 - val_loss: 12.3285\n",
            "Epoch 5261/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 10.6873 - val_loss: 12.4055\n",
            "Epoch 5262/6000\n",
            "6/6 [==============================] - 0s 39ms/step - loss: 10.6255 - val_loss: 12.3834\n",
            "Epoch 5263/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 11.0620 - val_loss: 12.3849\n",
            "Epoch 5264/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 10.8471 - val_loss: 12.4458\n",
            "Epoch 5265/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 10.6974 - val_loss: 12.4524\n",
            "Epoch 5266/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 10.6714 - val_loss: 12.3397\n",
            "Epoch 5267/6000\n",
            "6/6 [==============================] - 0s 39ms/step - loss: 10.4509 - val_loss: 12.2860\n",
            "Epoch 5268/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 10.5676 - val_loss: 12.4156\n",
            "Epoch 5269/6000\n",
            "6/6 [==============================] - 0s 39ms/step - loss: 10.9873 - val_loss: 12.3368\n",
            "Epoch 5270/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 10.6608 - val_loss: 12.4408\n",
            "Epoch 5271/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 10.5470 - val_loss: 12.4129\n",
            "Epoch 5272/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 10.7026 - val_loss: 12.5643\n",
            "Epoch 5273/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 10.5887 - val_loss: 12.4208\n",
            "Epoch 5274/6000\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 10.5215 - val_loss: 12.4048\n",
            "Epoch 5275/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 10.5727 - val_loss: 12.4264\n",
            "Epoch 5276/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 10.5864 - val_loss: 12.4054\n",
            "Epoch 5277/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 10.8080 - val_loss: 12.4159\n",
            "Epoch 5278/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 10.5452 - val_loss: 12.3206\n",
            "Epoch 5279/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 10.6665 - val_loss: 12.3982\n",
            "Epoch 5280/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 10.6004 - val_loss: 12.4030\n",
            "Epoch 5281/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 10.5380 - val_loss: 12.3945\n",
            "Epoch 5282/6000\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 10.6454 - val_loss: 12.3172\n",
            "Epoch 5283/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 10.9647 - val_loss: 12.4833\n",
            "Epoch 5284/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 10.5053 - val_loss: 12.2741\n",
            "Epoch 5285/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 10.7778 - val_loss: 12.5636\n",
            "Epoch 5286/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 10.5681 - val_loss: 12.4409\n",
            "Epoch 5287/6000\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 10.4395 - val_loss: 12.4248\n",
            "Epoch 5288/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 10.4953 - val_loss: 12.3314\n",
            "Epoch 5289/6000\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 10.6497 - val_loss: 12.3038\n",
            "Epoch 5290/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 10.3637 - val_loss: 12.2110\n",
            "Epoch 5291/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 10.4606 - val_loss: 12.2214\n",
            "Epoch 5292/6000\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 10.4273 - val_loss: 12.2400\n",
            "Epoch 5293/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 10.6440 - val_loss: 12.1955\n",
            "Epoch 5294/6000\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 10.3702 - val_loss: 12.2515\n",
            "Epoch 5295/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 10.4774 - val_loss: 12.1787\n",
            "Epoch 5296/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 10.3884 - val_loss: 12.2099\n",
            "Epoch 5297/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 10.7775 - val_loss: 12.1684\n",
            "Epoch 5298/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 10.5967 - val_loss: 12.3005\n",
            "Epoch 5299/6000\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 10.6410 - val_loss: 12.1688\n",
            "Epoch 5300/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 10.7215 - val_loss: 12.2137\n",
            "Epoch 5301/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 10.5857 - val_loss: 12.1710\n",
            "Epoch 5302/6000\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 10.6746 - val_loss: 12.3732\n",
            "Epoch 5303/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 10.5298 - val_loss: 12.1756\n",
            "Epoch 5304/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 10.4060 - val_loss: 12.2599\n",
            "Epoch 5305/6000\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 10.8408 - val_loss: 12.2545\n",
            "Epoch 5306/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 10.4110 - val_loss: 12.2324\n",
            "Epoch 5307/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 10.5154 - val_loss: 12.3393\n",
            "Epoch 5308/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 10.6186 - val_loss: 12.2640\n",
            "Epoch 5309/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 10.5193 - val_loss: 12.2371\n",
            "Epoch 5310/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 10.5661 - val_loss: 12.3595\n",
            "Epoch 5311/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 10.4922 - val_loss: 12.3207\n",
            "Epoch 5312/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 10.6858 - val_loss: 12.3434\n",
            "Epoch 5313/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 10.7376 - val_loss: 12.4824\n",
            "Epoch 5314/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 10.4121 - val_loss: 12.5028\n",
            "Epoch 5315/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 10.5879 - val_loss: 12.4514\n",
            "Epoch 5316/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 10.4642 - val_loss: 12.4231\n",
            "Epoch 5317/6000\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 10.3774 - val_loss: 12.4594\n",
            "Epoch 5318/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 10.6080 - val_loss: 12.2730\n",
            "Epoch 5319/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 10.5832 - val_loss: 12.3314\n",
            "Epoch 5320/6000\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 10.6228 - val_loss: 12.2916\n",
            "Epoch 5321/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 10.4734 - val_loss: 12.3105\n",
            "Epoch 5322/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 10.6506 - val_loss: 12.2162\n",
            "Epoch 5323/6000\n",
            "6/6 [==============================] - 0s 39ms/step - loss: 10.4372 - val_loss: 12.3044\n",
            "Epoch 5324/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 10.5070 - val_loss: 12.2108\n",
            "Epoch 5325/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 10.4870 - val_loss: 12.2198\n",
            "Epoch 5326/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 10.3741 - val_loss: 12.2759\n",
            "Epoch 5327/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 10.4002 - val_loss: 12.1907\n",
            "Epoch 5328/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 10.7031 - val_loss: 12.4689\n",
            "Epoch 5329/6000\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 10.9658 - val_loss: 12.3418\n",
            "Epoch 5330/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 10.5216 - val_loss: 12.4384\n",
            "Epoch 5331/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 10.5046 - val_loss: 12.3946\n",
            "Epoch 5332/6000\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 10.4357 - val_loss: 12.4121\n",
            "Epoch 5333/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 10.8406 - val_loss: 12.5455\n",
            "Epoch 5334/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 10.5591 - val_loss: 12.5527\n",
            "Epoch 5335/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 10.7879 - val_loss: 12.6511\n",
            "Epoch 5336/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 10.3988 - val_loss: 12.3412\n",
            "Epoch 5337/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 10.7857 - val_loss: 12.4742\n",
            "Epoch 5338/6000\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 10.4967 - val_loss: 12.4492\n",
            "Epoch 5339/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 10.6001 - val_loss: 12.4310\n",
            "Epoch 5340/6000\n",
            "6/6 [==============================] - 0s 39ms/step - loss: 10.7534 - val_loss: 12.3714\n",
            "Epoch 5341/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 10.3938 - val_loss: 12.3431\n",
            "Epoch 5342/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 10.3451 - val_loss: 12.1339\n",
            "Epoch 5343/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 10.5792 - val_loss: 12.2383\n",
            "Epoch 5344/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 10.5639 - val_loss: 12.1684\n",
            "Epoch 5345/6000\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 10.3701 - val_loss: 12.1976\n",
            "Epoch 5346/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 10.3947 - val_loss: 12.0939\n",
            "Epoch 5347/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 10.3170 - val_loss: 12.1968\n",
            "Epoch 5348/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 10.3842 - val_loss: 12.1232\n",
            "Epoch 5349/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 10.3137 - val_loss: 12.0743\n",
            "Epoch 5350/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 10.3563 - val_loss: 12.1063\n",
            "Epoch 5351/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 10.2957 - val_loss: 12.0510\n",
            "Epoch 5352/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 10.3991 - val_loss: 12.1437\n",
            "Epoch 5353/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 10.3031 - val_loss: 12.2046\n",
            "Epoch 5354/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 10.4580 - val_loss: 12.0248\n",
            "Epoch 5355/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 10.2507 - val_loss: 12.0656\n",
            "Epoch 5356/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 10.3756 - val_loss: 12.1080\n",
            "Epoch 5357/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 10.2162 - val_loss: 12.0855\n",
            "Epoch 5358/6000\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 10.3403 - val_loss: 12.1376\n",
            "Epoch 5359/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 10.1733 - val_loss: 12.0442\n",
            "Epoch 5360/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 10.5297 - val_loss: 12.1067\n",
            "Epoch 5361/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 10.3961 - val_loss: 12.1620\n",
            "Epoch 5362/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 10.2323 - val_loss: 12.0516\n",
            "Epoch 5363/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 10.3456 - val_loss: 12.0402\n",
            "Epoch 5364/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 10.4914 - val_loss: 12.1358\n",
            "Epoch 5365/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 10.2528 - val_loss: 12.0851\n",
            "Epoch 5366/6000\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 10.3970 - val_loss: 12.0193\n",
            "Epoch 5367/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 10.2791 - val_loss: 12.0216\n",
            "Epoch 5368/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 10.5169 - val_loss: 12.1476\n",
            "Epoch 5369/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 10.4744 - val_loss: 12.0541\n",
            "Epoch 5370/6000\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 10.4164 - val_loss: 12.0278\n",
            "Epoch 5371/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 10.2890 - val_loss: 12.1635\n",
            "Epoch 5372/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 10.4182 - val_loss: 12.1495\n",
            "Epoch 5373/6000\n",
            "6/6 [==============================] - 0s 39ms/step - loss: 10.8501 - val_loss: 12.0063\n",
            "Epoch 5374/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 10.3916 - val_loss: 12.2705\n",
            "Epoch 5375/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 10.4897 - val_loss: 12.0565\n",
            "Epoch 5376/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 10.2963 - val_loss: 12.2053\n",
            "Epoch 5377/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 10.4804 - val_loss: 12.2319\n",
            "Epoch 5378/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 10.3139 - val_loss: 12.1566\n",
            "Epoch 5379/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 10.6187 - val_loss: 12.3615\n",
            "Epoch 5380/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 10.4388 - val_loss: 12.1865\n",
            "Epoch 5381/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 10.4841 - val_loss: 12.3347\n",
            "Epoch 5382/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 10.3193 - val_loss: 12.1394\n",
            "Epoch 5383/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 10.5613 - val_loss: 12.3612\n",
            "Epoch 5384/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 10.3998 - val_loss: 12.2108\n",
            "Epoch 5385/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 10.3784 - val_loss: 12.1918\n",
            "Epoch 5386/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 10.2604 - val_loss: 12.1523\n",
            "Epoch 5387/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 10.2930 - val_loss: 12.1977\n",
            "Epoch 5388/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 10.1550 - val_loss: 11.9851\n",
            "Epoch 5389/6000\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 10.2312 - val_loss: 12.0186\n",
            "Epoch 5390/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 10.3329 - val_loss: 11.9893\n",
            "Epoch 5391/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 10.2433 - val_loss: 12.0507\n",
            "Epoch 5392/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 10.3144 - val_loss: 12.0155\n",
            "Epoch 5393/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 10.3163 - val_loss: 12.1316\n",
            "Epoch 5394/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 10.4371 - val_loss: 11.9400\n",
            "Epoch 5395/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 10.2338 - val_loss: 12.0164\n",
            "Epoch 5396/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 10.1600 - val_loss: 11.9289\n",
            "Epoch 5397/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 10.4820 - val_loss: 11.9792\n",
            "Epoch 5398/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 10.1644 - val_loss: 12.0284\n",
            "Epoch 5399/6000\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 10.6556 - val_loss: 11.9459\n",
            "Epoch 5400/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 10.4697 - val_loss: 12.0558\n",
            "Epoch 5401/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 10.2722 - val_loss: 11.9992\n",
            "Epoch 5402/6000\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 10.3770 - val_loss: 12.1299\n",
            "Epoch 5403/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 10.3238 - val_loss: 12.1362\n",
            "Epoch 5404/6000\n",
            "6/6 [==============================] - 0s 40ms/step - loss: 10.4257 - val_loss: 12.1632\n",
            "Epoch 5405/6000\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 10.2716 - val_loss: 12.2231\n",
            "Epoch 5406/6000\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 10.2804 - val_loss: 12.0561\n",
            "Epoch 5407/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 10.1851 - val_loss: 12.0069\n",
            "Epoch 5408/6000\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 10.0911 - val_loss: 12.0683\n",
            "Epoch 5409/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 10.3598 - val_loss: 11.9051\n",
            "Epoch 5410/6000\n",
            "6/6 [==============================] - 0s 40ms/step - loss: 10.3412 - val_loss: 12.0879\n",
            "Epoch 5411/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 10.2608 - val_loss: 11.9576\n",
            "Epoch 5412/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 10.2697 - val_loss: 12.0699\n",
            "Epoch 5413/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 10.1697 - val_loss: 12.0002\n",
            "Epoch 5414/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 10.3317 - val_loss: 12.0245\n",
            "Epoch 5415/6000\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 10.1090 - val_loss: 12.0818\n",
            "Epoch 5416/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 10.1807 - val_loss: 11.9940\n",
            "Epoch 5417/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 10.2649 - val_loss: 11.9355\n",
            "Epoch 5418/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 10.1581 - val_loss: 11.9938\n",
            "Epoch 5419/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 10.1354 - val_loss: 11.9808\n",
            "Epoch 5420/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 10.0232 - val_loss: 11.9608\n",
            "Epoch 5421/6000\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 10.0560 - val_loss: 11.9929\n",
            "Epoch 5422/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 10.1611 - val_loss: 11.9100\n",
            "Epoch 5423/6000\n",
            "6/6 [==============================] - 0s 39ms/step - loss: 10.1040 - val_loss: 11.9660\n",
            "Epoch 5424/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 10.3264 - val_loss: 11.9720\n",
            "Epoch 5425/6000\n",
            "6/6 [==============================] - 0s 39ms/step - loss: 10.1927 - val_loss: 11.9315\n",
            "Epoch 5426/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 10.2643 - val_loss: 11.9571\n",
            "Epoch 5427/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 10.3405 - val_loss: 12.1165\n",
            "Epoch 5428/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 10.2688 - val_loss: 11.9937\n",
            "Epoch 5429/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 10.3323 - val_loss: 12.0827\n",
            "Epoch 5430/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 10.4604 - val_loss: 11.9426\n",
            "Epoch 5431/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 10.0975 - val_loss: 12.1346\n",
            "Epoch 5432/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 10.2259 - val_loss: 12.0722\n",
            "Epoch 5433/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 10.1640 - val_loss: 11.9865\n",
            "Epoch 5434/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 9.9543 - val_loss: 11.9456\n",
            "Epoch 5435/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 10.4967 - val_loss: 11.8973\n",
            "Epoch 5436/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 10.0130 - val_loss: 11.9864\n",
            "Epoch 5437/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 10.0595 - val_loss: 11.8782\n",
            "Epoch 5438/6000\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 10.1529 - val_loss: 11.9737\n",
            "Epoch 5439/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 10.2000 - val_loss: 12.0639\n",
            "Epoch 5440/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 10.3239 - val_loss: 11.9878\n",
            "Epoch 5441/6000\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 10.0074 - val_loss: 12.1346\n",
            "Epoch 5442/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 10.1242 - val_loss: 11.9572\n",
            "Epoch 5443/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 10.1414 - val_loss: 12.0876\n",
            "Epoch 5444/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 10.0529 - val_loss: 11.8947\n",
            "Epoch 5445/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 10.0880 - val_loss: 11.9819\n",
            "Epoch 5446/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 10.0773 - val_loss: 11.9473\n",
            "Epoch 5447/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 10.0866 - val_loss: 11.9197\n",
            "Epoch 5448/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 10.1953 - val_loss: 12.1761\n",
            "Epoch 5449/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 10.3301 - val_loss: 11.9149\n",
            "Epoch 5450/6000\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 10.2083 - val_loss: 12.1144\n",
            "Epoch 5451/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 10.6782 - val_loss: 12.0799\n",
            "Epoch 5452/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 10.0719 - val_loss: 12.0408\n",
            "Epoch 5453/6000\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 10.0302 - val_loss: 12.0843\n",
            "Epoch 5454/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 10.1980 - val_loss: 12.1447\n",
            "Epoch 5455/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 10.2491 - val_loss: 12.0241\n",
            "Epoch 5456/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 10.1867 - val_loss: 11.8677\n",
            "Epoch 5457/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 10.3137 - val_loss: 12.0886\n",
            "Epoch 5458/6000\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 10.0680 - val_loss: 11.9368\n",
            "Epoch 5459/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 10.1441 - val_loss: 11.9115\n",
            "Epoch 5460/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 10.1275 - val_loss: 12.0299\n",
            "Epoch 5461/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 10.0965 - val_loss: 11.9011\n",
            "Epoch 5462/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 10.1704 - val_loss: 12.0988\n",
            "Epoch 5463/6000\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 10.1994 - val_loss: 12.1339\n",
            "Epoch 5464/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 10.2064 - val_loss: 12.0238\n",
            "Epoch 5465/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 10.2705 - val_loss: 12.0374\n",
            "Epoch 5466/6000\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 10.3257 - val_loss: 11.9847\n",
            "Epoch 5467/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 10.0713 - val_loss: 11.9221\n",
            "Epoch 5468/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 10.1171 - val_loss: 11.9561\n",
            "Epoch 5469/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 10.0060 - val_loss: 11.8658\n",
            "Epoch 5470/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 9.8488 - val_loss: 11.8075\n",
            "Epoch 5471/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 10.0307 - val_loss: 11.8550\n",
            "Epoch 5472/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 10.4137 - val_loss: 11.8130\n",
            "Epoch 5473/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 10.4727 - val_loss: 12.1939\n",
            "Epoch 5474/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 10.1433 - val_loss: 11.8918\n",
            "Epoch 5475/6000\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 10.1575 - val_loss: 11.9899\n",
            "Epoch 5476/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 10.0835 - val_loss: 11.9507\n",
            "Epoch 5477/6000\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 10.1401 - val_loss: 11.9825\n",
            "Epoch 5478/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 10.1127 - val_loss: 11.8711\n",
            "Epoch 5479/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 9.8743 - val_loss: 11.8695\n",
            "Epoch 5480/6000\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 9.8468 - val_loss: 11.8084\n",
            "Epoch 5481/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 9.8955 - val_loss: 11.8658\n",
            "Epoch 5482/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 9.9924 - val_loss: 11.7640\n",
            "Epoch 5483/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 10.0531 - val_loss: 11.8148\n",
            "Epoch 5484/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 9.9800 - val_loss: 11.8834\n",
            "Epoch 5485/6000\n",
            "6/6 [==============================] - 0s 39ms/step - loss: 9.8538 - val_loss: 11.8487\n",
            "Epoch 5486/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 9.9650 - val_loss: 11.8884\n",
            "Epoch 5487/6000\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 10.2226 - val_loss: 11.7610\n",
            "Epoch 5488/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 9.8849 - val_loss: 11.8207\n",
            "Epoch 5489/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 10.1095 - val_loss: 11.8798\n",
            "Epoch 5490/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 10.0846 - val_loss: 11.8191\n",
            "Epoch 5491/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 10.3445 - val_loss: 11.9710\n",
            "Epoch 5492/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 10.0306 - val_loss: 11.9333\n",
            "Epoch 5493/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 10.0790 - val_loss: 11.9203\n",
            "Epoch 5494/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 10.0658 - val_loss: 12.3083\n",
            "Epoch 5495/6000\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 10.2932 - val_loss: 11.8342\n",
            "Epoch 5496/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 10.1578 - val_loss: 12.2673\n",
            "Epoch 5497/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 10.0230 - val_loss: 12.0399\n",
            "Epoch 5498/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 9.9476 - val_loss: 12.0396\n",
            "Epoch 5499/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 10.2567 - val_loss: 12.1262\n",
            "Epoch 5500/6000\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 10.0004 - val_loss: 12.0811\n",
            "Epoch 5501/6000\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 9.9951 - val_loss: 12.2163\n",
            "Epoch 5502/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 9.9296 - val_loss: 11.9992\n",
            "Epoch 5503/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 10.0110 - val_loss: 12.0897\n",
            "Epoch 5504/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 10.0692 - val_loss: 11.8427\n",
            "Epoch 5505/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 9.8701 - val_loss: 11.8961\n",
            "Epoch 5506/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 9.9188 - val_loss: 11.7599\n",
            "Epoch 5507/6000\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 9.8742 - val_loss: 11.7925\n",
            "Epoch 5508/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 9.8743 - val_loss: 11.7289\n",
            "Epoch 5509/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 10.1702 - val_loss: 11.9089\n",
            "Epoch 5510/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 9.9041 - val_loss: 11.7086\n",
            "Epoch 5511/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 9.9617 - val_loss: 11.8559\n",
            "Epoch 5512/6000\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 9.9168 - val_loss: 11.6749\n",
            "Epoch 5513/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 10.2087 - val_loss: 11.7706\n",
            "Epoch 5514/6000\n",
            "6/6 [==============================] - 0s 41ms/step - loss: 9.8375 - val_loss: 11.7155\n",
            "Epoch 5515/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 9.9975 - val_loss: 11.7875\n",
            "Epoch 5516/6000\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 9.8385 - val_loss: 11.8078\n",
            "Epoch 5517/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 9.9545 - val_loss: 11.7957\n",
            "Epoch 5518/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 10.2817 - val_loss: 11.9234\n",
            "Epoch 5519/6000\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 10.0512 - val_loss: 11.7516\n",
            "Epoch 5520/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 10.1524 - val_loss: 12.0020\n",
            "Epoch 5521/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 9.9226 - val_loss: 11.7717\n",
            "Epoch 5522/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 9.8910 - val_loss: 11.7528\n",
            "Epoch 5523/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 9.8871 - val_loss: 11.7992\n",
            "Epoch 5524/6000\n",
            "6/6 [==============================] - 0s 40ms/step - loss: 9.9724 - val_loss: 11.7151\n",
            "Epoch 5525/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 9.8395 - val_loss: 11.6713\n",
            "Epoch 5526/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 9.9998 - val_loss: 11.7472\n",
            "Epoch 5527/6000\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 10.1580 - val_loss: 11.7595\n",
            "Epoch 5528/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 9.9666 - val_loss: 11.7749\n",
            "Epoch 5529/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 9.7464 - val_loss: 11.6504\n",
            "Epoch 5530/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 9.8044 - val_loss: 11.7017\n",
            "Epoch 5531/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 9.7950 - val_loss: 11.6077\n",
            "Epoch 5532/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 9.8659 - val_loss: 11.7418\n",
            "Epoch 5533/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 9.8416 - val_loss: 11.5454\n",
            "Epoch 5534/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 9.9215 - val_loss: 11.7021\n",
            "Epoch 5535/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 9.8771 - val_loss: 11.7438\n",
            "Epoch 5536/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 10.0189 - val_loss: 11.5930\n",
            "Epoch 5537/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 10.0089 - val_loss: 11.7046\n",
            "Epoch 5538/6000\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 9.9418 - val_loss: 11.6578\n",
            "Epoch 5539/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 9.7141 - val_loss: 11.6499\n",
            "Epoch 5540/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 9.9358 - val_loss: 11.6351\n",
            "Epoch 5541/6000\n",
            "6/6 [==============================] - 0s 41ms/step - loss: 9.7563 - val_loss: 11.6249\n",
            "Epoch 5542/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 9.9842 - val_loss: 11.6337\n",
            "Epoch 5543/6000\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 10.1261 - val_loss: 11.7251\n",
            "Epoch 5544/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 9.9177 - val_loss: 11.5989\n",
            "Epoch 5545/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 9.8028 - val_loss: 11.6919\n",
            "Epoch 5546/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 9.8667 - val_loss: 11.5354\n",
            "Epoch 5547/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 9.8047 - val_loss: 11.6392\n",
            "Epoch 5548/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 9.7351 - val_loss: 11.5559\n",
            "Epoch 5549/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 10.0671 - val_loss: 11.5945\n",
            "Epoch 5550/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 9.9281 - val_loss: 11.7393\n",
            "Epoch 5551/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 9.8970 - val_loss: 11.6977\n",
            "Epoch 5552/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 9.9296 - val_loss: 11.6847\n",
            "Epoch 5553/6000\n",
            "6/6 [==============================] - 0s 39ms/step - loss: 9.7086 - val_loss: 11.5885\n",
            "Epoch 5554/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 9.8647 - val_loss: 11.5796\n",
            "Epoch 5555/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 9.6834 - val_loss: 11.4995\n",
            "Epoch 5556/6000\n",
            "6/6 [==============================] - 0s 39ms/step - loss: 10.1153 - val_loss: 11.5512\n",
            "Epoch 5557/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 9.9081 - val_loss: 11.5991\n",
            "Epoch 5558/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 9.7394 - val_loss: 11.5946\n",
            "Epoch 5559/6000\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 9.8274 - val_loss: 11.7151\n",
            "Epoch 5560/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 9.6913 - val_loss: 11.8068\n",
            "Epoch 5561/6000\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 9.8480 - val_loss: 11.6329\n",
            "Epoch 5562/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 9.7828 - val_loss: 11.6868\n",
            "Epoch 5563/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 10.0236 - val_loss: 11.9230\n",
            "Epoch 5564/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 9.7104 - val_loss: 11.7089\n",
            "Epoch 5565/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 9.9988 - val_loss: 11.8727\n",
            "Epoch 5566/6000\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 10.3077 - val_loss: 11.9700\n",
            "Epoch 5567/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 10.1833 - val_loss: 11.8593\n",
            "Epoch 5568/6000\n",
            "6/6 [==============================] - 0s 41ms/step - loss: 10.2560 - val_loss: 12.3529\n",
            "Epoch 5569/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 10.3671 - val_loss: 12.1663\n",
            "Epoch 5570/6000\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 10.5511 - val_loss: 12.6051\n",
            "Epoch 5571/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 10.1626 - val_loss: 12.4071\n",
            "Epoch 5572/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 10.0215 - val_loss: 12.7162\n",
            "Epoch 5573/6000\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 9.8120 - val_loss: 12.3764\n",
            "Epoch 5574/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 9.7600 - val_loss: 12.3043\n",
            "Epoch 5575/6000\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 9.8156 - val_loss: 12.1292\n",
            "Epoch 5576/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 9.7105 - val_loss: 12.0276\n",
            "Epoch 5577/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 9.7854 - val_loss: 12.1030\n",
            "Epoch 5578/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 10.1527 - val_loss: 11.9058\n",
            "Epoch 5579/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 9.7139 - val_loss: 12.1420\n",
            "Epoch 5580/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 9.7473 - val_loss: 12.2023\n",
            "Epoch 5581/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 9.8284 - val_loss: 11.9403\n",
            "Epoch 5582/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 9.6768 - val_loss: 11.9154\n",
            "Epoch 5583/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 9.7194 - val_loss: 11.7856\n",
            "Epoch 5584/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 9.6115 - val_loss: 11.7603\n",
            "Epoch 5585/6000\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 9.6630 - val_loss: 11.9726\n",
            "Epoch 5586/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 9.9575 - val_loss: 11.7693\n",
            "Epoch 5587/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 9.8800 - val_loss: 11.8061\n",
            "Epoch 5588/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 9.8423 - val_loss: 11.9953\n",
            "Epoch 5589/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 9.9333 - val_loss: 11.9665\n",
            "Epoch 5590/6000\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 9.8433 - val_loss: 12.0139\n",
            "Epoch 5591/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 9.7092 - val_loss: 11.9416\n",
            "Epoch 5592/6000\n",
            "6/6 [==============================] - 0s 40ms/step - loss: 9.6966 - val_loss: 12.0782\n",
            "Epoch 5593/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 9.9420 - val_loss: 11.9241\n",
            "Epoch 5594/6000\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 9.7615 - val_loss: 12.0424\n",
            "Epoch 5595/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 9.7822 - val_loss: 11.9576\n",
            "Epoch 5596/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 9.7084 - val_loss: 11.9578\n",
            "Epoch 5597/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 9.8936 - val_loss: 12.0332\n",
            "Epoch 5598/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 10.0421 - val_loss: 12.0890\n",
            "Epoch 5599/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 9.8578 - val_loss: 12.0556\n",
            "Epoch 5600/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 9.8820 - val_loss: 11.8390\n",
            "Epoch 5601/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 9.7104 - val_loss: 11.8716\n",
            "Epoch 5602/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 9.6343 - val_loss: 11.7519\n",
            "Epoch 5603/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 9.7617 - val_loss: 11.8357\n",
            "Epoch 5604/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 9.7039 - val_loss: 11.7812\n",
            "Epoch 5605/6000\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 9.8926 - val_loss: 11.7947\n",
            "Epoch 5606/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 9.7935 - val_loss: 11.5166\n",
            "Epoch 5607/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 9.8692 - val_loss: 11.6601\n",
            "Epoch 5608/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 9.8444 - val_loss: 11.5675\n",
            "Epoch 5609/6000\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 9.8535 - val_loss: 11.5546\n",
            "Epoch 5610/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 9.8512 - val_loss: 11.6286\n",
            "Epoch 5611/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 9.9808 - val_loss: 11.7071\n",
            "Epoch 5612/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 9.8783 - val_loss: 11.6343\n",
            "Epoch 5613/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 9.5145 - val_loss: 11.5470\n",
            "Epoch 5614/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 9.8822 - val_loss: 11.4585\n",
            "Epoch 5615/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 9.5163 - val_loss: 11.5954\n",
            "Epoch 5616/6000\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 9.5237 - val_loss: 11.3898\n",
            "Epoch 5617/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 9.4646 - val_loss: 11.5000\n",
            "Epoch 5618/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 9.5223 - val_loss: 11.4035\n",
            "Epoch 5619/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 9.5306 - val_loss: 11.4715\n",
            "Epoch 5620/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 9.6261 - val_loss: 11.5273\n",
            "Epoch 5621/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 9.6416 - val_loss: 11.4064\n",
            "Epoch 5622/6000\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 9.4392 - val_loss: 11.5212\n",
            "Epoch 5623/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 10.0112 - val_loss: 11.4694\n",
            "Epoch 5624/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 9.5579 - val_loss: 11.5114\n",
            "Epoch 5625/6000\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 9.6948 - val_loss: 11.5965\n",
            "Epoch 5626/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 9.8365 - val_loss: 11.5122\n",
            "Epoch 5627/6000\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 9.7692 - val_loss: 11.5920\n",
            "Epoch 5628/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 9.6587 - val_loss: 11.4419\n",
            "Epoch 5629/6000\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 9.6194 - val_loss: 11.5651\n",
            "Epoch 5630/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 9.5888 - val_loss: 11.4737\n",
            "Epoch 5631/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 9.7376 - val_loss: 11.4567\n",
            "Epoch 5632/6000\n",
            "6/6 [==============================] - 0s 40ms/step - loss: 9.6208 - val_loss: 11.4478\n",
            "Epoch 5633/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 9.6545 - val_loss: 11.3470\n",
            "Epoch 5634/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 9.5770 - val_loss: 11.4787\n",
            "Epoch 5635/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 9.6550 - val_loss: 11.4238\n",
            "Epoch 5636/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 9.5949 - val_loss: 11.5517\n",
            "Epoch 5637/6000\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 9.8226 - val_loss: 11.4174\n",
            "Epoch 5638/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 9.5764 - val_loss: 11.4591\n",
            "Epoch 5639/6000\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 9.5331 - val_loss: 11.5109\n",
            "Epoch 5640/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 9.5704 - val_loss: 11.4179\n",
            "Epoch 5641/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 9.5868 - val_loss: 11.4374\n",
            "Epoch 5642/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 9.5934 - val_loss: 11.4128\n",
            "Epoch 5643/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 9.4770 - val_loss: 11.4027\n",
            "Epoch 5644/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 9.4971 - val_loss: 11.4459\n",
            "Epoch 5645/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 9.4190 - val_loss: 11.4003\n",
            "Epoch 5646/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 9.4698 - val_loss: 11.4480\n",
            "Epoch 5647/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 9.5114 - val_loss: 11.4603\n",
            "Epoch 5648/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 9.9375 - val_loss: 11.4588\n",
            "Epoch 5649/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 9.8360 - val_loss: 11.4308\n",
            "Epoch 5650/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 9.6990 - val_loss: 11.4848\n",
            "Epoch 5651/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 10.0813 - val_loss: 11.3326\n",
            "Epoch 5652/6000\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 9.5831 - val_loss: 11.3858\n",
            "Epoch 5653/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 9.4358 - val_loss: 11.3442\n",
            "Epoch 5654/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 9.4733 - val_loss: 11.4347\n",
            "Epoch 5655/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 9.4093 - val_loss: 11.3757\n",
            "Epoch 5656/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 9.5695 - val_loss: 11.3702\n",
            "Epoch 5657/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 9.6857 - val_loss: 11.4944\n",
            "Epoch 5658/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 9.5980 - val_loss: 11.2949\n",
            "Epoch 5659/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 9.8001 - val_loss: 11.3637\n",
            "Epoch 5660/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 9.4581 - val_loss: 11.4352\n",
            "Epoch 5661/6000\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 9.8338 - val_loss: 11.4290\n",
            "Epoch 5662/6000\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 9.5300 - val_loss: 11.4507\n",
            "Epoch 5663/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 9.6132 - val_loss: 11.2958\n",
            "Epoch 5664/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 9.6392 - val_loss: 11.3546\n",
            "Epoch 5665/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 9.4273 - val_loss: 11.3210\n",
            "Epoch 5666/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 9.8203 - val_loss: 11.3871\n",
            "Epoch 5667/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 9.4857 - val_loss: 11.3052\n",
            "Epoch 5668/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 9.3995 - val_loss: 11.2916\n",
            "Epoch 5669/6000\n",
            "6/6 [==============================] - 0s 39ms/step - loss: 9.5441 - val_loss: 11.2644\n",
            "Epoch 5670/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 9.7886 - val_loss: 11.4524\n",
            "Epoch 5671/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 9.5474 - val_loss: 11.3389\n",
            "Epoch 5672/6000\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 9.4668 - val_loss: 11.4223\n",
            "Epoch 5673/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 9.5436 - val_loss: 11.3689\n",
            "Epoch 5674/6000\n",
            "6/6 [==============================] - 0s 40ms/step - loss: 9.4890 - val_loss: 11.4020\n",
            "Epoch 5675/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 9.4071 - val_loss: 11.4599\n",
            "Epoch 5676/6000\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 9.6661 - val_loss: 11.5077\n",
            "Epoch 5677/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 9.7303 - val_loss: 11.4669\n",
            "Epoch 5678/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 9.2607 - val_loss: 11.4624\n",
            "Epoch 5679/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 9.3577 - val_loss: 11.4299\n",
            "Epoch 5680/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 9.6053 - val_loss: 11.5346\n",
            "Epoch 5681/6000\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 9.7539 - val_loss: 11.4947\n",
            "Epoch 5682/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 9.4856 - val_loss: 11.5928\n",
            "Epoch 5683/6000\n",
            "6/6 [==============================] - 0s 40ms/step - loss: 9.3389 - val_loss: 11.4765\n",
            "Epoch 5684/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 9.4920 - val_loss: 11.4572\n",
            "Epoch 5685/6000\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 9.5612 - val_loss: 11.4529\n",
            "Epoch 5686/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 9.6084 - val_loss: 11.5158\n",
            "Epoch 5687/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 9.3190 - val_loss: 11.5112\n",
            "Epoch 5688/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 9.4807 - val_loss: 11.3584\n",
            "Epoch 5689/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 10.0121 - val_loss: 11.5888\n",
            "Epoch 5690/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 9.4845 - val_loss: 11.4526\n",
            "Epoch 5691/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 9.5255 - val_loss: 11.4336\n",
            "Epoch 5692/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 9.4552 - val_loss: 11.5553\n",
            "Epoch 5693/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 9.4516 - val_loss: 11.6127\n",
            "Epoch 5694/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 9.5203 - val_loss: 11.3792\n",
            "Epoch 5695/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 9.5418 - val_loss: 11.6248\n",
            "Epoch 5696/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 9.3784 - val_loss: 11.4068\n",
            "Epoch 5697/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 9.3751 - val_loss: 11.5022\n",
            "Epoch 5698/6000\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 9.3272 - val_loss: 11.5300\n",
            "Epoch 5699/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 9.7574 - val_loss: 11.4530\n",
            "Epoch 5700/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 9.6177 - val_loss: 11.4551\n",
            "Epoch 5701/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 9.5821 - val_loss: 11.7097\n",
            "Epoch 5702/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 9.5409 - val_loss: 11.4613\n",
            "Epoch 5703/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 9.3589 - val_loss: 11.5281\n",
            "Epoch 5704/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 9.2573 - val_loss: 11.6359\n",
            "Epoch 5705/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 9.5162 - val_loss: 11.6338\n",
            "Epoch 5706/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 9.2835 - val_loss: 11.6084\n",
            "Epoch 5707/6000\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 9.4153 - val_loss: 11.4321\n",
            "Epoch 5708/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 9.2593 - val_loss: 11.4660\n",
            "Epoch 5709/6000\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 9.2805 - val_loss: 11.4400\n",
            "Epoch 5710/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 9.2360 - val_loss: 11.2752\n",
            "Epoch 5711/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 9.3784 - val_loss: 11.3089\n",
            "Epoch 5712/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 9.3721 - val_loss: 11.2960\n",
            "Epoch 5713/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 9.3647 - val_loss: 11.3647\n",
            "Epoch 5714/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 9.6831 - val_loss: 11.3288\n",
            "Epoch 5715/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 9.4723 - val_loss: 11.2258\n",
            "Epoch 5716/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 9.7805 - val_loss: 11.3505\n",
            "Epoch 5717/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 9.2189 - val_loss: 11.2821\n",
            "Epoch 5718/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 9.3978 - val_loss: 11.2902\n",
            "Epoch 5719/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 9.2429 - val_loss: 11.3880\n",
            "Epoch 5720/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 9.5410 - val_loss: 11.2461\n",
            "Epoch 5721/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 9.4851 - val_loss: 11.2872\n",
            "Epoch 5722/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 9.3031 - val_loss: 11.3526\n",
            "Epoch 5723/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 9.5472 - val_loss: 11.1644\n",
            "Epoch 5724/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 9.1644 - val_loss: 11.1684\n",
            "Epoch 5725/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 9.1513 - val_loss: 11.1285\n",
            "Epoch 5726/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 9.4782 - val_loss: 11.2149\n",
            "Epoch 5727/6000\n",
            "6/6 [==============================] - 0s 39ms/step - loss: 9.3049 - val_loss: 11.1544\n",
            "Epoch 5728/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 9.1981 - val_loss: 11.1363\n",
            "Epoch 5729/6000\n",
            "6/6 [==============================] - 0s 39ms/step - loss: 9.2575 - val_loss: 11.2337\n",
            "Epoch 5730/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 9.4945 - val_loss: 11.2274\n",
            "Epoch 5731/6000\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 9.3154 - val_loss: 11.4037\n",
            "Epoch 5732/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 9.4588 - val_loss: 11.1537\n",
            "Epoch 5733/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 9.4590 - val_loss: 11.2459\n",
            "Epoch 5734/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 9.3541 - val_loss: 11.2365\n",
            "Epoch 5735/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 9.4248 - val_loss: 11.2919\n",
            "Epoch 5736/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 9.4641 - val_loss: 11.3689\n",
            "Epoch 5737/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 9.3677 - val_loss: 11.1610\n",
            "Epoch 5738/6000\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 9.3367 - val_loss: 11.1880\n",
            "Epoch 5739/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 9.3685 - val_loss: 11.3335\n",
            "Epoch 5740/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 9.1634 - val_loss: 11.1687\n",
            "Epoch 5741/6000\n",
            "6/6 [==============================] - 0s 40ms/step - loss: 9.4465 - val_loss: 11.1383\n",
            "Epoch 5742/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 9.1836 - val_loss: 11.1313\n",
            "Epoch 5743/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 9.1537 - val_loss: 11.2080\n",
            "Epoch 5744/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 9.3032 - val_loss: 11.2093\n",
            "Epoch 5745/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 9.2540 - val_loss: 11.2587\n",
            "Epoch 5746/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 9.4439 - val_loss: 11.2944\n",
            "Epoch 5747/6000\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 9.3627 - val_loss: 11.0624\n",
            "Epoch 5748/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 9.7571 - val_loss: 11.2759\n",
            "Epoch 5749/6000\n",
            "6/6 [==============================] - 0s 35ms/step - loss: 9.4210 - val_loss: 11.0979\n",
            "Epoch 5750/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 9.4255 - val_loss: 11.4456\n",
            "Epoch 5751/6000\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 9.5446 - val_loss: 11.2352\n",
            "Epoch 5752/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 9.5424 - val_loss: 11.2843\n",
            "Epoch 5753/6000\n",
            "6/6 [==============================] - 0s 39ms/step - loss: 9.4866 - val_loss: 11.7190\n",
            "Epoch 5754/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 9.6748 - val_loss: 11.3104\n",
            "Epoch 5755/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 9.6427 - val_loss: 11.5776\n",
            "Epoch 5756/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 9.2895 - val_loss: 11.4864\n",
            "Epoch 5757/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 9.2186 - val_loss: 11.4060\n",
            "Epoch 5758/6000\n",
            "6/6 [==============================] - 0s 39ms/step - loss: 9.1239 - val_loss: 11.5601\n",
            "Epoch 5759/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 9.3937 - val_loss: 11.4170\n",
            "Epoch 5760/6000\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 9.1283 - val_loss: 11.2770\n",
            "Epoch 5761/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 9.3015 - val_loss: 11.2048\n",
            "Epoch 5762/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 9.0440 - val_loss: 11.1641\n",
            "Epoch 5763/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 9.1679 - val_loss: 11.1520\n",
            "Epoch 5764/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 9.3010 - val_loss: 11.1449\n",
            "Epoch 5765/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 9.2165 - val_loss: 11.1823\n",
            "Epoch 5766/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 9.2382 - val_loss: 11.2885\n",
            "Epoch 5767/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 9.3080 - val_loss: 11.1147\n",
            "Epoch 5768/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 9.4550 - val_loss: 11.1489\n",
            "Epoch 5769/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 9.4009 - val_loss: 11.3391\n",
            "Epoch 5770/6000\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 9.1572 - val_loss: 11.2598\n",
            "Epoch 5771/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 9.2487 - val_loss: 11.2684\n",
            "Epoch 5772/6000\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 9.2239 - val_loss: 11.1578\n",
            "Epoch 5773/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 9.1887 - val_loss: 11.2748\n",
            "Epoch 5774/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 9.3014 - val_loss: 11.2451\n",
            "Epoch 5775/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 9.1144 - val_loss: 11.3721\n",
            "Epoch 5776/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 9.1864 - val_loss: 11.1562\n",
            "Epoch 5777/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 9.4347 - val_loss: 11.2731\n",
            "Epoch 5778/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 9.3547 - val_loss: 11.2353\n",
            "Epoch 5779/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 9.3434 - val_loss: 11.1617\n",
            "Epoch 5780/6000\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 9.3307 - val_loss: 11.2466\n",
            "Epoch 5781/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 9.3226 - val_loss: 11.1920\n",
            "Epoch 5782/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 9.2442 - val_loss: 11.2193\n",
            "Epoch 5783/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 9.1690 - val_loss: 11.2359\n",
            "Epoch 5784/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 9.1806 - val_loss: 11.1487\n",
            "Epoch 5785/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 9.5693 - val_loss: 11.3031\n",
            "Epoch 5786/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 9.3914 - val_loss: 11.2600\n",
            "Epoch 5787/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 9.2828 - val_loss: 11.1984\n",
            "Epoch 5788/6000\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 9.1734 - val_loss: 11.2812\n",
            "Epoch 5789/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 9.0488 - val_loss: 11.1459\n",
            "Epoch 5790/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 9.1369 - val_loss: 11.2855\n",
            "Epoch 5791/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 9.0346 - val_loss: 11.2683\n",
            "Epoch 5792/6000\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 8.9666 - val_loss: 11.0624\n",
            "Epoch 5793/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 9.2699 - val_loss: 11.1773\n",
            "Epoch 5794/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 9.0938 - val_loss: 11.3972\n",
            "Epoch 5795/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 9.1871 - val_loss: 11.2117\n",
            "Epoch 5796/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 9.0991 - val_loss: 11.3750\n",
            "Epoch 5797/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 9.3186 - val_loss: 11.1073\n",
            "Epoch 5798/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 9.1942 - val_loss: 11.1471\n",
            "Epoch 5799/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 9.3146 - val_loss: 11.1300\n",
            "Epoch 5800/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 9.5048 - val_loss: 11.1095\n",
            "Epoch 5801/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 9.1592 - val_loss: 11.0945\n",
            "Epoch 5802/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 9.2485 - val_loss: 11.1072\n",
            "Epoch 5803/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 9.5104 - val_loss: 11.2815\n",
            "Epoch 5804/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 9.0946 - val_loss: 11.1544\n",
            "Epoch 5805/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 9.1392 - val_loss: 11.1510\n",
            "Epoch 5806/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 8.9865 - val_loss: 11.1285\n",
            "Epoch 5807/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 9.3915 - val_loss: 11.0274\n",
            "Epoch 5808/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 9.1588 - val_loss: 11.0386\n",
            "Epoch 5809/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 9.2550 - val_loss: 11.0512\n",
            "Epoch 5810/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 9.4673 - val_loss: 10.9761\n",
            "Epoch 5811/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 9.2128 - val_loss: 11.1307\n",
            "Epoch 5812/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 9.1135 - val_loss: 11.1985\n",
            "Epoch 5813/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 9.1086 - val_loss: 10.9815\n",
            "Epoch 5814/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 9.0747 - val_loss: 11.2918\n",
            "Epoch 5815/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 9.2578 - val_loss: 10.9645\n",
            "Epoch 5816/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 9.2774 - val_loss: 11.0692\n",
            "Epoch 5817/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 9.0929 - val_loss: 10.9257\n",
            "Epoch 5818/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 9.0416 - val_loss: 11.0295\n",
            "Epoch 5819/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 9.1851 - val_loss: 11.0966\n",
            "Epoch 5820/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 8.9655 - val_loss: 11.0705\n",
            "Epoch 5821/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 9.0508 - val_loss: 11.1337\n",
            "Epoch 5822/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 9.0378 - val_loss: 11.1684\n",
            "Epoch 5823/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 9.0475 - val_loss: 11.0950\n",
            "Epoch 5824/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 8.9200 - val_loss: 11.0242\n",
            "Epoch 5825/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 9.0678 - val_loss: 11.2152\n",
            "Epoch 5826/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 9.1043 - val_loss: 11.2599\n",
            "Epoch 5827/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 9.1140 - val_loss: 11.0835\n",
            "Epoch 5828/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 9.0838 - val_loss: 11.3891\n",
            "Epoch 5829/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 9.2817 - val_loss: 11.0162\n",
            "Epoch 5830/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 9.2779 - val_loss: 11.1957\n",
            "Epoch 5831/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 9.1852 - val_loss: 11.1498\n",
            "Epoch 5832/6000\n",
            "6/6 [==============================] - 0s 39ms/step - loss: 9.1154 - val_loss: 11.0610\n",
            "Epoch 5833/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 9.1287 - val_loss: 11.1172\n",
            "Epoch 5834/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 9.0880 - val_loss: 11.0421\n",
            "Epoch 5835/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 8.9792 - val_loss: 11.1248\n",
            "Epoch 5836/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 9.3065 - val_loss: 11.0716\n",
            "Epoch 5837/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 9.2244 - val_loss: 11.1193\n",
            "Epoch 5838/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 9.3428 - val_loss: 11.1222\n",
            "Epoch 5839/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 9.1061 - val_loss: 11.4134\n",
            "Epoch 5840/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 9.2476 - val_loss: 11.1836\n",
            "Epoch 5841/6000\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 9.5410 - val_loss: 11.4853\n",
            "Epoch 5842/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 9.2512 - val_loss: 11.1067\n",
            "Epoch 5843/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 9.6696 - val_loss: 11.3300\n",
            "Epoch 5844/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 8.9907 - val_loss: 11.2046\n",
            "Epoch 5845/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 9.0647 - val_loss: 11.1692\n",
            "Epoch 5846/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 9.0712 - val_loss: 11.2206\n",
            "Epoch 5847/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 8.9839 - val_loss: 11.1084\n",
            "Epoch 5848/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 8.8876 - val_loss: 11.0274\n",
            "Epoch 5849/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 8.8998 - val_loss: 10.9958\n",
            "Epoch 5850/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 9.1620 - val_loss: 11.0230\n",
            "Epoch 5851/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 8.9647 - val_loss: 10.9970\n",
            "Epoch 5852/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 8.9027 - val_loss: 11.0498\n",
            "Epoch 5853/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 9.0963 - val_loss: 10.9682\n",
            "Epoch 5854/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 9.2910 - val_loss: 11.2309\n",
            "Epoch 5855/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 9.1243 - val_loss: 11.1095\n",
            "Epoch 5856/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 9.1532 - val_loss: 11.1780\n",
            "Epoch 5857/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 9.0439 - val_loss: 11.2011\n",
            "Epoch 5858/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 9.0359 - val_loss: 10.8387\n",
            "Epoch 5859/6000\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 9.0331 - val_loss: 11.0417\n",
            "Epoch 5860/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 8.9765 - val_loss: 10.8521\n",
            "Epoch 5861/6000\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 9.0620 - val_loss: 10.9161\n",
            "Epoch 5862/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 9.1614 - val_loss: 10.9873\n",
            "Epoch 5863/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 9.3380 - val_loss: 10.8552\n",
            "Epoch 5864/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 9.2929 - val_loss: 10.9791\n",
            "Epoch 5865/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 9.1959 - val_loss: 11.2384\n",
            "Epoch 5866/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 9.0407 - val_loss: 10.9883\n",
            "Epoch 5867/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 9.0913 - val_loss: 11.0849\n",
            "Epoch 5868/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 9.1223 - val_loss: 11.0077\n",
            "Epoch 5869/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 8.8926 - val_loss: 11.0395\n",
            "Epoch 5870/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 8.9509 - val_loss: 10.8402\n",
            "Epoch 5871/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 8.8352 - val_loss: 10.9528\n",
            "Epoch 5872/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 9.0584 - val_loss: 10.8759\n",
            "Epoch 5873/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 9.3225 - val_loss: 10.8800\n",
            "Epoch 5874/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 8.9726 - val_loss: 10.8552\n",
            "Epoch 5875/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 9.0342 - val_loss: 11.1517\n",
            "Epoch 5876/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 9.0883 - val_loss: 11.0061\n",
            "Epoch 5877/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 8.9479 - val_loss: 11.1448\n",
            "Epoch 5878/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 9.1065 - val_loss: 11.1363\n",
            "Epoch 5879/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 8.8718 - val_loss: 10.9453\n",
            "Epoch 5880/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 8.8551 - val_loss: 10.9810\n",
            "Epoch 5881/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 9.1986 - val_loss: 11.0693\n",
            "Epoch 5882/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 9.3951 - val_loss: 11.1398\n",
            "Epoch 5883/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 9.3233 - val_loss: 11.0540\n",
            "Epoch 5884/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 9.4902 - val_loss: 11.2365\n",
            "Epoch 5885/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 9.1206 - val_loss: 11.0488\n",
            "Epoch 5886/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 8.8653 - val_loss: 11.0049\n",
            "Epoch 5887/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 8.9613 - val_loss: 11.0917\n",
            "Epoch 5888/6000\n",
            "6/6 [==============================] - 0s 27ms/step - loss: 8.9359 - val_loss: 11.0605\n",
            "Epoch 5889/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 8.9483 - val_loss: 10.8907\n",
            "Epoch 5890/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 9.0508 - val_loss: 10.8640\n",
            "Epoch 5891/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 9.1570 - val_loss: 10.8808\n",
            "Epoch 5892/6000\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 9.0359 - val_loss: 10.9343\n",
            "Epoch 5893/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 8.9261 - val_loss: 10.9769\n",
            "Epoch 5894/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 8.8295 - val_loss: 11.0196\n",
            "Epoch 5895/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 8.7652 - val_loss: 10.9504\n",
            "Epoch 5896/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 9.0667 - val_loss: 11.0503\n",
            "Epoch 5897/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 8.9030 - val_loss: 10.8925\n",
            "Epoch 5898/6000\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 9.1610 - val_loss: 10.8876\n",
            "Epoch 5899/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 8.9912 - val_loss: 11.0180\n",
            "Epoch 5900/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 8.8981 - val_loss: 11.1248\n",
            "Epoch 5901/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 9.1245 - val_loss: 10.9829\n",
            "Epoch 5902/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 8.9077 - val_loss: 11.0214\n",
            "Epoch 5903/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 8.8299 - val_loss: 11.1846\n",
            "Epoch 5904/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 8.8211 - val_loss: 11.1086\n",
            "Epoch 5905/6000\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 9.1899 - val_loss: 11.2078\n",
            "Epoch 5906/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 9.1232 - val_loss: 11.3396\n",
            "Epoch 5907/6000\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 9.4169 - val_loss: 11.3442\n",
            "Epoch 5908/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 9.3596 - val_loss: 11.5784\n",
            "Epoch 5909/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 9.1679 - val_loss: 11.2746\n",
            "Epoch 5910/6000\n",
            "6/6 [==============================] - 0s 26ms/step - loss: 8.9356 - val_loss: 11.3372\n",
            "Epoch 5911/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 8.8412 - val_loss: 11.1913\n",
            "Epoch 5912/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 8.9481 - val_loss: 11.2652\n",
            "Epoch 5913/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 8.8380 - val_loss: 10.9062\n",
            "Epoch 5914/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 8.8865 - val_loss: 11.2265\n",
            "Epoch 5915/6000\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 8.9449 - val_loss: 10.8156\n",
            "Epoch 5916/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 9.1350 - val_loss: 11.1822\n",
            "Epoch 5917/6000\n",
            "6/6 [==============================] - 0s 41ms/step - loss: 8.8112 - val_loss: 11.0878\n",
            "Epoch 5918/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 8.9861 - val_loss: 11.0523\n",
            "Epoch 5919/6000\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 9.1310 - val_loss: 10.9669\n",
            "Epoch 5920/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 8.7362 - val_loss: 10.9443\n",
            "Epoch 5921/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 9.2113 - val_loss: 10.8901\n",
            "Epoch 5922/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 8.8753 - val_loss: 11.0646\n",
            "Epoch 5923/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 9.2096 - val_loss: 10.8822\n",
            "Epoch 5924/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 9.0553 - val_loss: 11.2048\n",
            "Epoch 5925/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 9.0088 - val_loss: 10.9576\n",
            "Epoch 5926/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 8.7547 - val_loss: 10.9949\n",
            "Epoch 5927/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 8.9251 - val_loss: 11.0828\n",
            "Epoch 5928/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 8.8331 - val_loss: 11.0180\n",
            "Epoch 5929/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 8.6689 - val_loss: 11.0749\n",
            "Epoch 5930/6000\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 8.9307 - val_loss: 10.9007\n",
            "Epoch 5931/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 8.8606 - val_loss: 10.8775\n",
            "Epoch 5932/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 8.9082 - val_loss: 10.8505\n",
            "Epoch 5933/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 9.0004 - val_loss: 10.9313\n",
            "Epoch 5934/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 8.7822 - val_loss: 11.0934\n",
            "Epoch 5935/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 8.7392 - val_loss: 10.8971\n",
            "Epoch 5936/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 9.0426 - val_loss: 10.8502\n",
            "Epoch 5937/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 8.7130 - val_loss: 10.9346\n",
            "Epoch 5938/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 8.7649 - val_loss: 10.7985\n",
            "Epoch 5939/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 8.9568 - val_loss: 11.1180\n",
            "Epoch 5940/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 8.9581 - val_loss: 10.8240\n",
            "Epoch 5941/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 9.0689 - val_loss: 10.9991\n",
            "Epoch 5942/6000\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 8.6346 - val_loss: 11.0417\n",
            "Epoch 5943/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 8.9236 - val_loss: 10.9504\n",
            "Epoch 5944/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 8.7681 - val_loss: 10.8418\n",
            "Epoch 5945/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 8.8001 - val_loss: 10.7657\n",
            "Epoch 5946/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 8.8571 - val_loss: 10.7220\n",
            "Epoch 5947/6000\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 9.0897 - val_loss: 10.8375\n",
            "Epoch 5948/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 8.7344 - val_loss: 10.8429\n",
            "Epoch 5949/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 8.8060 - val_loss: 10.8624\n",
            "Epoch 5950/6000\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 8.7679 - val_loss: 10.8344\n",
            "Epoch 5951/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 8.7423 - val_loss: 10.7936\n",
            "Epoch 5952/6000\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 8.8437 - val_loss: 10.8212\n",
            "Epoch 5953/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 8.7052 - val_loss: 10.7267\n",
            "Epoch 5954/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 8.8076 - val_loss: 10.8618\n",
            "Epoch 5955/6000\n",
            "6/6 [==============================] - 0s 24ms/step - loss: 8.9681 - val_loss: 11.0328\n",
            "Epoch 5956/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 8.7994 - val_loss: 10.8441\n",
            "Epoch 5957/6000\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 9.0940 - val_loss: 11.1353\n",
            "Epoch 5958/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 8.8472 - val_loss: 10.9267\n",
            "Epoch 5959/6000\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 8.9241 - val_loss: 11.0288\n",
            "Epoch 5960/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 8.7020 - val_loss: 10.8160\n",
            "Epoch 5961/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 9.1405 - val_loss: 10.8921\n",
            "Epoch 5962/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 8.9007 - val_loss: 11.1453\n",
            "Epoch 5963/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 8.7362 - val_loss: 10.8732\n",
            "Epoch 5964/6000\n",
            "6/6 [==============================] - 0s 38ms/step - loss: 8.9019 - val_loss: 10.9244\n",
            "Epoch 5965/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 8.8925 - val_loss: 10.9719\n",
            "Epoch 5966/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 8.7497 - val_loss: 10.7807\n",
            "Epoch 5967/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 8.7954 - val_loss: 10.8531\n",
            "Epoch 5968/6000\n",
            "6/6 [==============================] - 0s 23ms/step - loss: 8.6065 - val_loss: 10.7859\n",
            "Epoch 5969/6000\n",
            "6/6 [==============================] - 0s 28ms/step - loss: 8.7219 - val_loss: 10.8629\n",
            "Epoch 5970/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 8.5802 - val_loss: 10.7437\n",
            "Epoch 5971/6000\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 8.6449 - val_loss: 10.9039\n",
            "Epoch 5972/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 8.8182 - val_loss: 10.9559\n",
            "Epoch 5973/6000\n",
            "6/6 [==============================] - 0s 31ms/step - loss: 8.7895 - val_loss: 10.8430\n",
            "Epoch 5974/6000\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 9.0830 - val_loss: 10.8890\n",
            "Epoch 5975/6000\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 8.9502 - val_loss: 11.1565\n",
            "Epoch 5976/6000\n",
            "6/6 [==============================] - 0s 34ms/step - loss: 8.9638 - val_loss: 10.8988\n",
            "Epoch 5977/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 9.0924 - val_loss: 11.1470\n",
            "Epoch 5978/6000\n",
            "6/6 [==============================] - 0s 29ms/step - loss: 8.9038 - val_loss: 11.1332\n",
            "Epoch 5979/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 8.8921 - val_loss: 11.1444\n",
            "Epoch 5980/6000\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 9.0265 - val_loss: 11.1580\n",
            "Epoch 5981/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 8.7549 - val_loss: 11.0047\n",
            "Epoch 5982/6000\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 8.6753 - val_loss: 10.8855\n",
            "Epoch 5983/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 8.6787 - val_loss: 10.9040\n",
            "Epoch 5984/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 8.8809 - val_loss: 10.8942\n",
            "Epoch 5985/6000\n",
            "6/6 [==============================] - 0s 30ms/step - loss: 8.6422 - val_loss: 10.7165\n",
            "Epoch 5986/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 8.6887 - val_loss: 10.7686\n",
            "Epoch 5987/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 8.8520 - val_loss: 10.6886\n",
            "Epoch 5988/6000\n",
            "6/6 [==============================] - 0s 32ms/step - loss: 8.7995 - val_loss: 10.8958\n",
            "Epoch 5989/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 8.8124 - val_loss: 10.7430\n",
            "Epoch 5990/6000\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 8.9298 - val_loss: 10.8723\n",
            "Epoch 5991/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 8.6510 - val_loss: 10.7262\n",
            "Epoch 5992/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 8.5369 - val_loss: 10.7729\n",
            "Epoch 5993/6000\n",
            "6/6 [==============================] - 0s 37ms/step - loss: 8.6080 - val_loss: 10.8090\n",
            "Epoch 5994/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 8.6974 - val_loss: 10.8067\n",
            "Epoch 5995/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 8.7402 - val_loss: 10.6850\n",
            "Epoch 5996/6000\n",
            "6/6 [==============================] - 0s 36ms/step - loss: 8.6900 - val_loss: 10.8105\n",
            "Epoch 5997/6000\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 8.7269 - val_loss: 10.7539\n",
            "Epoch 5998/6000\n",
            "6/6 [==============================] - 0s 33ms/step - loss: 8.5625 - val_loss: 10.6019\n",
            "Epoch 5999/6000\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 8.7930 - val_loss: 10.6768\n",
            "Epoch 6000/6000\n",
            "6/6 [==============================] - 0s 25ms/step - loss: 8.7314 - val_loss: 10.8340\n",
            "422/422 [==============================] - 0s 589us/step - loss: 10.9263\n",
            "10.92629623413086\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Best Guess \n",
        "normalizer = tf.keras.layers.Normalization(axis=-1)\n",
        "normalizer.adapt(np.array(X_tr_ex))\n",
        "\n",
        "mod_ex = keras.Sequential()\n",
        "mod_ex.add(normalizer)\n",
        "mod_ex.add(InputLayer(input_shape=(start_width,)))\n",
        "mod_ex.add(Dense(start_width*3, activation='relu'))\n",
        "mod_ex.add(BatchNormalization())\n",
        "#mod_ex.add(Dense(start_width*3, activation='relu'))\n",
        "#mod_ex.add(BatchNormalization())\n",
        "mod_ex.add(Dense(start_width*2, activation='relu'))\n",
        "mod_ex.add(BatchNormalization())\n",
        "#mod_ex.add(Dropout(.2))\n",
        "mod_ex.add(Dense(start_width*2, activation='relu'))\n",
        "mod_ex.add(BatchNormalization())\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(BatchNormalization())\n",
        "mod_ex.add(Dense(start_width, activation='relu'))\n",
        "mod_ex.add(BatchNormalization())\n",
        "#mod_ex.add(Dropout(.2))\n",
        "mod_ex.add(Dense(start_width/2, activation='relu'))\n",
        "mod_ex.add(BatchNormalization())\n",
        "#mod_ex.add(Dropout(.2))\n",
        "mod_ex.add(Dense(start_width/2, activation='relu'))\n",
        "mod_ex.add(BatchNormalization())\n",
        "#mod_ex.add(Dense(start_width/3, activation='relu'))\n",
        "#mod_ex.add(BatchNormalization())\n",
        "#mod_ex.add(Dropout(.2))\n",
        "mod_ex.add(Dense(start_width/3, activation='relu'))\n",
        "mod_ex.add(BatchNormalization())\n",
        "mod_ex.add(Dense(start_width/4, activation='relu'))\n",
        "mod_ex.add(BatchNormalization())\n",
        "mod_ex.add(Dense(1))\n",
        "\n",
        "mod_ex.compile(optimizer='adam', loss=\"mean_absolute_percentage_error\")\n",
        "\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=400, restore_best_weights=True) \n",
        "\n",
        "hist_ex = mod_ex.fit(\n",
        "  X_tr_ex,\n",
        "  y_tr_ex,\n",
        "  epochs=6000,\n",
        "  batch_size=6000,\n",
        "  validation_split=0.2,\n",
        "  callbacks=[callback],\n",
        "  verbose=1\n",
        ")\n",
        "print(mod_ex.evaluate(X_te_ex, y_te_ex))\n",
        "plot_loss(hist_ex)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "keras_optimizations_sol.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('ml3950')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "4d722d3adfa415172c1f5238b519fb86b488acdae450fd691ab06c09f4ca9173"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
